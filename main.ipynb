{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbd9740e-606f-488c-adc6-450f320dae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cae94c70-d297-474f-904a-ba2ebc62a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Set\n",
    "from enum import Enum\n",
    "import math\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "data_folder = \"data/\"\n",
    "jsons_path = \"data/*.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a807f4-ada1-46e4-82ac-d78a74271261",
   "metadata": {},
   "source": [
    "Création de la classe FullCellInfo récupérant l'ensmeble des informations d'une cellule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cfa8d38-bca5-4b48-9f44-50e11f331653",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FullCellInfo:\n",
    "    \"\"\"Structure complète d'une cellule Excel avec les informations disponibles dans le JSON Univer\"\"\"\n",
    "    # Contenu (disponible dans le JSON)\n",
    "    raw_value: Any = \"\"\n",
    "    cell_type: int = 0  # 1=text, 2=number, 3=formula (inféré)\n",
    "    formula: str = \"\"   # \"f\" - formule si présente (avec = au début)\n",
    "    \n",
    "    # Position\n",
    "    row: int = 0\n",
    "    col: int = 0\n",
    "    sheet_id: str = \"default\"\n",
    "    sheet_name: str = \"\"\n",
    "    \n",
    "    # Style complet (basé sur le format Univer optimisé)\n",
    "    style_id: str = \"\"  # Peut être vide si pas de style\n",
    "    \n",
    "    # Formatage de texte\n",
    "    bold: bool = False          # \"bl\": 1\n",
    "    italic: bool = False        # \"it\": 1  \n",
    "    underline: bool = False     # \"ul\": {\"s\": 1}\n",
    "    strike: bool = False        # \"st\": {\"s\": 1}\n",
    "    font_size: float = 11.0     # \"fs\": size (défaut Calibri 11)\n",
    "    font_family: str = \"Calibri\" # \"ff\": family\n",
    "    \n",
    "    # Couleurs\n",
    "    text_color: str = \"#000000\"     # \"cl\": {\"rgb\": \"#color\"}\n",
    "    background_color: str = \"#FFFFFF\"  # \"bg\": {\"rgb\": \"#color\"}\n",
    "    \n",
    "    # Bordures\n",
    "    border_top: int = 0      # \"bd\": {\"t\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_bottom: int = 0   # \"bd\": {\"b\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_left: int = 0     # \"bd\": {\"l\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_right: int = 0    # \"bd\": {\"r\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_color: str = \"#000000\"\n",
    "    \n",
    "    # Alignement\n",
    "    horizontal_align: int = 0  # \"ht\": 1=left, 2=center, 3=right, 4=justify\n",
    "    vertical_align: int = 0    # \"vt\": 1=top, 2=center, 3=bottom\n",
    "    text_wrap: bool = False    # \"tb\": 3\n",
    "    \n",
    "    # Rotation/Transformation\n",
    "    text_rotation: int = 0     # \"tr\": {\"a\": angle, \"v\": 0}\n",
    "    \n",
    "    # Format de nombre\n",
    "    number_format: str = \"General\"  # \"n\": {\"pattern\": \"format\"}\n",
    "    \n",
    "    # Fusion de cellules (disponible via mergeData)\n",
    "    is_merged: bool = False\n",
    "    merge_range: Tuple[int, int, int, int] = (0, 0, 0, 0)  # (startRow, endRow, startCol, endCol)\n",
    "    \n",
    "    # Métadonnées de feuille\n",
    "    sheet_hidden: bool = False\n",
    "    sheet_tab_color: str = \"\"\n",
    "    sheet_zoom: float = 1.0\n",
    "    sheet_show_gridlines: bool = True\n",
    "    \n",
    "    # Métadonnées de ligne/colonne\n",
    "    row_height: Optional[float] = None\n",
    "    row_hidden: bool = False\n",
    "    col_width: Optional[int] = None\n",
    "    col_hidden: bool = False\n",
    "    \n",
    "    # Volets figés\n",
    "    freeze_start_row: int = -1\n",
    "    freeze_start_col: int = -1\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Post-processing après création\"\"\"\n",
    "        # Le type est défini par \"t\" dans le JSON ou inféré du contenu\n",
    "        if self.cell_type == 0:  # Si pas de type défini\n",
    "            if self.formula:\n",
    "                self.cell_type = 3\n",
    "            elif isinstance(self.raw_value, (int, float)):\n",
    "                self.cell_type = 2\n",
    "            elif isinstance(self.raw_value, str) and self.raw_value.strip():\n",
    "                self.cell_type = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef97d7-8054-4630-afd8-51c40872a5f2",
   "metadata": {},
   "source": [
    "Classe pour générer les FullCellInfo à partir d'un json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "325735e2-438e-4887-8588-8e2575063cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcelParser:\n",
    "    \"\"\"Parse les fichiers Excel JSON Univer en structures FullCellInfo\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_excel_json(excel_data: Dict) -> List['FullCellInfo']:\n",
    "        \"\"\"Convertit JSON Excel Univer en liste de FullCellInfo\"\"\"\n",
    "        cells = []  \n",
    "        \n",
    "        styles = excel_data.get('styles', {})\n",
    "        \n",
    "        for sheet_id, sheet_info in excel_data.get('sheets', {}).items():\n",
    "            sheet_name = sheet_info.get('name', \"\")\n",
    "            cell_data = sheet_info.get('cellData', {})\n",
    "            merge_data = sheet_info.get('mergeData', [])\n",
    "            row_data = sheet_info.get('rowData', {})\n",
    "            column_data = sheet_info.get('columnData', {})\n",
    "            freeze_info = sheet_info.get('freeze', {})\n",
    "            \n",
    "            # Métadonnées de feuille\n",
    "            sheet_hidden = bool(sheet_info.get('hidden', 0))\n",
    "            sheet_tab_color = sheet_info.get('tabColor', \"\")\n",
    "            sheet_zoom = sheet_info.get('zoomRatio', 1.0)\n",
    "            sheet_show_gridlines = bool(sheet_info.get('showGridlines', 1))\n",
    "            \n",
    "            # Informations de volets figés\n",
    "            freeze_start_row = freeze_info.get('startRow', -1)\n",
    "            freeze_start_col = freeze_info.get('startColumn', -1)\n",
    "            \n",
    "            # Créer un mapping des cellules fusionnées\n",
    "            merge_map = ExcelParser._create_merge_map(merge_data)\n",
    "            \n",
    "            for row_str, row_cells in cell_data.items():\n",
    "                row = int(row_str)\n",
    "                \n",
    "                # Informations de ligne\n",
    "                row_info = row_data.get(row_str, {})\n",
    "                row_height = row_info.get('h')\n",
    "                row_hidden = bool(row_info.get('hd', 0))\n",
    "                \n",
    "                for col_str, cell_info in row_cells.items():\n",
    "                    col = int(col_str)\n",
    "                    \n",
    "                    # Informations de colonne\n",
    "                    col_info = column_data.get(col_str, {})\n",
    "                    col_width = col_info.get('w')\n",
    "                    col_hidden = bool(col_info.get('hd', 0))\n",
    "                    \n",
    "                    # Extraire les informations de style\n",
    "                    style_id = cell_info.get('s', '')\n",
    "                    style = styles.get(style_id, {}) if style_id else {}\n",
    "                    \n",
    "                    # Vérifier si cette cellule fait partie d'une fusion\n",
    "                    merge_info = merge_map.get((row, col), None)\n",
    "                    \n",
    "                    cell = FullCellInfo(\n",
    "                        raw_value=cell_info.get('v', ''),\n",
    "                        cell_type=cell_info.get('t', 0),\n",
    "                        formula=cell_info.get('f', ''),\n",
    "                        row=row,\n",
    "                        col=col,\n",
    "                        sheet_id=sheet_id,\n",
    "                        sheet_name=sheet_name,\n",
    "                        style_id=style_id,\n",
    "                        is_merged=merge_info is not None,\n",
    "                        merge_range=merge_info if merge_info else (0, 0, 0, 0),\n",
    "                        sheet_hidden=sheet_hidden,\n",
    "                        sheet_tab_color=sheet_tab_color,\n",
    "                        sheet_zoom=sheet_zoom,\n",
    "                        sheet_show_gridlines=sheet_show_gridlines,\n",
    "                        row_height=row_height,\n",
    "                        row_hidden=row_hidden,\n",
    "                        col_width=col_width,\n",
    "                        col_hidden=col_hidden,\n",
    "                        freeze_start_row=freeze_start_row,\n",
    "                        freeze_start_col=freeze_start_col,\n",
    "                        **ExcelParser._parse_style(style)\n",
    "                    )\n",
    "                    \n",
    "                    cells.append(cell)  \n",
    "        \n",
    "        return cells\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_merge_map(merge_data: List[Dict]) -> Dict[Tuple[int, int], Tuple[int, int, int, int]]:\n",
    "        \"\"\"Crée un mapping des cellules fusionnées\"\"\"\n",
    "        merge_map = {}\n",
    "        \n",
    "        for merge in merge_data:\n",
    "            start_row = merge['startRow']\n",
    "            end_row = merge['endRow'] \n",
    "            start_col = merge['startColumn']\n",
    "            end_col = merge['endColumn']\n",
    "            \n",
    "            # Marquer toutes les cellules dans cette plage comme fusionnées\n",
    "            for row in range(start_row, end_row + 1):\n",
    "                for col in range(start_col, end_col + 1):\n",
    "                    merge_map[(row, col)] = (start_row, end_row, start_col, end_col)\n",
    "        \n",
    "        return merge_map\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_style(style: Dict) -> Dict:\n",
    "        \"\"\"Parse les informations de style basé sur le format Univer optimisé\"\"\"\n",
    "        parsed = {\n",
    "            'bold': bool(style.get('bl', 0)),\n",
    "            'italic': bool(style.get('it', 0)),\n",
    "            'font_size': float(style.get('fs', 11.0)),\n",
    "            'font_family': style.get('ff', 'Calibri'),\n",
    "            'text_wrap': bool(style.get('tb', 0) == 3),  # tb: 3 = wrap\n",
    "        }\n",
    "        \n",
    "        # Underline - structure: \"ul\": {\"s\": 1}\n",
    "        ul_info = style.get('ul', {})\n",
    "        if isinstance(ul_info, dict):\n",
    "            parsed['underline'] = bool(ul_info.get('s', 0))\n",
    "        else:\n",
    "            parsed['underline'] = bool(ul_info)\n",
    "        \n",
    "        # Strike - structure: \"st\": {\"s\": 1}\n",
    "        st_info = style.get('st', {})\n",
    "        if isinstance(st_info, dict):\n",
    "            parsed['strike'] = bool(st_info.get('s', 0))\n",
    "        else:\n",
    "            parsed['strike'] = bool(st_info)\n",
    "        \n",
    "        # Couleurs\n",
    "        if 'cl' in style:  # text color\n",
    "            parsed['text_color'] = style['cl'].get('rgb', '#000000')\n",
    "        if 'bg' in style:  # background color\n",
    "            parsed['background_color'] = style['bg'].get('rgb', '#FFFFFF')\n",
    "            \n",
    "        # Bordures - structure: \"bd\": {\"t\": {\"s\": 8, \"cl\": {\"rgb\": \"#000000\"}}}\n",
    "        borders = style.get('bd', {})\n",
    "        parsed.update({\n",
    "            'border_top': borders.get('t', {}).get('s', 0),\n",
    "            'border_bottom': borders.get('b', {}).get('s', 0),\n",
    "            'border_left': borders.get('l', {}).get('s', 0),\n",
    "            'border_right': borders.get('r', {}).get('s', 0),\n",
    "        })\n",
    "        \n",
    "        # Couleur de bordure (prendre la première trouvée)\n",
    "        border_color = \"#000000\"\n",
    "        for border_side in ['t', 'b', 'l', 'r']:\n",
    "            if border_side in borders and 'cl' in borders[border_side]:\n",
    "                border_color = borders[border_side]['cl'].get('rgb', '#000000')\n",
    "                break\n",
    "        parsed['border_color'] = border_color\n",
    "        \n",
    "        # Alignement (mapping exact du convertisseur)\n",
    "        parsed.update({\n",
    "            'horizontal_align': style.get('ht', 0),  # 1=left, 2=center, 3=right, 4=justify\n",
    "            'vertical_align': style.get('vt', 0),    # 1=top, 2=center, 3=bottom\n",
    "        })\n",
    "        \n",
    "        # Rotation/Transformation - \"tr\": {\"a\": angle, \"v\": 0}\n",
    "        tr_info = style.get('tr', {})\n",
    "        if isinstance(tr_info, dict):\n",
    "            parsed['text_rotation'] = tr_info.get('a', 0)  # angle\n",
    "        else:\n",
    "            parsed['text_rotation'] = 0\n",
    "        \n",
    "        # Format de nombre - structure: \"n\": {\"pattern\": \"format\"}\n",
    "        number_info = style.get('n', {})\n",
    "        if isinstance(number_info, dict):\n",
    "            parsed['number_format'] = number_info.get('pattern', 'General')\n",
    "        else:\n",
    "            parsed['number_format'] = 'General'\n",
    "        \n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c348c-af2f-43bb-9bc3-9b8cf5421447",
   "metadata": {},
   "source": [
    "Tokenisation d'un classeur : [POS:1,0][TYPE:TEXT][STYLE:B,I,BG:#4470C4][VALUE:Map brief][MERGE:1,2,0,6][LAYOUT:RH:25.2,CW:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "401e09af-a884-4155-b3dd-c0bc83ebbe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcelDataProcessor:\n",
    "    \"\"\"Classe pour préparer les données Excel pour l'entraînement de transformers\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def cells_to_text_sequence(cells: List[FullCellInfo], include_empty_cells: bool = False) -> str:\n",
    "        \"\"\"Convertit une liste de cellules en séquence de texte pour l'entraînement\"\"\"\n",
    "        sequences = []\n",
    "        \n",
    "        # Regrouper par feuille et position\n",
    "        sheets = {}\n",
    "        for cell in cells:\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append(cell)\n",
    "        \n",
    "        for sheet_name, sheet_cells in sheets.items():\n",
    "            # Trier par position (row, col)\n",
    "            sheet_cells.sort(key=lambda c: (c.row, c.col))\n",
    "            \n",
    "            # Métadonnées de feuille enrichies\n",
    "            sheet_meta = f\"[SHEET:{sheet_name}\"\n",
    "            if sheet_cells:\n",
    "                first_cell = sheet_cells[0]\n",
    "                if first_cell.sheet_hidden:\n",
    "                    sheet_meta += \",HIDDEN\"\n",
    "                if first_cell.sheet_tab_color:\n",
    "                    sheet_meta += f\",TAB:{first_cell.sheet_tab_color}\"\n",
    "                if first_cell.sheet_zoom != 1.0:\n",
    "                    sheet_meta += f\",ZOOM:{first_cell.sheet_zoom}\"\n",
    "                if not first_cell.sheet_show_gridlines:\n",
    "                    sheet_meta += \",NO_GRID\"\n",
    "                if first_cell.freeze_start_row >= 0 or first_cell.freeze_start_col >= 0:\n",
    "                    sheet_meta += f\",FREEZE:{first_cell.freeze_start_row},{first_cell.freeze_start_col}\"\n",
    "            sheet_meta += \"]\"\n",
    "            \n",
    "            sheet_text = sheet_meta\n",
    "            for cell in sheet_cells:\n",
    "                if not include_empty_cells and not cell.raw_value and not cell.is_merged and not cell.style_id:\n",
    "                    continue\n",
    "                cell_repr = ExcelDataProcessor._cell_to_token(cell)\n",
    "                sheet_text += f\" {cell_repr}\"\n",
    "            \n",
    "            sequences.append(sheet_text)\n",
    "        \n",
    "        return \" [SHEET_END] \".join(sequences)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _cell_to_token(cell: FullCellInfo) -> str:\n",
    "        \"\"\"Convertit une cellule en token enrichi pour le transformer\"\"\"\n",
    "        # Format: [POS:row,col][TYPE:t][STYLE:...][VALUE:...][MERGE:...][ROW/COL:...]\n",
    "        pos = f\"[POS:{cell.row},{cell.col}]\"\n",
    "        \n",
    "        # Type de cellule\n",
    "        type_map = {0: \"EMPTY\", 1: \"TEXT\", 2: \"NUMBER\", 3: \"FORMULA\"}\n",
    "        cell_type = f\"[TYPE:{type_map.get(cell.cell_type, 'UNKNOWN')}]\"\n",
    "        \n",
    "        # Style simplifié pour le token\n",
    "        style_parts = []\n",
    "        if cell.bold: style_parts.append(\"B\")\n",
    "        if cell.italic: style_parts.append(\"I\") \n",
    "        if cell.underline: style_parts.append(\"U\")\n",
    "        if cell.strike: style_parts.append(\"S\")\n",
    "        if cell.background_color != \"#FFFFFF\": \n",
    "            style_parts.append(f\"BG:{cell.background_color}\")\n",
    "        if cell.text_rotation != 0: \n",
    "            style_parts.append(f\"ROT:{cell.text_rotation}\")\n",
    "        if any([cell.border_top, cell.border_bottom, cell.border_left, cell.border_right]):\n",
    "            style_parts.append(\"BORDER\")\n",
    "        if cell.horizontal_align != 0:\n",
    "            align_map = {1: \"LEFT\", 2: \"CENTER\", 3: \"RIGHT\", 4: \"JUSTIFY\"}\n",
    "            style_parts.append(f\"ALIGN:{align_map.get(cell.horizontal_align, 'UNKNOWN')}\")\n",
    "        if cell.text_wrap:\n",
    "            style_parts.append(\"WRAP\")\n",
    "        if cell.font_size != 11.0:\n",
    "            style_parts.append(f\"SIZE:{cell.font_size}\")\n",
    "        if cell.font_family != \"Calibri\":\n",
    "            style_parts.append(f\"FONT:{cell.font_family}\")\n",
    "        \n",
    "        style = f\"[STYLE:{','.join(style_parts)}]\" if style_parts else \"[STYLE:NONE]\"\n",
    "        \n",
    "        # Valeur (formule ou valeur)\n",
    "        if cell.formula:\n",
    "            # Formule avec = au début selon le convertisseur\n",
    "            formula_clean = cell.formula.lstrip('=')\n",
    "            value = f\"[FORMULA:={formula_clean}]\"\n",
    "        else:\n",
    "            value = f\"[VALUE:{cell.raw_value}]\"\n",
    "        \n",
    "        # Ajout information de fusion\n",
    "        merge = \"\"\n",
    "        if cell.is_merged:\n",
    "            sr, er, sc, ec = cell.merge_range\n",
    "            merge = f\"[MERGE:{sr},{er},{sc},{ec}]\"\n",
    "        \n",
    "        # Informations de ligne/colonne si non-standard\n",
    "        layout = \"\"\n",
    "        layout_parts = []\n",
    "        if cell.row_height is not None:\n",
    "            layout_parts.append(f\"RH:{cell.row_height}\")\n",
    "        if cell.row_hidden:\n",
    "            layout_parts.append(\"ROW_HIDDEN\")\n",
    "        if cell.col_width is not None:\n",
    "            layout_parts.append(f\"CW:{cell.col_width}\")\n",
    "        if cell.col_hidden:\n",
    "            layout_parts.append(\"COL_HIDDEN\")\n",
    "        \n",
    "        if layout_parts:\n",
    "            layout = f\"[LAYOUT:{','.join(layout_parts)}]\"\n",
    "        \n",
    "        return f\"{pos}{cell_type}{style}{value}{merge}{layout}\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_workbook_metadata(cells: List[FullCellInfo]) -> Dict[str, Any]:\n",
    "        \"\"\"Extrait les métadonnées complètes du classeur\"\"\"\n",
    "        if not cells:\n",
    "            return {}\n",
    "        \n",
    "        sheet_metadata = {}\n",
    "        \n",
    "        for cell in cells:\n",
    "            if cell.sheet_name not in sheet_metadata:\n",
    "                sheet_metadata[cell.sheet_name] = {\n",
    "                    'sheet_id': cell.sheet_id,\n",
    "                    'hidden': cell.sheet_hidden,\n",
    "                    'tab_color': cell.sheet_tab_color,\n",
    "                    'zoom': cell.sheet_zoom,\n",
    "                    'show_gridlines': cell.sheet_show_gridlines,\n",
    "                    'freeze_panes': (cell.freeze_start_row, cell.freeze_start_col) if cell.freeze_start_row >= 0 or cell.freeze_start_col >= 0 else None,\n",
    "                    'cell_count': 0,\n",
    "                    'merged_count': 0,\n",
    "                    'formula_count': 0,\n",
    "                    'styles_used': set(),\n",
    "                    'max_row': 0,\n",
    "                    'max_col': 0,\n",
    "                    'custom_row_heights': 0,\n",
    "                    'custom_col_widths': 0,\n",
    "                    'hidden_rows': 0,\n",
    "                    'hidden_cols': 0\n",
    "                }\n",
    "            \n",
    "            meta = sheet_metadata[cell.sheet_name]\n",
    "            meta['cell_count'] += 1\n",
    "            meta['max_row'] = max(meta['max_row'], cell.row)\n",
    "            meta['max_col'] = max(meta['max_col'], cell.col)\n",
    "            \n",
    "            if cell.is_merged:\n",
    "                meta['merged_count'] += 1\n",
    "            if cell.formula:\n",
    "                meta['formula_count'] += 1\n",
    "            if cell.style_id:\n",
    "                meta['styles_used'].add(cell.style_id)\n",
    "            if cell.row_height is not None:\n",
    "                meta['custom_row_heights'] += 1\n",
    "            if cell.col_width is not None:\n",
    "                meta['custom_col_widths'] += 1\n",
    "            if cell.row_hidden:\n",
    "                meta['hidden_rows'] += 1\n",
    "            if cell.col_hidden:\n",
    "                meta['hidden_cols'] += 1\n",
    "        \n",
    "        # Convertir les sets en listes pour la sérialisation\n",
    "        for meta in sheet_metadata.values():\n",
    "            meta['styles_used'] = list(meta['styles_used'])\n",
    "        \n",
    "        return {\n",
    "            'sheets': sheet_metadata,\n",
    "            'total_cells': len(cells),\n",
    "            'total_sheets': len(sheet_metadata),\n",
    "            'total_merged_cells': sum(meta['merged_count'] for meta in sheet_metadata.values()),\n",
    "            'total_formulas': sum(meta['formula_count'] for meta in sheet_metadata.values()),\n",
    "            'total_styles': len(set(cell.style_id for cell in cells if cell.style_id))\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748e56d-a71b-4c4f-b48f-ce17391fc9a0",
   "metadata": {},
   "source": [
    "Embedder depuis FullCellInfo : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c13001e0-ba4b-42fd-bccb-06ab8dcd3ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 525\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;66;03m# Obtenir l'embedding\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     embedding = \u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    527\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding (premiers 10 éléments): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding[:\u001b[32m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mExcelCellEmbedder.forward\u001b[39m\u001b[34m(self, cells)\u001b[39m\n\u001b[32m    118\u001b[39m type_emb = \u001b[38;5;28mself\u001b[39m.type_embedding(torch.tensor(cell.cell_type))\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Position 2: Contenu\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m value_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Position 3-6: Formatage booléen\u001b[39;00m\n\u001b[32m    124\u001b[39m bold_emb = \u001b[38;5;28mself\u001b[39m.bool_embedding(torch.tensor(\u001b[38;5;28mint\u001b[39m(cell.bold)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 266\u001b[39m, in \u001b[36mValueEncoder.forward\u001b[39m\u001b[34m(self, cell)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, cell: \u001b[33m'\u001b[39m\u001b[33mFullCellInfo\u001b[39m\u001b[33m'\u001b[39m) -> torch.Tensor:\n\u001b[32m    265\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Encode la valeur en séquence de tokens\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmask_content\u001b[49m:\n\u001b[32m    267\u001b[39m         \u001b[38;5;66;03m# Pour le masked prediction\u001b[39;00m\n\u001b[32m    268\u001b[39m         tokens = [\u001b[38;5;28mself\u001b[39m.mask_token_id] * \u001b[38;5;28mself\u001b[39m.max_tokens\n\u001b[32m    269\u001b[39m         content_type = \u001b[32m0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'mask_content' is not defined"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class EmbeddingConfig:\n",
    "    \"\"\"Configuration pour l'embedder Excel\"\"\"\n",
    "    # Dimensions\n",
    "    embedding_dim: int = 256\n",
    "    position_embedding_dim: int = 24\n",
    "    type_embedding_dim: int = 16\n",
    "    \n",
    "    # Vocabulaires fixes\n",
    "    max_position: int = 1000  # pour row/col\n",
    "    max_value_length: int = 100\n",
    "    max_font_size: int = 72\n",
    "    \n",
    "    # Couleurs (nombre de couleurs possibles)\n",
    "    color_vocab_size: int = 100\n",
    "    \n",
    "    # Alignements, bordures, etc.\n",
    "    align_vocab_size: int = 5\n",
    "    border_vocab_size: int = 10\n",
    "    font_vocab_size: int = 20\n",
    "\n",
    "class ExcelCellEmbedder(nn.Module):\n",
    "    \"\"\"Embedder direct pour FullCellInfo avec positions fixes\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Position 0-1: Position et Type\n",
    "        self.row_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "        self.col_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "        self.type_embedding = nn.Embedding(4, config.type_embedding_dim)  # EMPTY, TEXT, NUMBER, FORMULA\n",
    "        \n",
    "        # Position 2: Contenu (valeur/formule)\n",
    "        self.value_encoder = ValueEncoder(config)\n",
    "        \n",
    "        # Position 3-6: Formatage booléen\n",
    "        self.bool_embedding = nn.Embedding(2, 8)  # TRUE/FALSE -> 8 dim\n",
    "        \n",
    "        # Position 7-8: Police\n",
    "        self.font_size_embedding = nn.Embedding(config.max_font_size + 1, 16)\n",
    "        self.font_family_embedding = nn.Embedding(config.font_vocab_size, 32)\n",
    "        \n",
    "        # Position 9-10: Couleurs\n",
    "        self.color_embedding = nn.Embedding(config.color_vocab_size, 24)\n",
    "        \n",
    "        # Position 11-14: Alignement\n",
    "        self.align_h_embedding = nn.Embedding(config.align_vocab_size, 16)\n",
    "        self.align_v_embedding = nn.Embedding(config.align_vocab_size, 16)\n",
    "        self.rotation_embedding = nn.Embedding(361, 16)  # 0-360 degrés\n",
    "        \n",
    "        # Position 15-18: Bordures\n",
    "        self.border_embedding = nn.Embedding(config.border_vocab_size, 16)\n",
    "        \n",
    "        # Position 19: Fusion\n",
    "        self.merge_encoder = MergeEncoder(config)\n",
    "        \n",
    "        # Projection finale\n",
    "        total_dim = self._calculate_total_dim()\n",
    "        self.projection = nn.Linear(total_dim, config.embedding_dim)\n",
    "        \n",
    "        # Normalisation\n",
    "        self.layer_norm = nn.LayerNorm(config.embedding_dim)\n",
    "        \n",
    "        # Vocabulaires pour la conversion\n",
    "        self._build_vocabularies()\n",
    "    \n",
    "    def _calculate_total_dim(self) -> int:\n",
    "        \"\"\"Calcule la dimension totale avant projection\"\"\"\n",
    "        return (\n",
    "            2 * self.config.position_embedding_dim +  # row, col\n",
    "            self.config.type_embedding_dim +          # type\n",
    "            self.value_encoder.output_dim +           # value (maintenant 2048D)\n",
    "            4 * 8 +                                   # 4 bool (bold, italic, underline, strike)\n",
    "            16 + 32 +                                 # font_size, font_family\n",
    "            2 * 24 +                                  # text_color, bg_color\n",
    "            2 * 16 + 8 + 16 +                        # align_h, align_v, wrap, rotation\n",
    "            4 * 16 +                                  # 4 borders\n",
    "            self.merge_encoder.output_dim             # merge\n",
    "        )\n",
    "    \n",
    "    def _build_vocabularies(self):\n",
    "        \"\"\"Construit les vocabulaires de conversion\"\"\"\n",
    "        # Familles de police communes\n",
    "        self.font_families = [\n",
    "            \"Calibri\", \"Arial\", \"Times New Roman\", \"Helvetica\", \"Verdana\",\n",
    "            \"Georgia\", \"Courier New\", \"Tahoma\", \"Comic Sans MS\", \"Impact\",\n",
    "            # ... ajouter d'autres polices communes\n",
    "        ]\n",
    "        self.font_family_to_id = {font: i for i, font in enumerate(self.font_families)}\n",
    "        \n",
    "        # Styles de bordure\n",
    "        self.border_styles = [\"NONE\", \"THIN\", \"HAIR\", \"DOTTED\", \"DASHED\", \"DOUBLE\", \"MEDIUM\", \"THICK\"]\n",
    "        self.border_style_to_id = {style: i for i, style in enumerate(self.border_styles)}\n",
    "    \n",
    "    def forward(self, cells: Union['FullCellInfo', List['FullCellInfo']]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convertit FullCellInfo en embeddings\n",
    "        \n",
    "        Args:\n",
    "            cells: Une cellule ou liste de cellules\n",
    "            \n",
    "        Returns:\n",
    "            Tensor de shape [batch_size, embedding_dim] ou [embedding_dim]\n",
    "        \"\"\"\n",
    "        if not isinstance(cells, list):\n",
    "            cells = [cells]\n",
    "        \n",
    "        batch_size = len(cells)\n",
    "        embeddings = []\n",
    "        \n",
    "        for cell in cells:\n",
    "            # Position 0-1: Position spatiale\n",
    "            row_emb = self.row_embedding(torch.clamp(torch.tensor(cell.row), 0, self.config.max_position - 1))\n",
    "            col_emb = self.col_embedding(torch.clamp(torch.tensor(cell.col), 0, self.config.max_position - 1))\n",
    "            \n",
    "            # Position 1: Type de cellule\n",
    "            type_emb = self.type_embedding(torch.tensor(cell.cell_type))\n",
    "            \n",
    "            # Position 2: Contenu\n",
    "            value_emb = self.value_encoder(cell)\n",
    "            \n",
    "            # Position 3-6: Formatage booléen\n",
    "            bold_emb = self.bool_embedding(torch.tensor(int(cell.bold)))\n",
    "            italic_emb = self.bool_embedding(torch.tensor(int(cell.italic)))\n",
    "            underline_emb = self.bool_embedding(torch.tensor(int(cell.underline)))\n",
    "            strike_emb = self.bool_embedding(torch.tensor(int(cell.strike)))\n",
    "            \n",
    "            # Position 7-8: Police\n",
    "            font_size = min(int(cell.font_size), self.config.max_font_size)\n",
    "            font_size_emb = self.font_size_embedding(torch.tensor(font_size))\n",
    "            \n",
    "            font_id = self.font_family_to_id.get(cell.font_family, 0)\n",
    "            font_family_emb = self.font_family_embedding(torch.tensor(font_id))\n",
    "            \n",
    "            # Position 9-10: Couleurs\n",
    "            text_color_id = self._color_to_id(cell.text_color)\n",
    "            bg_color_id = self._color_to_id(cell.background_color)\n",
    "            text_color_emb = self.color_embedding(torch.tensor(text_color_id))\n",
    "            bg_color_emb = self.color_embedding(torch.tensor(bg_color_id))\n",
    "            \n",
    "            # Position 11-14: Alignement\n",
    "            align_h_emb = self.align_h_embedding(torch.tensor(cell.horizontal_align))\n",
    "            align_v_emb = self.align_v_embedding(torch.tensor(cell.vertical_align))\n",
    "            wrap_emb = self.bool_embedding(torch.tensor(int(cell.text_wrap)))\n",
    "            rotation = min(abs(cell.text_rotation), 360)\n",
    "            rotation_emb = self.rotation_embedding(torch.tensor(rotation))\n",
    "            \n",
    "            # Position 15-18: Bordures\n",
    "            border_top_id = self._border_to_id(cell.border_top)\n",
    "            border_bottom_id = self._border_to_id(cell.border_bottom)\n",
    "            border_left_id = self._border_to_id(cell.border_left)\n",
    "            border_right_id = self._border_to_id(cell.border_right)\n",
    "            \n",
    "            border_top_emb = self.border_embedding(torch.tensor(border_top_id))\n",
    "            border_bottom_emb = self.border_embedding(torch.tensor(border_bottom_id))\n",
    "            border_left_emb = self.border_embedding(torch.tensor(border_left_id))\n",
    "            border_right_emb = self.border_embedding(torch.tensor(border_right_id))\n",
    "            \n",
    "            # Position 19: Fusion\n",
    "            merge_emb = self.merge_encoder(cell)\n",
    "            \n",
    "            # Concaténer tous les embeddings\n",
    "            cell_embedding = torch.cat([\n",
    "                row_emb, col_emb, type_emb, value_emb,\n",
    "                bold_emb, italic_emb, underline_emb, strike_emb,\n",
    "                font_size_emb, font_family_emb,\n",
    "                text_color_emb, bg_color_emb,\n",
    "                align_h_emb, align_v_emb, wrap_emb, rotation_emb,\n",
    "                border_top_emb, border_bottom_emb, border_left_emb, border_right_emb,\n",
    "                merge_emb\n",
    "            ], dim=0)\n",
    "            \n",
    "            embeddings.append(cell_embedding)\n",
    "        \n",
    "        # Stack et projeter\n",
    "        batch_embeddings = torch.stack(embeddings)\n",
    "        projected = self.projection(batch_embeddings)\n",
    "        normalized = self.layer_norm(projected)\n",
    "        \n",
    "        return normalized.squeeze(0) if len(cells) == 1 else normalized\n",
    "    \n",
    "    def _color_to_id(self, color: str) -> int:\n",
    "        \"\"\"Convertit une couleur hex en ID\"\"\"\n",
    "        if not color or color == \"#FFFFFF\":\n",
    "            return 0  # Couleur par défaut\n",
    "        \n",
    "        # Convertir hex en entier et mapper\n",
    "        try:\n",
    "            hex_val = int(color.replace(\"#\", \"\"), 16)\n",
    "            return (hex_val % (self.config.color_vocab_size - 1)) + 1\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def _border_to_id(self, border_style: int) -> int:\n",
    "        \"\"\"Convertit un style de bordure en ID\"\"\"\n",
    "        # Mapping basé sur les styles Univer\n",
    "        border_map = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 13: 7}\n",
    "        return border_map.get(border_style, 0)\n",
    "    \n",
    "    def get_embedding_at_position(self, cell: 'FullCellInfo', position: int) -> torch.Tensor:\n",
    "        \"\"\"Récupère l'embedding d'une position spécifique\"\"\"\n",
    "        full_embedding = self.forward(cell)\n",
    "        \n",
    "        # Mapping des positions aux dimensions dans l'embedding final\n",
    "        position_slices = self._get_position_slices()\n",
    "        \n",
    "        if position in position_slices:\n",
    "            start, end = position_slices[position]\n",
    "            return full_embedding[start:end]\n",
    "        else:\n",
    "            raise ValueError(f\"Position {position} not found\")\n",
    "    \n",
    "    def _get_position_slices(self) -> Dict[int, Tuple[int, int]]:\n",
    "        \"\"\"Retourne les tranches d'embedding pour chaque position logique\"\"\"\n",
    "        slices = {}\n",
    "        offset = 0\n",
    "        \n",
    "        # Position 0: row\n",
    "        slices[0] = (offset, offset + self.config.position_embedding_dim)\n",
    "        offset += self.config.position_embedding_dim\n",
    "        \n",
    "        # Position 1: col  \n",
    "        slices[1] = (offset, offset + self.config.position_embedding_dim)\n",
    "        offset += self.config.position_embedding_dim\n",
    "        \n",
    "        # Position 2: type\n",
    "        slices[2] = (offset, offset + self.config.type_embedding_dim)\n",
    "        offset += self.config.type_embedding_dim\n",
    "        \n",
    "        # Position 3: value\n",
    "        slices[3] = (offset, offset + self.value_encoder.output_dim)\n",
    "        offset += self.value_encoder.output_dim\n",
    "        \n",
    "        # Et ainsi de suite...\n",
    "        return slices\n",
    "\n",
    "class ValueEncoder(nn.Module):\n",
    "    \"\"\"Encodeur spécialisé pour les valeurs de cellules avec gestion du contenu complexe\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.max_tokens = 8  # Nombre max de tokens pour le contenu\n",
    "        self.token_dim = 32   # Dimension par token\n",
    "        self.output_dim = self.max_tokens * self.token_dim  # 32 * 64 = 2048D\n",
    "        \n",
    "        # Tokenizer simple (remplacer par un vrai tokenizer)\n",
    "        self.vocab_size = 10000\n",
    "        self.token_embedding = nn.Embedding(self.vocab_size, self.token_dim)\n",
    "        \n",
    "        # Embeddings spéciaux\n",
    "        self.pad_token_id = 0\n",
    "        self.unk_token_id = 1\n",
    "        self.number_token_id = 2\n",
    "        self.formula_start_id = 3\n",
    "        \n",
    "        # Encodeur de position pour les tokens\n",
    "        self.token_position_embedding = nn.Embedding(self.max_tokens, self.token_dim)\n",
    "        \n",
    "        # Classification du type de contenu\n",
    "        self.content_type_embedding = nn.Embedding(4, self.token_dim)  # TEXT, NUMBER, FORMULA, EMPTY\n",
    "        \n",
    "    def forward(self, cell: 'FullCellInfo') -> torch.Tensor:\n",
    "        \"\"\"Encode la valeur en séquence de tokens\"\"\"\n",
    "        if mask_content:\n",
    "            # Pour le masked prediction\n",
    "            tokens = [self.mask_token_id] * self.max_tokens\n",
    "            content_type = 0\n",
    "        if cell.formula:\n",
    "            tokens = self._tokenize_formula(cell.formula)\n",
    "            content_type = 3  # FORMULA\n",
    "        elif cell.raw_value and cell.cell_type == 2:  # Number\n",
    "            tokens = self._tokenize_number(cell.raw_value)\n",
    "            content_type = 2  # NUMBER\n",
    "        elif cell.raw_value and cell.cell_type == 1:  # Text\n",
    "            tokens = self._tokenize_text(str(cell.raw_value))\n",
    "            content_type = 1  # TEXT\n",
    "        else:\n",
    "            tokens = [self.pad_token_id] * self.max_tokens\n",
    "            content_type = 0  # EMPTY\n",
    "        \n",
    "        # Padding/truncation à max_tokens\n",
    "        if len(tokens) > self.max_tokens:\n",
    "            tokens = tokens[:self.max_tokens]\n",
    "        else:\n",
    "            tokens.extend([self.pad_token_id] * (self.max_tokens - len(tokens)))\n",
    "        \n",
    "        # Convertir en embeddings\n",
    "        token_ids = torch.tensor(tokens)\n",
    "        token_embs = self.token_embedding(token_ids)  # [max_tokens, token_dim]\n",
    "        \n",
    "        # Ajouter encodage positionnel\n",
    "        positions = torch.arange(self.max_tokens)\n",
    "        pos_embs = self.token_position_embedding(positions)\n",
    "        \n",
    "        # Ajouter type de contenu à chaque token\n",
    "        content_type_emb = self.content_type_embedding(torch.tensor(content_type))\n",
    "        content_type_emb = content_type_emb.unsqueeze(0).expand(self.max_tokens, -1)\n",
    "        \n",
    "        # Combiner\n",
    "        combined_embs = token_embs + pos_embs + content_type_emb  # [max_tokens, token_dim]\n",
    "        \n",
    "        # Aplatir pour la sortie\n",
    "        return combined_embs.flatten()  # [max_tokens * token_dim]\n",
    "    \n",
    "    def _tokenize_text(self, text: str) -> List[int]:\n",
    "        \"\"\"Tokenise le texte (placeholder - utiliser un vrai tokenizer)\"\"\"\n",
    "        # Simplification: split par mots et hash\n",
    "        words = text.lower().split()[:self.max_tokens]\n",
    "        tokens = []\n",
    "        for word in words:\n",
    "            token_id = (hash(word) % (self.vocab_size - 10)) + 10  # Éviter les tokens spéciaux\n",
    "            tokens.append(token_id)\n",
    "        return tokens\n",
    "    \n",
    "    def _tokenize_number(self, value: Any) -> List[int]:\n",
    "        \"\"\"Tokenise un nombre\"\"\"\n",
    "        try:\n",
    "            num_str = str(float(value))\n",
    "            # Séparer en caractères pour une représentation fine\n",
    "            tokens = [self.number_token_id]  # Token de début de nombre\n",
    "            for char in num_str[:self.max_tokens-1]:\n",
    "                if char.isdigit():\n",
    "                    tokens.append(ord(char) - ord('0') + 4)  # Chiffres 0-9 → IDs 4-13\n",
    "                elif char == '.':\n",
    "                    tokens.append(14)  # Point décimal\n",
    "                elif char == '-':\n",
    "                    tokens.append(15)  # Signe négatif\n",
    "                elif char == 'e' or char == 'E':\n",
    "                    tokens.append(16)  # Notation scientifique\n",
    "            return tokens\n",
    "        except:\n",
    "            return [self.unk_token_id]\n",
    "    \n",
    "    def _tokenize_formula(self, formula: str) -> List[int]:\n",
    "        \"\"\"Tokenise une formule Excel\"\"\"\n",
    "        tokens = [self.formula_start_id]  # Token de début de formule\n",
    "        \n",
    "        # Simplification: tokenisation caractère par caractère pour les opérateurs\n",
    "        # En réalité, utiliser un parser Excel\n",
    "        i = 0\n",
    "        while i < len(formula) and len(tokens) < self.max_tokens:\n",
    "            char = formula[i]\n",
    "            \n",
    "            if char.isalpha():\n",
    "                # Fonction ou référence de cellule\n",
    "                word = \"\"\n",
    "                while i < len(formula) and (formula[i].isalnum() or formula[i] in \".$\"):\n",
    "                    word += formula[i]\n",
    "                    i += 1\n",
    "                token_id = (hash(word.upper()) % (self.vocab_size - 100)) + 100\n",
    "                tokens.append(token_id)\n",
    "                continue\n",
    "            elif char.isdigit():\n",
    "                # Nombre dans la formule\n",
    "                num = \"\"\n",
    "                while i < len(formula) and (formula[i].isdigit() or formula[i] == '.'):\n",
    "                    num += formula[i]\n",
    "                    i += 1\n",
    "                token_id = (hash(num) % (self.vocab_size - 200)) + 200\n",
    "                tokens.append(token_id)\n",
    "                continue\n",
    "            else:\n",
    "                # Opérateur ou symbole\n",
    "                token_map = {\n",
    "                    '+': 17, '-': 18, '*': 19, '/': 20, '=': 21, \n",
    "                    '(': 22, ')': 23, ',': 24, ':': 25, ';': 26,\n",
    "                    '<': 27, '>': 28, '&': 29, '^': 30\n",
    "                }\n",
    "                tokens.append(token_map.get(char, self.unk_token_id))\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "class MergeEncoder(nn.Module):\n",
    "    \"\"\"Encodeur pour les informations de fusion\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.output_dim = 32\n",
    "        \n",
    "        # Embeddings pour les coordonnées de fusion\n",
    "        self.merge_coord_embedding = nn.Embedding(config.max_position, 8)\n",
    "        self.merge_projection = nn.Linear(4 * 8, self.output_dim)\n",
    "        self.no_merge_embedding = nn.Parameter(torch.randn(self.output_dim))\n",
    "    \n",
    "    def forward(self, cell: 'FullCellInfo') -> torch.Tensor:\n",
    "        \"\"\"Encode les informations de fusion\"\"\"\n",
    "        if not cell.is_merged:\n",
    "            return self.no_merge_embedding\n",
    "        \n",
    "        sr, er, sc, ec = cell.merge_range\n",
    "        \n",
    "        # Limiter les coordonnées\n",
    "        sr = min(sr, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        er = min(er, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        sc = min(sc, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        ec = min(ec, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        \n",
    "        # Embeddings des coordonnées\n",
    "        sr_emb = self.merge_coord_embedding(torch.tensor(sr))\n",
    "        er_emb = self.merge_coord_embedding(torch.tensor(er))\n",
    "        sc_emb = self.merge_coord_embedding(torch.tensor(sc))\n",
    "        ec_emb = self.merge_coord_embedding(torch.tensor(ec))\n",
    "        \n",
    "        # Concaténer et projeter\n",
    "        merge_vec = torch.cat([sr_emb, er_emb, sc_emb, ec_emb])\n",
    "        return self.merge_projection(merge_vec)\n",
    "\n",
    "class ExcelSheetEmbedder(nn.Module):\n",
    "    \"\"\"Embedder pour des feuilles entières\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.cell_embedder = ExcelCellEmbedder(config)\n",
    "        self.position_encoder = PositionalEncoder(config.embedding_dim)\n",
    "        \n",
    "    def forward(self, cells: List['FullCellInfo'], max_cells: Optional[int] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Embed une feuille entière\n",
    "        \n",
    "        Args:\n",
    "            cells: Liste de cellules\n",
    "            max_cells: Nombre maximum de cellules (pour padding)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor [num_cells, embedding_dim] ou [max_cells, embedding_dim]\n",
    "        \"\"\"\n",
    "        # Trier par position\n",
    "        sorted_cells = sorted(cells, key=lambda c: (c.row, c.col))\n",
    "        \n",
    "        if max_cells:\n",
    "            # Padding ou troncature\n",
    "            if len(sorted_cells) > max_cells:\n",
    "                sorted_cells = sorted_cells[:max_cells]\n",
    "            elif len(sorted_cells) < max_cells:\n",
    "                # Créer des cellules vides pour le padding\n",
    "                empty_cell = self._create_empty_cell()\n",
    "                sorted_cells.extend([empty_cell] * (max_cells - len(sorted_cells)))\n",
    "        \n",
    "        # Embedder toutes les cellules\n",
    "        cell_embeddings = self.cell_embedder(sorted_cells)\n",
    "        \n",
    "        # Ajouter l'encodage positionnel\n",
    "        positioned_embeddings = self.position_encoder(cell_embeddings)\n",
    "        \n",
    "        return positioned_embeddings\n",
    "    \n",
    "    def _create_empty_cell(self) -> 'FullCellInfo':\n",
    "        \"\"\"Crée une cellule vide pour le padding\"\"\"\n",
    "        # Retourner une cellule avec toutes les valeurs par défaut\n",
    "        # Cette implémentation dépend de votre classe FullCellInfo\n",
    "        pass\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    \"\"\"Encodage positionnel pour les séquences de cellules\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int, max_length: int = 10000):\n",
    "        super().__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_length, embedding_dim)\n",
    "        position = torch.arange(0, max_length).unsqueeze(1).float()\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() *\n",
    "                           -(np.log(10000.0) / embedding_dim))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Ajoute l'encodage positionnel\"\"\"\n",
    "        seq_len = x.size(0)\n",
    "        return x + self.pe[:seq_len]\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    config = EmbeddingConfig(\n",
    "        embedding_dim=256,\n",
    "        position_embedding_dim=32\n",
    "    )\n",
    "    \n",
    "    # Créer l'embedder\n",
    "    embedder = ExcelCellEmbedder(config)\n",
    "    \n",
    "    # Simuler une cellule (remplacer par votre vraie classe FullCellInfo)\n",
    "    from dataclasses import dataclass\n",
    "    from typing import Tuple\n",
    "    \n",
    "    @dataclass \n",
    "    class MockFullCellInfo:\n",
    "        raw_value: str = \"Hello\"\n",
    "        cell_type: int = 1\n",
    "        formula: str = \"\"\n",
    "        row: int = 5\n",
    "        col: int = 3\n",
    "        bold: bool = True\n",
    "        italic: bool = False\n",
    "        underline: bool = False\n",
    "        strike: bool = False\n",
    "        font_size: float = 12.0\n",
    "        font_family: str = \"Arial\"\n",
    "        text_color: str = \"#FF0000\"\n",
    "        background_color: str = \"#FFFFFF\"\n",
    "        horizontal_align: int = 1\n",
    "        vertical_align: int = 0\n",
    "        text_wrap: bool = False\n",
    "        text_rotation: int = 0\n",
    "        border_top: int = 1\n",
    "        border_bottom: int = 0\n",
    "        border_left: int = 0\n",
    "        border_right: int = 0\n",
    "        is_merged: bool = False\n",
    "        merge_range: Tuple[int, int, int, int] = (0, 0, 0, 0)\n",
    "    \n",
    "    # Créer une cellule test\n",
    "    cell = MockFullCellInfo()\n",
    "    \n",
    "    # Obtenir l'embedding\n",
    "    with torch.no_grad():\n",
    "        embedding = embedder(cell)\n",
    "        print(f\"Embedding shape: {embedding.shape}\")\n",
    "        print(f\"Embedding (premiers 10 éléments): {embedding[:10]}\")\n",
    "        \n",
    "        # Test avec plusieurs cellules\n",
    "        cells = [cell, cell, cell]\n",
    "        batch_embedding = embedder(cells)\n",
    "        print(f\"Batch embedding shape: {batch_embedding.shape}\")\n",
    "        \n",
    "        # Nombre de paramètres\n",
    "        total_params = sum(p.numel() for p in embedder.parameters())\n",
    "        print(f\"Nombre total de paramètres: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21174b58-7057-4add-9cb3-96aff6f70f20",
   "metadata": {},
   "source": [
    "Création du Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71749465-3df3-4bc5-8858-c6b5ed01a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeType(Enum):\n",
    "    \"\"\"Types d'arêtes dans le graphe Excel\"\"\"\n",
    "    # Relations spatiales\n",
    "    SAME_ROW = \"same_row\"\n",
    "    SAME_COL = \"same_col\"\n",
    "    ADJACENT_RIGHT = \"adjacent_right\"\n",
    "    ADJACENT_DOWN = \"adjacent_down\"\n",
    "    ADJACENT_DIAG = \"adjacent_diag\"\n",
    "    \n",
    "    # Relations de distance\n",
    "    NEAR_2 = \"near_2\"      # Distance 2\n",
    "    NEAR_3 = \"near_3\"      # Distance 3\n",
    "    NEAR_5 = \"near_5\"      # Distance 5\n",
    "    FAR = \"far\"            # Distance > 5\n",
    "    \n",
    "    # Relations de dépendance\n",
    "    FORMULA_REF = \"formula_ref\"           # A1 référence B1 dans une formule\n",
    "    FORMULA_RANGE = \"formula_range\"       # Formule utilise une plage (A1:B5)\n",
    "    FORMULA_INDIRECT = \"formula_indirect\" # Référence indirecte (INDIRECT, etc.)\n",
    "    CROSS_SHEET_REF = \"cross_sheet_ref\"   # Référence entre feuilles (Sheet2!A1)\n",
    "    \n",
    "    # Relations structurelles\n",
    "    MERGED_CELL = \"merged_cell\"      # Cellules fusionnées\n",
    "    SAME_STYLE = \"same_style\"        # Même style appliqué\n",
    "    SAME_VALUE_TYPE = \"same_value_type\"  # Même type de valeur\n",
    "    \n",
    "    # Relations de feuille\n",
    "    SAME_SHEET = \"same_sheet\"        # Appartiennent à la même feuille\n",
    "    CROSS_SHEET = \"cross_sheet\"      # Appartiennent à des feuilles différentes\n",
    "    \n",
    "    # Relations de plage\n",
    "    RANGE_START = \"range_start\"      # Début de plage\n",
    "    RANGE_END = \"range_end\"          # Fin de plage\n",
    "    RANGE_MEMBER = \"range_member\"    # Membre d'une plage\n",
    "\n",
    "@dataclass\n",
    "class GraphEdge:\n",
    "    \"\"\"Représente une arête dans le graphe Excel\"\"\"\n",
    "    source_idx: int           # Index de la cellule source\n",
    "    target_idx: int           # Index de la cellule cible\n",
    "    edge_type: EdgeType       # Type de relation\n",
    "    weight: float = 1.0       # Poids de l'arête\n",
    "    metadata: Dict[str, Any] = None  # Métadonnées additionnelles\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.metadata is None:\n",
    "            self.metadata = {}\n",
    "\n",
    "@dataclass\n",
    "class ExcelGraph:\n",
    "    \"\"\"Représente le graphe Excel avec cellules et arêtes\"\"\"\n",
    "    cell_embeddings: torch.Tensor      # [num_cells, embedding_dim]\n",
    "    edge_embeddings: torch.Tensor      # [num_edges, edge_embedding_dim]\n",
    "    edge_indices: torch.Tensor         # [2, num_edges] - format PyG\n",
    "    edge_types: List[EdgeType]         # Type de chaque arête\n",
    "    edge_weights: torch.Tensor         # [num_edges] - poids des arêtes\n",
    "    cell_positions: List[Tuple[int, int]]  # [(row, col)] positions originales\n",
    "    \n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        return self.cell_embeddings.size(0)\n",
    "    \n",
    "    @property\n",
    "    def num_edges(self) -> int:\n",
    "        return self.edge_embeddings.size(0)\n",
    "\n",
    "class ExcelGraphBuilder:\n",
    "    \"\"\"Construit le graphe de relations entre cellules Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 max_distance: int = 5,\n",
    "                 include_spatial: bool = True,\n",
    "                 include_formula_deps: bool = True,\n",
    "                 include_structural: bool = True,\n",
    "                 include_sheet_relations: bool = True,\n",
    "                 same_style_threshold: float = 0.8,\n",
    "                 cross_sheet_weight: float = 0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_distance: Distance maximale pour les arêtes spatiales\n",
    "            include_spatial: Inclure les relations spatiales\n",
    "            include_formula_deps: Inclure les dépendances de formules\n",
    "            include_structural: Inclure les relations structurelles\n",
    "            include_sheet_relations: Inclure les relations de feuille\n",
    "            same_style_threshold: Seuil pour considérer des styles similaires\n",
    "            cross_sheet_weight: Poids pour les relations inter-feuilles\n",
    "        \"\"\"\n",
    "        self.max_distance = max_distance\n",
    "        self.include_spatial = include_spatial\n",
    "        self.include_formula_deps = include_formula_deps\n",
    "        self.include_structural = include_structural\n",
    "        self.include_sheet_relations = include_sheet_relations\n",
    "        self.same_style_threshold = same_style_threshold\n",
    "        self.cross_sheet_weight = cross_sheet_weight\n",
    "    \n",
    "    def build_graph(self, cells: List['FullCellInfo']) -> Tuple[List[GraphEdge], Dict[Tuple[str, int, int], int]]:\n",
    "        \"\"\"\n",
    "        Construit le graphe de relations entre cellules\n",
    "        \n",
    "        Args:\n",
    "            cells: Liste des cellules Excel\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[edges, position_to_index_map] - position inclut maintenant sheet_name\n",
    "        \"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        # Créer un mapping (sheet, row, col) -> index\n",
    "        pos_to_idx = {(cell.sheet_name, cell.row, cell.col): i for i, cell in enumerate(cells)}\n",
    "        \n",
    "        # 1. Relations de feuille (en premier pour établir le contexte)\n",
    "        if self.include_sheet_relations:\n",
    "            edges.extend(self._build_sheet_relation_edges(cells, pos_to_idx))\n",
    "        \n",
    "        # 2. Relations spatiales (seulement dans la même feuille)\n",
    "        if self.include_spatial:\n",
    "            edges.extend(self._build_spatial_edges(cells, pos_to_idx))\n",
    "        \n",
    "        # 3. Relations de dépendance (formules - incluant cross-sheet)\n",
    "        if self.include_formula_deps:\n",
    "            edges.extend(self._build_formula_dependency_edges(cells, pos_to_idx))\n",
    "        \n",
    "        # 4. Relations structurelles\n",
    "        if self.include_structural:\n",
    "            edges.extend(self._build_structural_edges(cells, pos_to_idx))\n",
    "        \n",
    "        return edges, pos_to_idx\n",
    "    \n",
    "    def _build_sheet_relation_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur l'appartenance aux feuilles\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        # Grouper les cellules par feuille\n",
    "        sheets = {}\n",
    "        for i, cell in enumerate(cells):\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append(i)\n",
    "        \n",
    "        # Relations intra-feuille (SAME_SHEET)\n",
    "        for sheet_name, cell_indices in sheets.items():\n",
    "            for i in range(len(cell_indices)):\n",
    "                for j in range(i + 1, len(cell_indices)):\n",
    "                    idx_i, idx_j = cell_indices[i], cell_indices[j]\n",
    "                    edges.append(GraphEdge(\n",
    "                        idx_i, idx_j, \n",
    "                        EdgeType.SAME_SHEET, \n",
    "                        weight=1.0,\n",
    "                        metadata={'sheet_name': sheet_name}\n",
    "                    ))\n",
    "        \n",
    "        # Relations inter-feuilles (CROSS_SHEET)\n",
    "        sheet_names = list(sheets.keys())\n",
    "        for i in range(len(sheet_names)):\n",
    "            for j in range(i + 1, len(sheet_names)):\n",
    "                sheet_i, sheet_j = sheet_names[i], sheet_names[j]\n",
    "                cells_i, cells_j = sheets[sheet_i], sheets[sheet_j]\n",
    "                \n",
    "                # Connecter toutes les cellules entre feuilles différentes\n",
    "                # (peut être coûteux - limiter si nécessaire)\n",
    "                for cell_idx_i in cells_i[:10]:  # Limiter à 10 cellules par feuille\n",
    "                    for cell_idx_j in cells_j[:10]:\n",
    "                        edges.append(GraphEdge(\n",
    "                            cell_idx_i, cell_idx_j,\n",
    "                            EdgeType.CROSS_SHEET,\n",
    "                            weight=self.cross_sheet_weight,\n",
    "                            metadata={\n",
    "                                'sheet_i': sheet_i,\n",
    "                                'sheet_j': sheet_j\n",
    "                            }\n",
    "                        ))\n",
    "        \n",
    "        return edges\n",
    "    \n",
    "    def _build_spatial_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur les relations spatiales (dans la même feuille uniquement)\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        # Grouper par feuille pour éviter les relations spatiales inter-feuilles\n",
    "        sheets = {}\n",
    "        for i, cell in enumerate(cells):\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append((i, cell))\n",
    "        \n",
    "        # Construire les relations spatiales pour chaque feuille séparément\n",
    "        for sheet_name, sheet_cells in sheets.items():\n",
    "            for i, (idx_i, cell_i) in enumerate(sheet_cells):\n",
    "                for j, (idx_j, cell_j) in enumerate(sheet_cells):\n",
    "                    if i >= j:  # Éviter les doublons\n",
    "                        continue\n",
    "                    \n",
    "                    row_i, col_i = cell_i.row, cell_i.col\n",
    "                    row_j, col_j = cell_j.row, cell_j.col\n",
    "                    \n",
    "                    # Distance Manhattan\n",
    "                    distance = abs(row_i - row_j) + abs(col_i - col_j)\n",
    "                    \n",
    "                    if distance > self.max_distance:\n",
    "                        # Relation \"far\" (même feuille)\n",
    "                        edges.append(GraphEdge(\n",
    "                            idx_i, idx_j, EdgeType.FAR, \n",
    "                            weight=1.0/distance,\n",
    "                            metadata={'sheet_name': sheet_name}\n",
    "                        ))\n",
    "                        continue\n",
    "                    \n",
    "                    # Relations spécifiques\n",
    "                    if row_i == row_j and col_i != col_j:\n",
    "                        # Même ligne\n",
    "                        edges.append(GraphEdge(\n",
    "                            idx_i, idx_j, EdgeType.SAME_ROW, \n",
    "                            weight=1.0,\n",
    "                            metadata={'sheet_name': sheet_name, 'row': row_i}\n",
    "                        ))\n",
    "                        \n",
    "                        # Adjacent horizontal\n",
    "                        if abs(col_i - col_j) == 1:\n",
    "                            edges.append(GraphEdge(idx_i, idx_j, EdgeType.ADJACENT_RIGHT, weight=1.0))\n",
    "                    \n",
    "                    elif col_i == col_j and row_i != row_j:\n",
    "                        # Même colonne\n",
    "                        edges.append(GraphEdge(\n",
    "                            idx_i, idx_j, EdgeType.SAME_COL, \n",
    "                            weight=1.0,\n",
    "                            metadata={'sheet_name': sheet_name, 'col': col_i}\n",
    "                        ))\n",
    "                        \n",
    "                        # Adjacent vertical\n",
    "                        if abs(row_i - row_j) == 1:\n",
    "                            edges.append(GraphEdge(idx_i, idx_j, EdgeType.ADJACENT_DOWN, weight=1.0))\n",
    "                    \n",
    "                    elif distance == 2 and abs(row_i - row_j) == 1 and abs(col_i - col_j) == 1:\n",
    "                        # Adjacent diagonal\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.ADJACENT_DIAG, weight=0.7))\n",
    "                    \n",
    "                    # Relations de distance\n",
    "                    elif distance == 2:\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.NEAR_2, weight=0.5))\n",
    "                    elif distance == 3:\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.NEAR_3, weight=0.3))\n",
    "                    elif distance <= 5:\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.NEAR_5, weight=0.1))\n",
    "        \n",
    "        return edges\n",
    "    \n",
    "    def _build_formula_dependency_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur les dépendances de formules (incluant cross-sheet)\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            if not cell.formula:\n",
    "                continue\n",
    "            \n",
    "            # Parser les références dans la formule\n",
    "            references = self._parse_formula_references(cell.formula, cell.sheet_name)\n",
    "            \n",
    "            for ref in references:\n",
    "                if ref['type'] == 'cell':\n",
    "                    # Référence à une cellule (même feuille ou autre)\n",
    "                    target_pos = (ref['sheet'], ref['row'], ref['col'])\n",
    "                    if target_pos in pos_to_idx:\n",
    "                        j = pos_to_idx[target_pos]\n",
    "                        edge_type = EdgeType.CROSS_SHEET_REF if ref['sheet'] != cell.sheet_name else EdgeType.FORMULA_REF\n",
    "                        weight = 0.8 if ref['sheet'] != cell.sheet_name else 1.0\n",
    "                        \n",
    "                        edges.append(GraphEdge(\n",
    "                            i, j, edge_type, \n",
    "                            weight=weight,\n",
    "                            metadata={\n",
    "                                'formula_ref': ref['text'],\n",
    "                                'source_sheet': cell.sheet_name,\n",
    "                                'target_sheet': ref['sheet']\n",
    "                            }\n",
    "                        ))\n",
    "                \n",
    "                elif ref['type'] == 'range':\n",
    "                    # Référence à une plage\n",
    "                    start_row, start_col = ref['start_row'], ref['start_col']\n",
    "                    end_row, end_col = ref['end_row'], ref['end_col']\n",
    "                    \n",
    "                    for row in range(start_row, end_row + 1):\n",
    "                        for col in range(start_col, end_col + 1):\n",
    "                            target_pos = (ref['sheet'], row, col)\n",
    "                            if target_pos in pos_to_idx:\n",
    "                                j = pos_to_idx[target_pos]\n",
    "                                edge_type = EdgeType.CROSS_SHEET_REF if ref['sheet'] != cell.sheet_name else EdgeType.FORMULA_RANGE\n",
    "                                weight = 0.4 if ref['sheet'] != cell.sheet_name else 0.5\n",
    "                                \n",
    "                                edges.append(GraphEdge(\n",
    "                                    i, j, edge_type,\n",
    "                                    weight=weight,\n",
    "                                    metadata={\n",
    "                                        'formula_range': ref['text'],\n",
    "                                        'source_sheet': cell.sheet_name,\n",
    "                                        'target_sheet': ref['sheet']\n",
    "                                    }\n",
    "                                ))\n",
    "                \n",
    "                elif ref['type'] == 'indirect':\n",
    "                    # Référence indirecte (plus complexe à analyser)\n",
    "                    edges.append(GraphEdge(\n",
    "                        i, i, EdgeType.FORMULA_INDIRECT, \n",
    "                        weight=0.3,\n",
    "                        metadata={'indirect_ref': ref['text']}\n",
    "                    ))\n",
    "        \n",
    "        return edges\n",
    "    \n",
    "    def _parse_formula_references(self, formula: str, current_sheet: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Parse les références dans une formule Excel (incluant cross-sheet)\"\"\"\n",
    "        references = []\n",
    "        \n",
    "        # Pattern pour les références cross-sheet (Sheet1!A1, 'Sheet Name'!A1)\n",
    "        cross_sheet_pattern = r\"(?:'([^']+)'|([^!\\s]+))!(\\$?[A-Z]+\\$?\\d+)\"\n",
    "        cross_sheet_matches = re.finditer(cross_sheet_pattern, formula.upper())\n",
    "        \n",
    "        for match in cross_sheet_matches:\n",
    "            sheet_name_quoted, sheet_name_simple, cell_ref = match.groups()\n",
    "            sheet_name = sheet_name_quoted or sheet_name_simple\n",
    "            \n",
    "            # Parser la référence de cellule\n",
    "            cell_match = re.match(r'\\$?([A-Z]+)\\$?(\\d+)', cell_ref)\n",
    "            if cell_match:\n",
    "                col_str, row_str = cell_match.groups()\n",
    "                col = self._col_str_to_num(col_str)\n",
    "                row = int(row_str) - 1\n",
    "                \n",
    "                references.append({\n",
    "                    'type': 'cell',\n",
    "                    'sheet': sheet_name,\n",
    "                    'row': row,\n",
    "                    'col': col,\n",
    "                    'text': match.group(0)\n",
    "                })\n",
    "        \n",
    "        # Pattern pour les plages cross-sheet (Sheet1!A1:B5)\n",
    "        cross_sheet_range_pattern = r\"(?:'([^']+)'|([^!\\s]+))!(\\$?[A-Z]+\\$?\\d+:\\$?[A-Z]+\\$?\\d+)\"\n",
    "        cross_sheet_range_matches = re.finditer(cross_sheet_range_pattern, formula.upper())\n",
    "        \n",
    "        for match in cross_sheet_range_matches:\n",
    "            sheet_name_quoted, sheet_name_simple, range_ref = match.groups()\n",
    "            sheet_name = sheet_name_quoted or sheet_name_simple\n",
    "            \n",
    "            # Parser la plage\n",
    "            range_match = re.match(r'\\$?([A-Z]+)\\$?(\\d+):\\$?([A-Z]+)\\$?(\\d+)', range_ref)\n",
    "            if range_match:\n",
    "                start_col_str, start_row_str, end_col_str, end_row_str = range_match.groups()\n",
    "                start_col = self._col_str_to_num(start_col_str)\n",
    "                start_row = int(start_row_str) - 1\n",
    "                end_col = self._col_str_to_num(end_col_str)\n",
    "                end_row = int(end_row_str) - 1\n",
    "                \n",
    "                references.append({\n",
    "                    'type': 'range',\n",
    "                    'sheet': sheet_name,\n",
    "                    'start_row': start_row,\n",
    "                    'start_col': start_col,\n",
    "                    'end_row': end_row,\n",
    "                    'end_col': end_col,\n",
    "                    'text': match.group(0)\n",
    "                })\n",
    "        \n",
    "        # Pattern pour les références locales (A1, A1:B5 sans nom de feuille)\n",
    "        # Retirer d'abord les références cross-sheet pour éviter les doublons\n",
    "        formula_local = formula.upper()\n",
    "        for match in re.finditer(cross_sheet_pattern, formula_local):\n",
    "            formula_local = formula_local.replace(match.group(0), \"\")\n",
    "        for match in re.finditer(cross_sheet_range_pattern, formula_local):\n",
    "            formula_local = formula_local.replace(match.group(0), \"\")\n",
    "        \n",
    "        # Références de cellules locales\n",
    "        cell_pattern = r'\\$?([A-Z]+)\\$?(\\d+)'\n",
    "        cell_matches = re.finditer(cell_pattern, formula_local)\n",
    "        \n",
    "        for match in cell_matches:\n",
    "            col_str, row_str = match.groups()\n",
    "            col = self._col_str_to_num(col_str)\n",
    "            row = int(row_str) - 1\n",
    "            references.append({\n",
    "                'type': 'cell',\n",
    "                'sheet': current_sheet,\n",
    "                'row': row,\n",
    "                'col': col,\n",
    "                'text': match.group(0)\n",
    "            })\n",
    "        \n",
    "        # Plages locales\n",
    "        range_pattern = r'\\$?([A-Z]+)\\$?(\\d+):\\$?([A-Z]+)\\$?(\\d+)'\n",
    "        range_matches = re.finditer(range_pattern, formula_local)\n",
    "        \n",
    "        for match in range_matches:\n",
    "            start_col_str, start_row_str, end_col_str, end_row_str = match.groups()\n",
    "            start_col = self._col_str_to_num(start_col_str)\n",
    "            start_row = int(start_row_str) - 1\n",
    "            end_col = self._col_str_to_num(end_col_str)\n",
    "            end_row = int(end_row_str) - 1\n",
    "            \n",
    "            references.append({\n",
    "                'type': 'range',\n",
    "                'sheet': current_sheet,\n",
    "                'start_row': start_row,\n",
    "                'start_col': start_col,\n",
    "                'end_row': end_row,\n",
    "                'end_col': end_col,\n",
    "                'text': match.group(0)\n",
    "            })\n",
    "        \n",
    "        # Fonctions indirectes\n",
    "        indirect_pattern = r'INDIRECT\\s*\\([^)]+\\)'\n",
    "        indirect_matches = re.finditer(indirect_pattern, formula.upper())\n",
    "        \n",
    "        for match in indirect_matches:\n",
    "            references.append({\n",
    "                'type': 'indirect',\n",
    "                'text': match.group(0)\n",
    "            })\n",
    "        \n",
    "        return references\n",
    "    \n",
    "    def _col_str_to_num(self, col_str: str) -> int:\n",
    "        \"\"\"Convertit une colonne string (A, B, ..., AA, AB) en nombre\"\"\"\n",
    "        result = 0\n",
    "        for char in col_str:\n",
    "            result = result * 26 + (ord(char) - ord('A') + 1)\n",
    "        return result - 1  # Convert to 0-based\n",
    "    \n",
    "    def _build_structural_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur les relations structurelles\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        for i, cell_i in enumerate(cells):\n",
    "            for j, cell_j in enumerate(cells):\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                \n",
    "                # Cellules fusionnées\n",
    "                if cell_i.is_merged and cell_j.is_merged:\n",
    "                    if cell_i.merge_range == cell_j.merge_range:\n",
    "                        edges.append(GraphEdge(i, j, EdgeType.MERGED_CELL, weight=1.0))\n",
    "                \n",
    "                # Même style (simplifié - comparer style_id)\n",
    "                if cell_i.style_id and cell_j.style_id and cell_i.style_id == cell_j.style_id:\n",
    "                    edges.append(GraphEdge(i, j, EdgeType.SAME_STYLE, weight=0.8))\n",
    "                \n",
    "                # Même type de valeur\n",
    "                if cell_i.cell_type == cell_j.cell_type and cell_i.cell_type != 0:  # Pas vide\n",
    "                    edges.append(GraphEdge(i, j, EdgeType.SAME_VALUE_TYPE, weight=0.4))\n",
    "        \n",
    "        return edges\n",
    "\n",
    "class EdgeEmbedder(nn.Module):\n",
    "    \"\"\"Embedder pour les arêtes du graphe\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Embedding par type d'arête\n",
    "        num_edge_types = len(EdgeType)\n",
    "        self.edge_type_embedding = nn.Embedding(num_edge_types, embedding_dim)\n",
    "        \n",
    "        # Embedding pour les poids (discrétisés)\n",
    "        self.weight_bins = 20\n",
    "        self.weight_embedding = nn.Embedding(self.weight_bins, embedding_dim // 4)\n",
    "        \n",
    "        # Projection finale\n",
    "        self.projection = nn.Linear(embedding_dim + embedding_dim // 4, embedding_dim)\n",
    "        \n",
    "        # Mapping des types vers des IDs\n",
    "        self.edge_type_to_id = {edge_type: i for i, edge_type in enumerate(EdgeType)}\n",
    "    \n",
    "    def forward(self, edge_types: List[EdgeType], edge_weights: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Embed les arêtes\n",
    "        \n",
    "        Args:\n",
    "            edge_types: Liste des types d'arêtes\n",
    "            edge_weights: Poids des arêtes [num_edges]\n",
    "            \n",
    "        Returns:\n",
    "            Embeddings des arêtes [num_edges, embedding_dim]\n",
    "        \"\"\"\n",
    "        # Convertir types en IDs\n",
    "        type_ids = torch.tensor([self.edge_type_to_id[et] for et in edge_types])\n",
    "        type_embeddings = self.edge_type_embedding(type_ids)\n",
    "        \n",
    "        # Discrétiser les poids\n",
    "        weight_bins = torch.clamp(\n",
    "            (edge_weights * self.weight_bins).long(), \n",
    "            0, self.weight_bins - 1\n",
    "        )\n",
    "        weight_embeddings = self.weight_embedding(weight_bins)\n",
    "        \n",
    "        # Combiner\n",
    "        combined = torch.cat([type_embeddings, weight_embeddings], dim=1)\n",
    "        return self.projection(combined)\n",
    "\n",
    "class ExcelGraphEmbedder(nn.Module):\n",
    "    \"\"\"Embedder complet pour les graphes Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, cell_embedder: ExcelCellEmbedder, edge_embedding_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.cell_embedder = cell_embedder\n",
    "        self.edge_embedder = EdgeEmbedder(edge_embedding_dim)\n",
    "        self.graph_builder = ExcelGraphBuilder()\n",
    "        \n",
    "    def forward(self, cells: List['FullCellInfo']) -> ExcelGraph:\n",
    "        \"\"\"\n",
    "        Convertit une liste de cellules en graphe embedé\n",
    "        \n",
    "        Args:\n",
    "            cells: Liste des cellules Excel\n",
    "            \n",
    "        Returns:\n",
    "            ExcelGraph avec embeddings\n",
    "        \"\"\"\n",
    "        # 1. Embed les cellules\n",
    "        cell_embeddings = self.cell_embedder(cells)\n",
    "        \n",
    "        # 2. Construire le graphe\n",
    "        edges, pos_to_idx = self.graph_builder.build_graph(cells)\n",
    "        \n",
    "        if not edges:\n",
    "            # Graphe vide\n",
    "            return ExcelGraph(\n",
    "                cell_embeddings=cell_embeddings,\n",
    "                edge_embeddings=torch.empty(0, self.edge_embedder.embedding_dim),\n",
    "                edge_indices=torch.empty(2, 0, dtype=torch.long),\n",
    "                edge_types=[],\n",
    "                edge_weights=torch.empty(0),\n",
    "                cell_positions=[(cell.row, cell.col) for cell in cells]\n",
    "            )\n",
    "        \n",
    "        # 3. Préparer les données d'arêtes\n",
    "        edge_indices = torch.tensor([[e.source_idx, e.target_idx] for e in edges]).T\n",
    "        edge_types = [e.edge_type for e in edges]\n",
    "        edge_weights = torch.tensor([e.weight for e in edges])\n",
    "        \n",
    "        # 4. Embed les arêtes\n",
    "        edge_embeddings = self.edge_embedder(edge_types, edge_weights)\n",
    "        \n",
    "        # 5. Créer le graphe final\n",
    "        return ExcelGraph(\n",
    "            cell_embeddings=cell_embeddings,\n",
    "            edge_embeddings=edge_embeddings,\n",
    "            edge_indices=edge_indices,\n",
    "            edge_types=edge_types,\n",
    "            edge_weights=edge_weights,\n",
    "            cell_positions=[(cell.row, cell.col) for cell in cells]\n",
    "        )\n",
    "    \n",
    "    def get_edge_statistics(self, graph: ExcelGraph) -> Dict[str, int]:\n",
    "        \"\"\"Retourne des statistiques sur les types d'arêtes\"\"\"\n",
    "        stats = {}\n",
    "        for edge_type in graph.edge_types:\n",
    "            stats[edge_type.value] = stats.get(edge_type.value, 0) + 1\n",
    "        return stats\n",
    "\n",
    "# Exemple d'utilisation et tests\n",
    "if __name__ == \"__main__\":\n",
    "    # Simuler des cellules pour tester\n",
    "    from dataclasses import dataclass\n",
    "    from typing import Tuple\n",
    "    \n",
    "    @dataclass\n",
    "    class MockFullCellInfo:\n",
    "        raw_value: str = \"\"\n",
    "        cell_type: int = 0\n",
    "        formula: str = \"\"\n",
    "        row: int = 0\n",
    "        col: int = 0\n",
    "        sheet_name: str = \"Sheet1\"\n",
    "        style_id: str = \"\"\n",
    "        is_merged: bool = False\n",
    "        merge_range: Tuple[int, int, int, int] = (0, 0, 0, 0)\n",
    "        # Autres attributs...\n",
    "        bold: bool = False\n",
    "        italic: bool = False\n",
    "        underline: bool = False\n",
    "        strike: bool = False\n",
    "        font_size: float = 11.0\n",
    "        font_family: str = \"Calibri\"\n",
    "        text_color: str = \"#000000\"\n",
    "        background_color: str = \"#FFFFFF\"\n",
    "        horizontal_align: int = 0\n",
    "        vertical_align: int = 0\n",
    "        text_wrap: bool = False\n",
    "        text_rotation: int = 0\n",
    "        border_top: int = 0\n",
    "        border_bottom: int = 0\n",
    "        border_left: int = 0\n",
    "        border_right: int = 0\n",
    "    \n",
    "    # Créer des cellules de test avec multiple feuilles\n",
    "    cells = [\n",
    "        # Feuille 1\n",
    "        MockFullCellInfo(raw_value=\"A1\", row=0, col=0, cell_type=1, sheet_name=\"Sheet1\"),\n",
    "        MockFullCellInfo(raw_value=\"10\", row=0, col=1, cell_type=2, sheet_name=\"Sheet1\"),\n",
    "        MockFullCellInfo(raw_value=\"B1\", row=1, col=0, cell_type=1, sheet_name=\"Sheet1\"),\n",
    "        MockFullCellInfo(formula=\"=A1+B1\", row=1, col=1, cell_type=3, sheet_name=\"Sheet1\"),\n",
    "        \n",
    "        # Feuille 2\n",
    "        MockFullCellInfo(raw_value=\"Data\", row=0, col=0, cell_type=1, sheet_name=\"Sheet2\"),\n",
    "        MockFullCellInfo(raw_value=\"100\", row=0, col=1, cell_type=2, sheet_name=\"Sheet2\"),\n",
    "        MockFullCellInfo(formula=\"=Sheet1!A1*2\", row=1, col=0, cell_type=3, sheet_name=\"Sheet2\"),\n",
    "        \n",
    "        # Feuille 3 \n",
    "        MockFullCellInfo(formula=\"=SUM(Sheet1!A1:B2)\", row=0, col=0, cell_type=3, sheet_name=\"Sheet3\"),\n",
    "    ]\n",
    "    \n",
    "    # Créer le graph builder et tester\n",
    "    builder = ExcelGraphBuilder(include_sheet_relations=True)\n",
    "    edges, pos_to_idx = builder.build_graph(cells)\n",
    "    \n",
    "    print(f\"Nombre de cellules: {len(cells)}\")\n",
    "    print(f\"Nombre d'arêtes: {len(edges)}\")\n",
    "    print(f\"Nombre de feuilles: {len(set(cell.sheet_name for cell in cells))}\")\n",
    "    \n",
    "    print(f\"\\nPosition mapping (sheet, row, col) -> index:\")\n",
    "    for pos, idx in list(pos_to_idx.items())[:5]:\n",
    "        print(f\"  {pos} -> {idx}\")\n",
    "    \n",
    "    print(\"\\nArêtes par type:\")\n",
    "    edge_type_counts = {}\n",
    "    for edge in edges:\n",
    "        edge_type_counts[edge.edge_type.value] = edge_type_counts.get(edge.edge_type.value, 0) + 1\n",
    "    \n",
    "    for edge_type, count in sorted(edge_type_counts.items()):\n",
    "        print(f\"  {edge_type}: {count}\")\n",
    "    \n",
    "    print(\"\\nExemples d'arêtes de feuille:\")\n",
    "    sheet_edges = [e for e in edges if e.edge_type in [EdgeType.SAME_SHEET, EdgeType.CROSS_SHEET]]\n",
    "    for edge in sheet_edges[:5]:\n",
    "        source_cell = cells[edge.source_idx]\n",
    "        target_cell = cells[edge.target_idx]\n",
    "        print(f\"  {edge.edge_type.value}: \"\n",
    "              f\"{source_cell.sheet_name}!({source_cell.row},{source_cell.col}) -> \"\n",
    "              f\"{target_cell.sheet_name}!({target_cell.row},{target_cell.col}) \"\n",
    "              f\"[weight: {edge.weight:.2f}]\")\n",
    "    \n",
    "    print(\"\\nExemples de références cross-sheet:\")\n",
    "    cross_ref_edges = [e for e in edges if e.edge_type == EdgeType.CROSS_SHEET_REF]\n",
    "    for edge in cross_ref_edges:\n",
    "        source_cell = cells[edge.source_idx]\n",
    "        target_cell = cells[edge.target_idx]\n",
    "        metadata = edge.metadata or {}\n",
    "        print(f\"  {edge.edge_type.value}: \"\n",
    "              f\"{source_cell.sheet_name}!({source_cell.row},{source_cell.col}) -> \"\n",
    "              f\"{target_cell.sheet_name}!({target_cell.row},{target_cell.col}) \"\n",
    "              f\"[formula: {metadata.get('formula_ref', 'N/A')}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e0749-d488-44df-84d6-f2564967dfc7",
   "metadata": {},
   "source": [
    "Fonction pour transformer un/des json en GraphEmbedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48e8db-f591-413d-95f7-d005879625b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONToGraphTransformer:\n",
    "    \"\"\"Transforme un JSON Excel en GraphEmbedded\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embedding_config: Optional['EmbeddingConfig'] = None,\n",
    "                 max_cells_per_sheet: int = 1000,\n",
    "                 include_empty_cells: bool = False,\n",
    "                 graph_config: Optional[Dict[str, Any]] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_config: Configuration pour l'embedder\n",
    "            max_cells_per_sheet: Limite de cellules par feuille\n",
    "            include_empty_cells: Inclure les cellules vides\n",
    "            graph_config: Configuration pour le graph builder\n",
    "        \"\"\"\n",
    "        # Configuration par défaut\n",
    "        if embedding_config is None:\n",
    "            embedding_config = EmbeddingConfig(\n",
    "                embedding_dim=256,\n",
    "                position_embedding_dim=32,\n",
    "                max_position=10000,\n",
    "                color_vocab_size=1000\n",
    "            )\n",
    "        \n",
    "        if graph_config is None:\n",
    "            graph_config = {\n",
    "                'max_distance': 5,\n",
    "                'include_spatial': True,\n",
    "                'include_formula_deps': True,\n",
    "                'include_structural': True,\n",
    "                'include_sheet_relations': True,\n",
    "                'cross_sheet_weight': 0.3\n",
    "            }\n",
    "        \n",
    "        self.embedding_config = embedding_config\n",
    "        self.max_cells_per_sheet = max_cells_per_sheet\n",
    "        self.include_empty_cells = include_empty_cells\n",
    "        self.graph_config = graph_config\n",
    "        \n",
    "        # Initialiser les composants\n",
    "        self.cell_embedder = ExcelCellEmbedder(embedding_config)\n",
    "        self.graph_embedder = ExcelGraphEmbedder(\n",
    "            self.cell_embedder, \n",
    "            edge_embedding_dim=64\n",
    "        )\n",
    "        \n",
    "        # Configurer le graph builder\n",
    "        self.graph_embedder.graph_builder = ExcelGraphBuilder(**graph_config)\n",
    "    \n",
    "    def transform(self, \n",
    "                  json_data: Union[str, Dict[str, Any]], \n",
    "                  filter_sheets: Optional[List[str]] = None,\n",
    "                  max_total_cells: Optional[int] = None) -> 'ExcelGraph':\n",
    "        \"\"\"\n",
    "        Transforme un JSON Excel en ExcelGraph\n",
    "        \n",
    "        Args:\n",
    "            json_data: JSON string ou dict contenant les données Excel\n",
    "            filter_sheets: Liste des noms de feuilles à inclure (None = toutes)\n",
    "            max_total_cells: Limite totale de cellules (None = pas de limite)\n",
    "            \n",
    "        Returns:\n",
    "            ExcelGraph avec embeddings\n",
    "        \"\"\"\n",
    "        # 1. Parser le JSON\n",
    "        if isinstance(json_data, str):\n",
    "            excel_data = json.loads(json_data)\n",
    "        else:\n",
    "            excel_data = json_data\n",
    "        \n",
    "        # 2. Extraire les cellules\n",
    "        all_cells = self._extract_cells_from_json(excel_data, filter_sheets)\n",
    "        \n",
    "        # 3. Filtrer et limiter les cellules\n",
    "        filtered_cells = self._filter_cells(all_cells, max_total_cells)\n",
    "        \n",
    "        # 4. Transformer en graphe embedé\n",
    "        excel_graph = self.graph_embedder(filtered_cells)\n",
    "        \n",
    "        return excel_graph\n",
    "    \n",
    "    def _extract_cells_from_json(self, \n",
    "                                 excel_data: Dict[str, Any], \n",
    "                                 filter_sheets: Optional[List[str]] = None) -> List['FullCellInfo']:\n",
    "        \"\"\"Extrait les cellules du JSON Excel\"\"\"\n",
    "        try:\n",
    "            # Utiliser le parser existant\n",
    "            all_cells = ExcelParser.parse_excel_json(excel_data)\n",
    "            \n",
    "            # S'assurer qu'on a une liste\n",
    "            if not isinstance(all_cells, list):\n",
    "                if all_cells is None:\n",
    "                    return []\n",
    "                # Si c'est un seul objet FullCellInfo, le mettre dans une liste\n",
    "                return [all_cells]\n",
    "            \n",
    "            # Filtrer par feuilles si spécifié\n",
    "            if filter_sheets:\n",
    "                all_cells = [cell for cell in all_cells if cell.sheet_name in filter_sheets]\n",
    "            \n",
    "            return all_cells\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du parsing JSON: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _filter_cells(self, \n",
    "                      cells: List['FullCellInfo'], \n",
    "                      max_total_cells: Optional[int] = None) -> List['FullCellInfo']:\n",
    "        \"\"\"Filtre et limite les cellules selon les critères\"\"\"\n",
    "        # Vérifier que cells est bien une liste\n",
    "        if not isinstance(cells, list):\n",
    "            if cells is None:\n",
    "                return []\n",
    "            return [cells]  # Convertir un seul objet en liste\n",
    "        \n",
    "        if not cells:  # Liste vide\n",
    "            return []\n",
    "        \n",
    "        filtered_cells = []\n",
    "        \n",
    "        # Grouper par feuille\n",
    "        sheets = {}\n",
    "        for cell in cells:\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append(cell)\n",
    "        \n",
    "        # Filtrer par feuille\n",
    "        for sheet_name, sheet_cells in sheets.items():\n",
    "            # Filtrer les cellules vides si nécessaire\n",
    "            if not self.include_empty_cells:\n",
    "                sheet_cells = [\n",
    "                    cell for cell in sheet_cells \n",
    "                    if cell.raw_value or cell.formula or cell.style_id or cell.is_merged\n",
    "                ]\n",
    "            \n",
    "            # Trier par priorité (formules > valeurs > style > vides)\n",
    "            sheet_cells.sort(key=self._cell_priority, reverse=True)\n",
    "            \n",
    "            # Limiter par feuille\n",
    "            if len(sheet_cells) > self.max_cells_per_sheet:\n",
    "                sheet_cells = sheet_cells[:self.max_cells_per_sheet]\n",
    "            \n",
    "            filtered_cells.extend(sheet_cells)\n",
    "        \n",
    "        # Limiter le total si spécifié\n",
    "        if max_total_cells and len(filtered_cells) > max_total_cells:\n",
    "            # Trier par priorité globale et prendre les plus importantes\n",
    "            filtered_cells.sort(key=self._cell_priority, reverse=True)\n",
    "            filtered_cells = filtered_cells[:max_total_cells]\n",
    "        \n",
    "        return filtered_cells\n",
    "    \n",
    "    def _cell_priority(self, cell: 'FullCellInfo') -> int:\n",
    "        \"\"\"Calcule la priorité d'une cellule pour le filtrage\"\"\"\n",
    "        priority = 0\n",
    "        \n",
    "        # Formules ont la plus haute priorité\n",
    "        if cell.formula:\n",
    "            priority += 1000\n",
    "        \n",
    "        # Cellules avec valeurs\n",
    "        if cell.raw_value:\n",
    "            priority += 500\n",
    "            \n",
    "            # Bonus selon le type\n",
    "            if cell.cell_type == 2:  # Nombre\n",
    "                priority += 100\n",
    "            elif cell.cell_type == 1:  # Texte\n",
    "                priority += 50\n",
    "        \n",
    "        # Cellules avec style\n",
    "        if cell.style_id and cell.style_id != \"s0\":\n",
    "            priority += 200\n",
    "        \n",
    "        # Cellules fusionnées\n",
    "        if cell.is_merged:\n",
    "            priority += 150\n",
    "        \n",
    "        # Proximité du coin supérieur gauche (cellules importantes souvent en haut à gauche)\n",
    "        distance_from_origin = cell.row + cell.col\n",
    "        priority += max(0, 100 - distance_from_origin)\n",
    "        \n",
    "        return priority\n",
    "    \n",
    "    def transform_batch(self, \n",
    "                        json_files: List[Union[str, Dict[str, Any]]],\n",
    "                        batch_size: int = 32) -> List['ExcelGraph']:\n",
    "        \"\"\"\n",
    "        Transforme plusieurs JSON en batch\n",
    "        \n",
    "        Args:\n",
    "            json_files: Liste de JSON (strings ou dicts)\n",
    "            batch_size: Taille des batches pour l'embedding\n",
    "            \n",
    "        Returns:\n",
    "            Liste d'ExcelGraph\n",
    "        \"\"\"\n",
    "        graphs = []\n",
    "        \n",
    "        for i in range(0, len(json_files), batch_size):\n",
    "            batch = json_files[i:i + batch_size]\n",
    "            batch_graphs = []\n",
    "            \n",
    "            for json_data in batch:\n",
    "                try:\n",
    "                    graph = self.transform(json_data)\n",
    "                    batch_graphs.append(graph)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de la transformation: {e}\")\n",
    "                    # Créer un graphe vide en cas d'erreur\n",
    "                    empty_graph = self._create_empty_graph()\n",
    "                    batch_graphs.append(empty_graph)\n",
    "            \n",
    "            graphs.extend(batch_graphs)\n",
    "        \n",
    "        return graphs\n",
    "    \n",
    "    def _create_empty_graph(self) -> 'ExcelGraph':\n",
    "        \"\"\"Crée un graphe vide en cas d'erreur\"\"\"\n",
    "        return ExcelGraph(\n",
    "            cell_embeddings=torch.empty(0, self.embedding_config.embedding_dim),\n",
    "            edge_embeddings=torch.empty(0, 64),\n",
    "            edge_indices=torch.empty(2, 0, dtype=torch.long),\n",
    "            edge_types=[],\n",
    "            edge_weights=torch.empty(0),\n",
    "            cell_positions=[]\n",
    "        )\n",
    "    \n",
    "    def get_graph_statistics(self, graph: 'ExcelGraph') -> Dict[str, Any]:\n",
    "        \"\"\"Retourne des statistiques détaillées sur le graphe\"\"\"\n",
    "        if graph.num_nodes == 0:\n",
    "            return {'empty_graph': True}\n",
    "        \n",
    "        # Statistiques de base\n",
    "        stats = {\n",
    "            'num_nodes': graph.num_nodes,\n",
    "            'num_edges': graph.num_edges,\n",
    "            'avg_degree': graph.num_edges * 2 / graph.num_nodes if graph.num_nodes > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # Statistiques par type d'arête\n",
    "        edge_type_counts = {}\n",
    "        for edge_type in graph.edge_types:\n",
    "            edge_type_counts[edge_type.value] = edge_type_counts.get(edge_type.value, 0) + 1\n",
    "        stats['edge_types'] = edge_type_counts\n",
    "        \n",
    "        # Statistiques des feuilles\n",
    "        sheets = set(pos[0] if isinstance(pos, tuple) and len(pos) >= 1 else \"unknown\" \n",
    "                    for pos in graph.cell_positions)\n",
    "        stats['num_sheets'] = len(sheets)\n",
    "        stats['sheet_names'] = list(sheets)\n",
    "        \n",
    "        # Statistiques des positions\n",
    "        if graph.cell_positions:\n",
    "            positions = [(pos[1], pos[2]) if isinstance(pos, tuple) and len(pos) >= 3 \n",
    "                        else pos for pos in graph.cell_positions]\n",
    "            if positions and all(isinstance(p, tuple) and len(p) == 2 for p in positions):\n",
    "                rows = [p[0] for p in positions]\n",
    "                cols = [p[1] for p in positions]\n",
    "                stats['position_range'] = {\n",
    "                    'min_row': min(rows),\n",
    "                    'max_row': max(rows),\n",
    "                    'min_col': min(cols),\n",
    "                    'max_col': max(cols)\n",
    "                }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def save_graph(self, graph: 'ExcelGraph', filepath: str):\n",
    "        \"\"\"Sauvegarde un graphe au format PyTorch\"\"\"\n",
    "        torch.save({\n",
    "            'cell_embeddings': graph.cell_embeddings,\n",
    "            'edge_embeddings': graph.edge_embeddings,\n",
    "            'edge_indices': graph.edge_indices,\n",
    "            'edge_types': [et.value for et in graph.edge_types],\n",
    "            'edge_weights': graph.edge_weights,\n",
    "            'cell_positions': graph.cell_positions,\n",
    "            'config': self.embedding_config,\n",
    "            'graph_config': self.graph_config\n",
    "        }, filepath)\n",
    "    \n",
    "    def load_graph(self, filepath: str) -> 'ExcelGraph':\n",
    "        \"\"\"Charge un graphe depuis un fichier\"\"\"\n",
    "        data = torch.load(filepath)\n",
    "        \n",
    "        # Reconstituer les edge_types\n",
    "        edge_types = [EdgeType(et) for et in data['edge_types']]\n",
    "        \n",
    "        return ExcelGraph(\n",
    "            cell_embeddings=data['cell_embeddings'],\n",
    "            edge_embeddings=data['edge_embeddings'],\n",
    "            edge_indices=data['edge_indices'],\n",
    "            edge_types=edge_types,\n",
    "            edge_weights=data['edge_weights'],\n",
    "            cell_positions=data['cell_positions']\n",
    "        )\n",
    "\n",
    "# Fonction utilitaire standalone\n",
    "def json_to_excel_graph(json_data: Union[str, Dict[str, Any]], \n",
    "                        **kwargs) -> 'ExcelGraph':\n",
    "    \"\"\"\n",
    "    Fonction utilitaire pour transformer rapidement un JSON en ExcelGraph\n",
    "    \n",
    "    Args:\n",
    "        json_data: JSON Excel (string ou dict)\n",
    "        **kwargs: Arguments pour JSONToGraphTransformer\n",
    "        \n",
    "    Returns:\n",
    "        ExcelGraph\n",
    "    \"\"\"\n",
    "    transformer = JSONToGraphTransformer(**kwargs)\n",
    "    return transformer.transform(json_data)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # JSON d'exemple (format Univer)\n",
    "    example_json = {\n",
    "        \"styles\": {\n",
    "            \"s0\": {\"fs\": 12.0},\n",
    "            \"s1\": {\"fs\": 16.0, \"bl\": 1, \"cl\": {\"rgb\": \"#FFFFFF\"}, \"bg\": {\"rgb\": \"#4470C4\"}}\n",
    "        },\n",
    "        \"sheets\": {\n",
    "            \"sheet1\": {\n",
    "                \"id\": \"sheet1\",\n",
    "                \"name\": \"Sheet1\",\n",
    "                \"hidden\": 0,\n",
    "                \"rowCount\": 10,\n",
    "                \"columnCount\": 10,\n",
    "                \"mergeData\": [],\n",
    "                \"cellData\": {\n",
    "                    \"0\": {\n",
    "                        \"0\": {\"v\": \"Hello\", \"t\": 1, \"s\": \"s0\"},\n",
    "                        \"1\": {\"v\": \"World\", \"t\": 1, \"s\": \"s1\"}\n",
    "                    },\n",
    "                    \"1\": {\n",
    "                        \"0\": {\"v\": 42, \"t\": 2, \"s\": \"s0\"},\n",
    "                        \"1\": {\"f\": \"=A1&B1\", \"t\": 3, \"s\": \"s0\"}\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"sheet2\": {\n",
    "                \"id\": \"sheet2\", \n",
    "                \"name\": \"Sheet2\",\n",
    "                \"hidden\": 0,\n",
    "                \"rowCount\": 5,\n",
    "                \"columnCount\": 5,\n",
    "                \"mergeData\": [],\n",
    "                \"cellData\": {\n",
    "                    \"0\": {\n",
    "                        \"0\": {\"v\": \"Data\", \"t\": 1, \"s\": \"s0\"},\n",
    "                        \"1\": {\"f\": \"=Sheet1!A1\", \"t\": 3, \"s\": \"s0\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Créer le transformer\n",
    "    transformer = JSONToGraphTransformer(\n",
    "        max_cells_per_sheet=100,\n",
    "        include_empty_cells=False\n",
    "    )\n",
    "    \n",
    "    # Transformer le JSON\n",
    "    excel_graph = transformer.transform(example_json)\n",
    "    \n",
    "    # Afficher les statistiques\n",
    "    stats = transformer.get_graph_statistics(excel_graph)\n",
    "    print(\"Statistiques du graphe:\")\n",
    "    print(f\"  Nombre de nœuds: {stats['num_nodes']}\")\n",
    "    print(f\"  Nombre d'arêtes: {stats['num_edges']}\")\n",
    "    print(f\"  Degré moyen: {stats['avg_degree']:.2f}\")\n",
    "    print(f\"  Nombre de feuilles: {stats['num_sheets']}\")\n",
    "    print(f\"  Feuilles: {stats['sheet_names']}\")\n",
    "    \n",
    "    if 'edge_types' in stats:\n",
    "        print(\"  Types d'arêtes:\")\n",
    "        for edge_type, count in stats['edge_types'].items():\n",
    "            print(f\"    {edge_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nDimensions des embeddings:\")\n",
    "    print(f\"  Cellules: {excel_graph.cell_embeddings.shape}\")\n",
    "    print(f\"  Arêtes: {excel_graph.edge_embeddings.shape}\")\n",
    "    print(f\"  Indices d'arêtes: {excel_graph.edge_indices.shape}\")\n",
    "    \n",
    "    # Test avec une liste de JSON\n",
    "    json_list = [example_json, example_json]\n",
    "    graphs = transformer.transform_batch(json_list)\n",
    "    print(f\"\\nBatch transformé: {len(graphs)} graphes\")\n",
    "    \n",
    "    # Sauvegarde (optionnel)\n",
    "    # transformer.save_graph(excel_graph, \"example_graph.pt\")\n",
    "    \n",
    "    # Test de la fonction utilitaire\n",
    "    quick_graph = json_to_excel_graph(example_json, max_cells_per_sheet=50)\n",
    "    print(f\"\\nGraphe rapide: {quick_graph.num_nodes} nœuds, {quick_graph.num_edges} arêtes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5abb5e0a-c538-4d1a-a942-ed9c213e8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformerLayer(nn.Module):\n",
    "    \"Couche Transformer adaptée aux graphes Excel\"\n",
    "    \n",
    "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        # Multi-head attention spatiale\n",
    "        self.spatial_attention = nn.MultiheadAttention(\n",
    "            d_model, n_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Multi-head attention sur les arêtes\n",
    "        self.edge_attention = nn.MultiheadAttention(\n",
    "            d_model, n_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Feed forward\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Gate pour combiner spatial et edge attention\n",
    "        self.gate = nn.Linear(d_model * 2, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, \n",
    "                node_features: torch.Tensor,\n",
    "                edge_indices: torch.Tensor,\n",
    "                edge_features: torch.Tensor,\n",
    "                attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            node_features: [batch_size, num_nodes, d_model]\n",
    "            edge_indices: [2, num_edges] \n",
    "            edge_features: [num_edges, d_model]\n",
    "            attention_mask: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        batch_size, num_nodes, d_model = node_features.shape\n",
    "        \n",
    "        # 1. Attention spatiale globale (toutes les cellules)\n",
    "        spatial_out, spatial_weights = self.spatial_attention(\n",
    "            node_features, node_features, node_features,\n",
    "            attn_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # 2. Attention basée sur les arêtes du graphe\n",
    "        if edge_indices.size(1) > 0:\n",
    "            # Construire les features pour l'attention sur arêtes\n",
    "            edge_source_features = node_features[:, edge_indices[0]]  # [batch, num_edges, d_model]\n",
    "            edge_target_features = node_features[:, edge_indices[1]]  # [batch, num_edges, d_model]\n",
    "            \n",
    "            # Combiner avec les features d'arêtes\n",
    "            edge_combined = edge_source_features + edge_features.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            \n",
    "            # Attention sur les arêtes\n",
    "            edge_out, edge_weights = self.edge_attention(\n",
    "                edge_combined, edge_combined, edge_target_features\n",
    "            )\n",
    "            \n",
    "            # Agréger vers les nœuds (scatter_add simulation)\n",
    "            edge_aggregated = torch.zeros_like(node_features)\n",
    "            for i in range(edge_indices.size(1)):\n",
    "                target_idx = edge_indices[1, i]\n",
    "                edge_aggregated[:, target_idx] += edge_out[:, i]\n",
    "        else:\n",
    "            edge_aggregated = torch.zeros_like(node_features)\n",
    "        \n",
    "        # 3. Combiner spatial et edge attention avec gating\n",
    "        combined_attention = torch.cat([spatial_out, edge_aggregated], dim=-1)\n",
    "        gated_attention = torch.sigmoid(self.gate(combined_attention))\n",
    "        attended = gated_attention * spatial_out + (1 - gated_attention) * edge_aggregated\n",
    "        \n",
    "        # 4. Résiduelle + LayerNorm\n",
    "        x = self.norm1(node_features + self.dropout(attended))\n",
    "        \n",
    "        # 5. Feed Forward\n",
    "        ff_out = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ExcelGraphTransformer(nn.Module):\n",
    "    \"\"\"Transformer principal pour les graphes Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config: EmbeddingConfig,\n",
    "                 num_layers: int = 6,\n",
    "                 n_heads: int = 8,\n",
    "                 d_ff: int = 1024,\n",
    "                 dropout: float = 0.1,\n",
    "                 max_nodes: int = 512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.d_model = config.embedding_dim\n",
    "        self.max_nodes = max_nodes\n",
    "        \n",
    "        # Embedder de cellules optimisé\n",
    "        self.cell_embedder = self._create_cell_embedder(config)\n",
    "        \n",
    "        # Embedder d'arêtes\n",
    "        self.edge_embedder = EdgeEmbedder(config.embedding_dim)\n",
    "        \n",
    "        # Encodage positionnel 2D (row, col)\n",
    "        self.pos_encoding_2d = PositionalEncoding2D(config.embedding_dim)\n",
    "        \n",
    "        # Couches Transformer\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            GraphTransformerLayer(self.d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Projection finale\n",
    "        self.output_projection = nn.Linear(self.d_model, self.d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def _create_cell_embedder(self, config):\n",
    "        \"\"\"Crée un embedder de cellules optimisé\"\"\"\n",
    "        # Version simplifiée avec les dimensions optimisées\n",
    "        class CellEmbedder(nn.Module):\n",
    "            def __init__(self, config):\n",
    "                super().__init__()\n",
    "                self.config = config\n",
    "                \n",
    "                # Position\n",
    "                self.row_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "                self.col_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "                \n",
    "                # Type et contenu\n",
    "                self.type_embedding = nn.Embedding(4, config.type_embedding_dim)\n",
    "                self.value_encoder = ValueEncoder(config)\n",
    "                \n",
    "                # Style simplifié\n",
    "                self.bool_embedding = nn.Embedding(2, 8)\n",
    "                self.font_size_embedding = nn.Embedding(73, 16)\n",
    "                self.color_embedding = nn.Embedding(config.color_vocab_size, 24)\n",
    "                \n",
    "                # Projection finale optimisée\n",
    "                total_dim = (\n",
    "                    2 * config.position_embedding_dim +  # row, col\n",
    "                    config.type_embedding_dim +          # type\n",
    "                    self.value_encoder.output_dim +      # value (256D)\n",
    "                    4 * 8 +                              # bools\n",
    "                    16 + 24 + 48                         # font, colors, etc.\n",
    "                )\n",
    "                \n",
    "                self.projection = nn.Linear(total_dim, config.embedding_dim)\n",
    "                self.layer_norm = nn.LayerNorm(config.embedding_dim)\n",
    "                \n",
    "            def forward(self, cells, mask_indices=None):\n",
    "                if not isinstance(cells, list):\n",
    "                    cells = [cells]\n",
    "                \n",
    "                embeddings = []\n",
    "                for i, cell in enumerate(cells):\n",
    "                    # Position\n",
    "                    row_emb = self.row_embedding(torch.clamp(torch.tensor(cell.row), 0, self.config.max_position - 1))\n",
    "                    col_emb = self.col_embedding(torch.clamp(torch.tensor(cell.col), 0, self.config.max_position - 1))\n",
    "                    \n",
    "                    # Type\n",
    "                    type_emb = self.type_embedding(torch.tensor(cell.cell_type))\n",
    "                    \n",
    "                    # Contenu (avec masking possible)\n",
    "                    mask_content = mask_indices is not None and i in mask_indices\n",
    "                    value_emb = self.value_encoder(cell, mask_content=mask_content)\n",
    "                    \n",
    "                    # Style simplifié\n",
    "                    bold_emb = self.bool_embedding(torch.tensor(int(cell.bold)))\n",
    "                    italic_emb = self.bool_embedding(torch.tensor(int(cell.italic)))\n",
    "                    underline_emb = self.bool_embedding(torch.tensor(int(cell.underline)))\n",
    "                    strike_emb = self.bool_embedding(torch.tensor(int(cell.strike)))\n",
    "                    \n",
    "                    font_size = min(int(cell.font_size), 72)\n",
    "                    font_size_emb = self.font_size_embedding(torch.tensor(font_size))\n",
    "                    \n",
    "                    # Couleurs simplifiées\n",
    "                    text_color_id = self._color_to_id(cell.text_color)\n",
    "                    bg_color_id = self._color_to_id(cell.background_color)\n",
    "                    text_color_emb = self.color_embedding(torch.tensor(text_color_id))\n",
    "                    bg_color_emb = self.color_embedding(torch.tensor(bg_color_id))\n",
    "                    \n",
    "                    # Concaténer\n",
    "                    cell_embedding = torch.cat([\n",
    "                        row_emb, col_emb, type_emb, value_emb,\n",
    "                        bold_emb, italic_emb, underline_emb, strike_emb,\n",
    "                        font_size_emb, text_color_emb, bg_color_emb\n",
    "                    ], dim=0)\n",
    "                    \n",
    "                    embeddings.append(cell_embedding)\n",
    "                \n",
    "                # Stack et projeter\n",
    "                batch_embeddings = torch.stack(embeddings)\n",
    "                projected = self.projection(batch_embeddings)\n",
    "                normalized = self.layer_norm(projected)\n",
    "                \n",
    "                return normalized.squeeze(0) if len(cells) == 1 else normalized\n",
    "            \n",
    "            def _color_to_id(self, color: str) -> int:\n",
    "                if not color or color == \"#FFFFFF\":\n",
    "                    return 0\n",
    "                try:\n",
    "                    hex_val = int(color.replace(\"#\", \"\"), 16)\n",
    "                    return (hex_val % (self.config.color_vocab_size - 1)) + 1\n",
    "                except:\n",
    "                    return 0\n",
    "        \n",
    "        return CellEmbedder(config)\n",
    "    \n",
    "    def forward(self, \n",
    "                excel_graph: 'ExcelGraph',\n",
    "                mask_indices: Optional[List[int]] = None) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass du transformer\n",
    "        \n",
    "        Args:\n",
    "            excel_graph: Graphe Excel avec embeddings\n",
    "            mask_indices: Indices des cellules à masquer\n",
    "            \n",
    "        Returns:\n",
    "            Dict avec les embeddings et logits\n",
    "        \"\"\"\n",
    "        # Récupérer les features\n",
    "        node_features = excel_graph.cell_embeddings.unsqueeze(0)  # [1, num_nodes, d_model]\n",
    "        edge_indices = excel_graph.edge_indices\n",
    "        edge_features = excel_graph.edge_embeddings\n",
    "        \n",
    "        # Ajouter l'encodage positionnel 2D\n",
    "        positions = [(pos[0], pos[1]) for pos in excel_graph.cell_positions]\n",
    "        pos_encoding = self.pos_encoding_2d(positions, node_features.device)\n",
    "        node_features = node_features + pos_encoding.unsqueeze(0)\n",
    "        \n",
    "        # Appliquer les couches Transformer\n",
    "        x = node_features\n",
    "        attention_weights = []\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x, edge_indices, edge_features)\n",
    "        \n",
    "        # Projection finale\n",
    "        output_embeddings = self.output_projection(x)\n",
    "        \n",
    "        return {\n",
    "            'embeddings': output_embeddings,\n",
    "            'hidden_states': x,\n",
    "            'masked_indices': mask_indices\n",
    "        }\n",
    "\n",
    "class PositionalEncoding2D(nn.Module):\n",
    "    \"\"\"Encodage positionnel 2D pour les positions Excel (row, col)\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model: int, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # S'assurer que d_model est divisible par 4 pour le split row/col\n",
    "        if d_model % 4 != 0:\n",
    "            # Ajuster d_model au multiple de 4 le plus proche\n",
    "            d_model_adj = ((d_model // 4) + 1) * 4\n",
    "            self.projection = nn.Linear(d_model_adj, d_model)\n",
    "        else:\n",
    "            d_model_adj = d_model\n",
    "            self.projection = None\n",
    "        \n",
    "        # Créer l'encodage positionnel 2D\n",
    "        pe = torch.zeros(max_len, max_len, d_model_adj)\n",
    "        \n",
    "        # Dimension pour chaque composante (row, col)\n",
    "        dim_per_component = d_model_adj // 2\n",
    "        \n",
    "        # Position encoding pour les lignes (première moitié des dimensions)\n",
    "        position_row = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term_row = torch.exp(torch.arange(0, dim_per_component, 2).float() * \n",
    "                               -(math.log(10000.0) / dim_per_component))\n",
    "        \n",
    "        pe[:, :, 0::2][:, :, :dim_per_component//2] = torch.sin(\n",
    "            position_row * div_term_row\n",
    "        ).unsqueeze(1).expand(-1, max_len, -1)\n",
    "        pe[:, :, 1::2][:, :, :dim_per_component//2] = torch.cos(\n",
    "            position_row * div_term_row\n",
    "        ).unsqueeze(1).expand(-1, max_len, -1)\n",
    "        \n",
    "        # Position encoding pour les colonnes (deuxième moitié des dimensions)\n",
    "        position_col = torch.arange(0, max_len).unsqueeze(0).float()\n",
    "        div_term_col = torch.exp(torch.arange(0, dim_per_component, 2).float() * \n",
    "                               -(math.log(10000.0) / dim_per_component))\n",
    "        \n",
    "        start_idx = dim_per_component\n",
    "        pe[:, :, start_idx::2][:, :, :dim_per_component//2] = torch.sin(\n",
    "            position_col * div_term_col\n",
    "        ).unsqueeze(0).expand(max_len, -1, -1)\n",
    "        pe[:, :, start_idx+1::2][:, :, :dim_per_component//2] = torch.cos(\n",
    "            position_col * div_term_col\n",
    "        ).unsqueeze(0).expand(max_len, -1, -1)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, positions: List[Tuple[int, int]], device: torch.device) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            positions: Liste de (row, col)\n",
    "            device: Device PyTorch\n",
    "        \"\"\"\n",
    "        batch_pos = []\n",
    "        for row, col in positions:\n",
    "            row = min(row, self.pe.size(0) - 1)\n",
    "            col = min(col, self.pe.size(1) - 1)\n",
    "            pos_encoding = self.pe[row, col]\n",
    "            \n",
    "            # Projeter si nécessaire\n",
    "            if self.projection is not None:\n",
    "                pos_encoding = self.projection(pos_encoding)\n",
    "            \n",
    "            batch_pos.append(pos_encoding)\n",
    "        \n",
    "        return torch.stack(batch_pos).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf3f1a3-44bf-4430-a354-5fa8f4f464b7",
   "metadata": {},
   "source": [
    "Tache d'apprentissage : Masked Cell Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c752602-3d44-4aca-9533-b21be1010286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCellPredictor(nn.Module):\n",
    "    \"\"\"Modèle pour prédire les cellules masquées\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 transformer: ExcelGraphTransformer,\n",
    "                 num_candidates: int = 10):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "        self.num_candidates = num_candidates\n",
    "        \n",
    "        # Tête de classification pour choisir parmi les candidats\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(transformer.d_model, transformer.d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(transformer.d_model // 2, num_candidates)\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "                excel_graph: 'ExcelGraph',\n",
    "                mask_indices: List[int],\n",
    "                candidates: List[List[str]]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            excel_graph: Graphe Excel\n",
    "            mask_indices: Indices des cellules masquées\n",
    "            candidates: Liste de candidats pour chaque cellule masquée\n",
    "            \n",
    "        Returns:\n",
    "            Dict avec logits et probabilités\n",
    "        \"\"\"\n",
    "        # Forward pass du transformer\n",
    "        transformer_output = self.transformer(excel_graph, mask_indices)\n",
    "        embeddings = transformer_output['embeddings']  # [1, num_nodes, d_model]\n",
    "        \n",
    "        # Extraire les embeddings des cellules masquées\n",
    "        masked_embeddings = embeddings[0, mask_indices]  # [num_masked, d_model]\n",
    "        \n",
    "        # Prédiction pour chaque cellule masquée\n",
    "        logits = self.classification_head(masked_embeddings)  # [num_masked, num_candidates]\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'probabilities': probabilities,\n",
    "            'masked_embeddings': masked_embeddings,\n",
    "            'candidates': candidates\n",
    "        }\n",
    "    \n",
    "    def predict_top_candidates(self, \n",
    "                              excel_graph: 'ExcelGraph',\n",
    "                              mask_indices: List[int],\n",
    "                              candidates: List[List[str]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Prédit et retourne les candidats ordonnés par probabilité\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(excel_graph, mask_indices, candidates)\n",
    "            probabilities = output['probabilities']\n",
    "            \n",
    "            predictions = []\n",
    "            for i, (mask_idx, cell_candidates) in enumerate(zip(mask_indices, candidates)):\n",
    "                probs = probabilities[i].cpu().numpy()\n",
    "                \n",
    "                # Ordonner par probabilité décroissante\n",
    "                sorted_indices = np.argsort(probs)[::-1]\n",
    "                \n",
    "                prediction = {\n",
    "                    'cell_index': mask_idx,\n",
    "                    'candidates_ranked': [\n",
    "                        {\n",
    "                            'value': cell_candidates[idx] if idx < len(cell_candidates) else f\"candidate_{idx}\",\n",
    "                            'probability': float(probs[idx]),\n",
    "                            'rank': rank + 1\n",
    "                        }\n",
    "                        for rank, idx in enumerate(sorted_indices)\n",
    "                    ]\n",
    "                }\n",
    "                predictions.append(prediction)\n",
    "            \n",
    "            return predictions\n",
    "\n",
    "# Utilitaires pour l'entraînement\n",
    "class ExcelMaskingStrategy:\n",
    "    \"\"\"Stratégies pour masquer les cellules\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_masking(cells: List['FullCellInfo'], \n",
    "                      mask_ratio: float = 0.15) -> List[int]:\n",
    "        \"\"\"Masquage aléatoire\"\"\"\n",
    "        num_cells = len(cells)\n",
    "        num_mask = int(num_cells * mask_ratio)\n",
    "        \n",
    "        # Privilégier les cellules avec contenu\n",
    "        content_indices = [i for i, cell in enumerate(cells) \n",
    "                          if cell.raw_value or cell.formula]\n",
    "        \n",
    "        if len(content_indices) >= num_mask:\n",
    "            return random.sample(content_indices, num_mask)\n",
    "        else:\n",
    "            # Compléter avec des cellules aléatoires\n",
    "            remaining = num_mask - len(content_indices)\n",
    "            other_indices = [i for i in range(num_cells) if i not in content_indices]\n",
    "            additional = random.sample(other_indices, min(remaining, len(other_indices)))\n",
    "            return content_indices + additional\n",
    "    \n",
    "    @staticmethod\n",
    "    def strategic_masking(cells: List['FullCellInfo']) -> List[int]:\n",
    "        \"\"\"Masquage stratégique (formules, valeurs importantes)\"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            priority = 0\n",
    "            \n",
    "            # Formules = haute priorité\n",
    "            if cell.formula:\n",
    "                priority += 100\n",
    "            \n",
    "            # Valeurs numériques = moyenne priorité\n",
    "            elif cell.cell_type == 2:\n",
    "                priority += 50\n",
    "            \n",
    "            # Texte = basse priorité\n",
    "            elif cell.cell_type == 1:\n",
    "                priority += 25\n",
    "            \n",
    "            if priority > 0:\n",
    "                candidates.append((i, priority))\n",
    "        \n",
    "        # Prendre les plus prioritaires\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        num_mask = min(3, len(candidates))  # Masquer au plus 3 cellules\n",
    "        \n",
    "        return [idx for idx, _ in candidates[:num_mask]]\n",
    "\n",
    "def generate_candidates(cell: 'FullCellInfo', num_candidates: int = 10) -> List[str]:\n",
    "    \"\"\"Génère des candidats pour une cellule masquée\"\"\"\n",
    "    candidates = []\n",
    "    \n",
    "    if cell.cell_type == 2:  # Nombre\n",
    "        # Candidats numériques\n",
    "        try:\n",
    "            original = float(cell.raw_value) if cell.raw_value else 0\n",
    "            candidates = [\n",
    "                str(original),  # Valeur originale\n",
    "                str(original * 2),\n",
    "                str(original + 1),\n",
    "                str(original - 1),\n",
    "                str(int(original * 1.1)),\n",
    "                \"0\", \"1\", \"100\", \"42\", \"999\"\n",
    "            ]\n",
    "        except:\n",
    "            candidates = [\"0\", \"1\", \"10\", \"100\", \"42\", \"999\", \"1.5\", \"2.0\", \"3.14\", \"50\"]\n",
    "    \n",
    "    elif cell.cell_type == 1:  # Texte\n",
    "        original = str(cell.raw_value) if cell.raw_value else \"\"\n",
    "        candidates = [\n",
    "            original,  # Valeur originale\n",
    "            original.upper(),\n",
    "            original.lower(),\n",
    "            original + \"_copy\",\n",
    "            \"Text\", \"Data\", \"Value\", \"Item\", \"Total\", \"Summary\"\n",
    "        ]\n",
    "    \n",
    "    elif cell.cell_type == 3:  # Formule\n",
    "        candidates = [\n",
    "            cell.formula,  # Formule originale\n",
    "            \"=SUM(A1:A10)\",\n",
    "            \"=AVERAGE(B1:B5)\",\n",
    "            \"=COUNT(C1:C20)\",\n",
    "            \"=MAX(D1:D10)\",\n",
    "            \"=MIN(E1:E10)\",\n",
    "            \"=IF(F1>0,\\\"Yes\\\",\\\"No\\\")\",\n",
    "            \"=VLOOKUP(G1,A:B,2,FALSE)\",\n",
    "            \"=TODAY()\",\n",
    "            \"=CONCATENATE(H1,I1)\"\n",
    "        ]\n",
    "    \n",
    "    else:  # Vide\n",
    "        candidates = [\n",
    "            \"\", \"0\", \"1\", \"Text\", \"Data\", \"=SUM(A1:A5)\", \n",
    "            \"Total\", \"N/A\", \"TBD\", \"...\"\n",
    "        ]\n",
    "    \n",
    "    # S'assurer qu'on a exactement num_candidates\n",
    "    while len(candidates) < num_candidates:\n",
    "        candidates.append(f\"option_{len(candidates)}\")\n",
    "    \n",
    "    return candidates[:num_candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c593a8-b89b-4a7f-afda-1a3f92109d8d",
   "metadata": {},
   "source": [
    "Pipe pour application sur le dossier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a14793a-c0ff-4fa8-a015-2296552c0a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 INSTRUCTIONS D'UTILISATION DANS LE NOTEBOOK:\n",
      "\n",
      "1. Placez vos fichiers *.json dans le dossier 'data/'\n",
      "\n",
      "2. Exécutez cette cellule pour charger les fonctions\n",
      "\n",
      "3. Lancez l'analyse avec:\n",
      "   result = analyze_my_data(\"data\")\n",
      "\n",
      "4. Pour limiter à quelques fichiers:\n",
      "   result = analyze_my_data(\"data\", max_files=5)\n",
      "\n",
      "5. Les résultats seront affichés et un rapport HTML sera créé.\n",
      "\n",
      "📊 Cette version analyse vos données et évalue la faisabilité\n",
      "   d'un entraînement complet sans lancer le transformer lourd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Version compatible avec Jupyter Notebook\n",
    "# À exécuter directement dans une cellule de notebook\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration pour éviter les conflits dans Jupyter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_pipeline_notebook(data_folder=\"data\", max_files=None, quick_mode=True):\n",
    "    \"\"\"\n",
    "    Version simplifiée de la pipeline pour notebook Jupyter\n",
    "    \n",
    "    Args:\n",
    "        data_folder: Dossier contenant les fichiers JSON\n",
    "        max_files: Nombre maximum de fichiers à traiter (None = tous)\n",
    "        quick_mode: Mode rapide avec moins d'époques\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🚀 PIPELINE EXCEL TRANSFORMER - VERSION NOTEBOOK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Vérification de l'environnement\n",
    "    print(\"\\n1️⃣ VÉRIFICATION DE L'ENVIRONNEMENT\")\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        print(f\"✅ PyTorch: {torch.__version__}\")\n",
    "        print(f\"✅ NumPy: {np.__version__}\")\n",
    "        print(f\"✅ Pandas: {pd.__version__}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Module manquant: {e}\")\n",
    "        return {\"error\": f\"Missing module: {e}\"}\n",
    "    \n",
    "    # 2. Recherche des fichiers JSON\n",
    "    print(f\"\\n2️⃣ RECHERCHE DES FICHIERS JSON DANS '{data_folder}'\")\n",
    "    \n",
    "    if not os.path.exists(data_folder):\n",
    "        print(f\"❌ Le dossier '{data_folder}' n'existe pas!\")\n",
    "        print(\"💡 Créez le dossier et placez-y vos fichiers *.json\")\n",
    "        return {\"error\": f\"Folder {data_folder} not found\"}\n",
    "    \n",
    "    # Patterns de recherche\n",
    "    json_files = []\n",
    "    patterns = [\n",
    "        os.path.join(data_folder, \"*.json\"),\n",
    "        os.path.join(data_folder, \"**\", \"*.json\")\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        found_files = glob.glob(pattern, recursive=True)\n",
    "        json_files.extend(found_files)\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"❌ Aucun fichier *.json trouvé dans '{data_folder}'\")\n",
    "        return {\"error\": \"No JSON files found\"}\n",
    "    \n",
    "    print(f\"📁 Trouvé {len(json_files)} fichiers JSON\")\n",
    "    \n",
    "    # Limiter si nécessaire\n",
    "    if max_files and len(json_files) > max_files:\n",
    "        json_files = json_files[:max_files]\n",
    "        print(f\"🔄 Limitation à {max_files} fichiers\")\n",
    "    \n",
    "    # 3. Analyse des fichiers\n",
    "    print(f\"\\n3️⃣ ANALYSE DES FICHIERS\")\n",
    "    \n",
    "    valid_files = []\n",
    "    analysis_summary = {\n",
    "        'total_files': len(json_files),\n",
    "        'valid_files': 0,\n",
    "        'total_cells': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    for i, file_path in enumerate(json_files):\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Validation structure Excel\n",
    "            cell_count = 0\n",
    "            is_valid = False\n",
    "            \n",
    "            if 'sheets' in data:\n",
    "                for sheet_data in data['sheets'].values():\n",
    "                    if 'cellData' in sheet_data:\n",
    "                        for row_data in sheet_data['cellData'].values():\n",
    "                            cell_count += len(row_data)\n",
    "                        is_valid = True\n",
    "            \n",
    "            if is_valid and cell_count > 0:\n",
    "                valid_files.append(data)\n",
    "                analysis_summary['valid_files'] += 1\n",
    "                analysis_summary['total_cells'] += cell_count\n",
    "                print(f\"  ✅ {filename}: {cell_count} cellules\")\n",
    "            else:\n",
    "                print(f\"  ⚠️  {filename}: Structure non-Excel ou vide\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"{filename}: {str(e)[:50]}...\"\n",
    "            analysis_summary['errors'].append(error_msg)\n",
    "            print(f\"  ❌ {error_msg}\")\n",
    "    \n",
    "    print(f\"\\n📊 RÉSUMÉ DE L'ANALYSE:\")\n",
    "    print(f\"   Fichiers analysés: {analysis_summary['total_files']}\")\n",
    "    print(f\"   Fichiers valides: {analysis_summary['valid_files']}\")\n",
    "    print(f\"   Total cellules: {analysis_summary['total_cells']}\")\n",
    "    print(f\"   Erreurs: {len(analysis_summary['errors'])}\")\n",
    "    \n",
    "    if analysis_summary['valid_files'] == 0:\n",
    "        print(\"❌ Aucun fichier Excel valide trouvé!\")\n",
    "        return {\"error\": \"No valid Excel files\", \"analysis\": analysis_summary}\n",
    "    \n",
    "    # 4. Test de base sur les données (sans transformer complet)\n",
    "    print(f\"\\n4️⃣ TEST DE BASE SUR LES DONNÉES\")\n",
    "    \n",
    "    # Prendre les premiers fichiers pour test\n",
    "    test_files = valid_files[:min(3, len(valid_files))]\n",
    "    \n",
    "    cells_extracted = 0\n",
    "    sheets_found = 0\n",
    "    formulas_found = 0\n",
    "    \n",
    "    for file_data in test_files:\n",
    "        for sheet_data in file_data.get('sheets', {}).values():\n",
    "            sheets_found += 1\n",
    "            cell_data = sheet_data.get('cellData', {})\n",
    "            \n",
    "            for row_data in cell_data.values():\n",
    "                for cell_info in row_data.values():\n",
    "                    cells_extracted += 1\n",
    "                    if cell_info.get('f'):  # Formule\n",
    "                        formulas_found += 1\n",
    "    \n",
    "    print(f\"✅ Test réussi:\")\n",
    "    print(f\"   Cellules extraites: {cells_extracted}\")\n",
    "    print(f\"   Feuilles trouvées: {sheets_found}\")\n",
    "    print(f\"   Formules trouvées: {formulas_found}\")\n",
    "    \n",
    "    # 5. Simulation d'entraînement simple\n",
    "    print(f\"\\n5️⃣ SIMULATION D'ENTRAÎNEMENT\")\n",
    "    \n",
    "    # Statistiques des types de cellules\n",
    "    cell_types = {'empty': 0, 'text': 0, 'number': 0, 'formula': 0}\n",
    "    \n",
    "    for file_data in test_files:\n",
    "        for sheet_data in file_data.get('sheets', {}).values():\n",
    "            cell_data = sheet_data.get('cellData', {})\n",
    "            for row_data in cell_data.values():\n",
    "                for cell_info in row_data.values():\n",
    "                    cell_type = cell_info.get('t', 0)\n",
    "                    if cell_type == 0:\n",
    "                        cell_types['empty'] += 1\n",
    "                    elif cell_type == 1:\n",
    "                        cell_types['text'] += 1\n",
    "                    elif cell_type == 2:\n",
    "                        cell_types['number'] += 1\n",
    "                    elif cell_type == 3:\n",
    "                        cell_types['formula'] += 1\n",
    "    \n",
    "    print(\"📊 Types de cellules détectés:\")\n",
    "    total_cells = sum(cell_types.values())\n",
    "    for cell_type, count in cell_types.items():\n",
    "        percentage = (count / total_cells * 100) if total_cells > 0 else 0\n",
    "        print(f\"   {cell_type}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 6. Simulation de prédictions\n",
    "    print(f\"\\n6️⃣ SIMULATION DE PRÉDICTIONS\")\n",
    "    \n",
    "    # Générer des candidats pour quelques cellules d'exemple\n",
    "    sample_predictions = []\n",
    "    \n",
    "    # Prendre quelques cellules d'exemple\n",
    "    for file_data in test_files[:2]:\n",
    "        for sheet_data in file_data.get('sheets', {}).values():\n",
    "            cell_data = sheet_data.get('cellData', {})\n",
    "            count = 0\n",
    "            for row_key, row_data in cell_data.items():\n",
    "                for col_key, cell_info in row_data.items():\n",
    "                    if count >= 3:  # Limiter à 3 exemples par fichier\n",
    "                        break\n",
    "                    \n",
    "                    value = cell_info.get('v', '')\n",
    "                    cell_type = cell_info.get('t', 0)\n",
    "                    formula = cell_info.get('f', '')\n",
    "                    \n",
    "                    # Générer des candidats selon le type\n",
    "                    candidates = []\n",
    "                    if cell_type == 1:  # Texte\n",
    "                        candidates = [str(value), f\"{value}_copy\", \"Text\", \"Data\", \"Item\"]\n",
    "                    elif cell_type == 2:  # Nombre\n",
    "                        try:\n",
    "                            num_val = float(value) if value else 0\n",
    "                            candidates = [str(value), str(num_val + 1), str(num_val * 2), \"0\", \"100\"]\n",
    "                        except:\n",
    "                            candidates = [\"0\", \"1\", \"10\", \"100\", str(value)]\n",
    "                    elif cell_type == 3:  # Formule\n",
    "                        candidates = [formula, \"=SUM(A1:A10)\", \"=AVERAGE(B1:B5)\", \"=COUNT(C1:C10)\", \"=MAX(D1:D5)\"]\n",
    "                    else:\n",
    "                        candidates = [\"\", \"0\", \"Text\", \"Data\", \"N/A\"]\n",
    "                    \n",
    "                    # Simuler une prédiction (le vrai modèle assignerait des probabilités)\n",
    "                    predicted_probs = np.random.dirichlet([2, 1, 1, 1, 1])  # Favoriser le premier candidat\n",
    "                    \n",
    "                    sample_predictions.append({\n",
    "                        'position': f\"({row_key},{col_key})\",\n",
    "                        'true_value': str(value) if value else str(formula),\n",
    "                        'cell_type': ['Empty', 'Text', 'Number', 'Formula'][cell_type],\n",
    "                        'candidates': candidates[:5],\n",
    "                        'probabilities': predicted_probs[:5].tolist()\n",
    "                    })\n",
    "                    \n",
    "                    count += 1\n",
    "                if count >= 3:\n",
    "                    break\n",
    "    \n",
    "    print(\"🔮 Exemples de prédictions simulées:\")\n",
    "    for i, pred in enumerate(sample_predictions[:5]):\n",
    "        print(f\"\\n   Exemple {i+1} - Position {pred['position']} ({pred['cell_type']}):\")\n",
    "        print(f\"      Vraie valeur: '{pred['true_value']}'\")\n",
    "        print(\"      Top 3 prédictions:\")\n",
    "        \n",
    "        # Trier par probabilité\n",
    "        sorted_preds = sorted(zip(pred['candidates'], pred['probabilities']), \n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for rank, (candidate, prob) in enumerate(sorted_preds[:3]):\n",
    "            marker = \"🎯\" if candidate == pred['true_value'] else f\"{rank+1}.\"\n",
    "            print(f\"         {marker} {candidate[:20]:20s} ({prob:.1%})\")\n",
    "    \n",
    "    # 7. Rapport de faisabilité\n",
    "    print(f\"\\n7️⃣ RAPPORT DE FAISABILITÉ\")\n",
    "    \n",
    "    feasibility_score = 0\n",
    "    recommendations = []\n",
    "    \n",
    "    # Évaluer la faisabilité\n",
    "    if analysis_summary['valid_files'] >= 5:\n",
    "        feasibility_score += 30\n",
    "        recommendations.append(\"✅ Nombre suffisant de fichiers pour l'entraînement\")\n",
    "    else:\n",
    "        recommendations.append(\"⚠️ Peu de fichiers - entraînement limité possible\")\n",
    "    \n",
    "    if analysis_summary['total_cells'] >= 1000:\n",
    "        feasibility_score += 40\n",
    "        recommendations.append(\"✅ Nombre suffisant de cellules pour l'entraînement\")\n",
    "    elif analysis_summary['total_cells'] >= 100:\n",
    "        feasibility_score += 20\n",
    "        recommendations.append(\"⚠️ Nombre modéré de cellules - entraînement possible mais limité\")\n",
    "    else:\n",
    "        recommendations.append(\"❌ Trop peu de cellules pour un entraînement efficace\")\n",
    "    \n",
    "    if formulas_found >= 10:\n",
    "        feasibility_score += 20\n",
    "        recommendations.append(\"✅ Formules détectées - apprentissage des relations possible\")\n",
    "    elif formulas_found > 0:\n",
    "        feasibility_score += 10\n",
    "        recommendations.append(\"⚠️ Quelques formules - apprentissage partiel possible\")\n",
    "    else:\n",
    "        recommendations.append(\"⚠️ Aucune formule - apprentissage limité aux valeurs\")\n",
    "    \n",
    "    if len(analysis_summary['errors']) == 0:\n",
    "        feasibility_score += 10\n",
    "        recommendations.append(\"✅ Aucune erreur de format\")\n",
    "    else:\n",
    "        recommendations.append(f\"⚠️ {len(analysis_summary['errors'])} fichiers avec erreurs\")\n",
    "    \n",
    "    print(f\"📊 Score de faisabilité: {feasibility_score}/100\")\n",
    "    \n",
    "    if feasibility_score >= 70:\n",
    "        print(\"🟢 FAISABILITÉ ÉLEVÉE - Entraînement recommandé\")\n",
    "    elif feasibility_score >= 40:\n",
    "        print(\"🟡 FAISABILITÉ MODÉRÉE - Entraînement possible avec limitations\")\n",
    "    else:\n",
    "        print(\"🔴 FAISABILITÉ FAIBLE - Améliorer les données avant entraînement\")\n",
    "    \n",
    "    print(\"\\n💡 RECOMMANDATIONS:\")\n",
    "    for rec in recommendations:\n",
    "        print(f\"   {rec}\")\n",
    "    \n",
    "    # 8. Prochaines étapes\n",
    "    print(f\"\\n8️⃣ PROCHAINES ÉTAPES\")\n",
    "    \n",
    "    if feasibility_score >= 40:\n",
    "        print(\"Pour lancer l'entraînement complet:\")\n",
    "        print(\"1. 🚀 Utilisez la pipeline complète avec vos données\")\n",
    "        print(\"2. 📊 Ajustez les hyperparamètres selon la taille de vos données\")\n",
    "        print(\"3. 🔄 Itérez sur différentes stratégies de masquage\")\n",
    "        print(\"4. 📈 Évaluez les performances sur un ensemble de test\")\n",
    "    else:\n",
    "        print(\"Pour améliorer vos données:\")\n",
    "        print(\"1. 📁 Ajoutez plus de fichiers Excel au format JSON\")\n",
    "        print(\"2. 🔧 Vérifiez la structure de vos fichiers JSON\")\n",
    "        print(\"3. 📊 Assurez-vous d'avoir des formules et des valeurs variées\")\n",
    "        print(\"4. 🧹 Nettoyez les fichiers corrompus\")\n",
    "    \n",
    "    # Résumé final\n",
    "    result = {\n",
    "        'success': True,\n",
    "        'analysis': analysis_summary,\n",
    "        'feasibility_score': feasibility_score,\n",
    "        'recommendations': recommendations,\n",
    "        'sample_predictions': sample_predictions,\n",
    "        'cell_types': cell_types,\n",
    "        'next_steps': 'full_training' if feasibility_score >= 40 else 'improve_data'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🎉 ANALYSE TERMINÉE!\")\n",
    "    print(f\"📋 Résultat stocké dans la variable 'result'\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_data_report_notebook(result, output_file=\"data_report_notebook.html\"):\n",
    "    \"\"\"Crée un rapport HTML depuis les résultats d'analyse\"\"\"\n",
    "    \n",
    "    if not result.get('success'):\n",
    "        return None\n",
    "    \n",
    "    analysis = result['analysis']\n",
    "    feasibility = result['feasibility_score']\n",
    "    recommendations = result['recommendations']\n",
    "    \n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Rapport d'Analyse Excel - Notebook</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}\n",
    "            .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                       color: white; padding: 30px; border-radius: 10px; text-align: center; }}\n",
    "            .section {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; \n",
    "                       border-radius: 8px; background: #f9f9f9; }}\n",
    "            .metric {{ display: inline-block; margin: 10px; padding: 15px; \n",
    "                      background: white; border-radius: 8px; border-left: 4px solid #3498db; }}\n",
    "            .score {{ font-size: 2em; font-weight: bold; color: #2c3e50; }}\n",
    "            .good {{ border-left-color: #27ae60; }}\n",
    "            .warning {{ border-left-color: #f39c12; }}\n",
    "            .error {{ border-left-color: #e74c3c; }}\n",
    "            ul {{ list-style-type: none; padding: 0; }}\n",
    "            li {{ margin: 10px 0; padding: 10px; background: white; border-radius: 5px; }}\n",
    "            .emoji {{ font-size: 1.2em; margin-right: 10px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>📊 Analyse de Faisabilité Excel Transformer</h1>\n",
    "            <p>Rapport généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>📈 Résumé Exécutif</h2>\n",
    "            <div class=\"metric good\">\n",
    "                <strong>Fichiers analysés</strong><br>\n",
    "                <span class=\"score\">{analysis['total_files']}</span>\n",
    "            </div>\n",
    "            <div class=\"metric good\">\n",
    "                <strong>Fichiers valides</strong><br>\n",
    "                <span class=\"score\">{analysis['valid_files']}</span>\n",
    "            </div>\n",
    "            <div class=\"metric good\">\n",
    "                <strong>Total cellules</strong><br>\n",
    "                <span class=\"score\">{analysis['total_cells']:,}</span>\n",
    "            </div>\n",
    "            <div class=\"metric {'good' if feasibility >= 70 else 'warning' if feasibility >= 40 else 'error'}\">\n",
    "                <strong>Score de faisabilité</strong><br>\n",
    "                <span class=\"score\">{feasibility}/100</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>🎯 Évaluation de Faisabilité</h2>\n",
    "    \"\"\"\n",
    "    \n",
    "    if feasibility >= 70:\n",
    "        html_content += '<div style=\"background: #d4edda; padding: 15px; border-radius: 5px; border-left: 4px solid #28a745;\">'\n",
    "        html_content += '<h3 style=\"color: #155724; margin: 0;\">🟢 FAISABILITÉ ÉLEVÉE</h3>'\n",
    "        html_content += '<p style=\"margin: 10px 0 0 0;\">Vos données sont excellentes pour l\\'entraînement du transformer Excel!</p>'\n",
    "        html_content += '</div>'\n",
    "    elif feasibility >= 40:\n",
    "        html_content += '<div style=\"background: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107;\">'\n",
    "        html_content += '<h3 style=\"color: #856404; margin: 0;\">🟡 FAISABILITÉ MODÉRÉE</h3>'\n",
    "        html_content += '<p style=\"margin: 10px 0 0 0;\">L\\'entraînement est possible mais avec des limitations.</p>'\n",
    "        html_content += '</div>'\n",
    "    else:\n",
    "        html_content += '<div style=\"background: #f8d7da; padding: 15px; border-radius: 5px; border-left: 4px solid #dc3545;\">'\n",
    "        html_content += '<h3 style=\"color: #721c24; margin: 0;\">🔴 FAISABILITÉ FAIBLE</h3>'\n",
    "        html_content += '<p style=\"margin: 10px 0 0 0;\">Améliorez vos données avant de lancer l\\'entraînement.</p>'\n",
    "        html_content += '</div>'\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>💡 Recommandations</h2>\n",
    "            <ul>\n",
    "    \"\"\"\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        html_content += f'<li><span class=\"emoji\">{rec[:2]}</span>{rec[2:]}</li>'\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>🚀 Prochaines Étapes</h2>\n",
    "    \"\"\"\n",
    "    \n",
    "    if result['next_steps'] == 'full_training':\n",
    "        html_content += \"\"\"\n",
    "            <ol>\n",
    "                <li>✅ Lancez la pipeline complète d'entraînement</li>\n",
    "                <li>📊 Surveillez les métriques d'accuracy pendant l'entraînement</li>\n",
    "                <li>🔄 Expérimentez avec différentes stratégies de masquage</li>\n",
    "                <li>📈 Évaluez les performances sur un ensemble de validation</li>\n",
    "            </ol>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        html_content += \"\"\"\n",
    "            <ol>\n",
    "                <li>📁 Collectez plus de fichiers Excel au format JSON</li>\n",
    "                <li>🔧 Vérifiez et corrigez la structure de vos données</li>\n",
    "                <li>📊 Assurez-vous d'avoir une variété de types de cellules</li>\n",
    "                <li>🧹 Nettoyez les fichiers avec des erreurs</li>\n",
    "            </ol>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>📋 Détails Techniques</h2>\n",
    "            <p><strong>Fichiers avec erreurs:</strong> {len(analysis['errors'])}</p>\n",
    "            <p><strong>Taux de réussite:</strong> {(analysis['valid_files']/analysis['total_files']*100):.1f}%</p>\n",
    "            <p><strong>Cellules par fichier (moyenne):</strong> {(analysis['total_cells']/analysis['valid_files']):.0f}</p>\n",
    "        </div>\n",
    "        \n",
    "        <footer style=\"text-align: center; margin-top: 40px; color: #666;\">\n",
    "            <p>Rapport généré par Excel Graph Transformer Pipeline</p>\n",
    "        </footer>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"📄 Rapport HTML sauvegardé: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# Fonction principale pour notebook\n",
    "def analyze_my_data(data_folder=\"data\", max_files=None, create_report=True):\n",
    "    \"\"\"\n",
    "    Fonction principale à appeler dans le notebook\n",
    "    \n",
    "    Usage:\n",
    "        result = analyze_my_data(\"data\", max_files=5)\n",
    "    \"\"\"\n",
    "    result = run_pipeline_notebook(data_folder, max_files, quick_mode=True)\n",
    "    \n",
    "    if result.get('success') and create_report:\n",
    "        create_data_report_notebook(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Instructions d'utilisation\n",
    "print(\"\"\"\n",
    "🎯 INSTRUCTIONS D'UTILISATION DANS LE NOTEBOOK:\n",
    "\n",
    "1. Placez vos fichiers *.json dans le dossier 'data/'\n",
    "\n",
    "2. Exécutez cette cellule pour charger les fonctions\n",
    "\n",
    "3. Lancez l'analyse avec:\n",
    "   result = analyze_my_data(\"data\")\n",
    "\n",
    "4. Pour limiter à quelques fichiers:\n",
    "   result = analyze_my_data(\"data\", max_files=5)\n",
    "\n",
    "5. Les résultats seront affichés et un rapport HTML sera créé.\n",
    "\n",
    "📊 Cette version analyse vos données et évalue la faisabilité\n",
    "   d'un entraînement complet sans lancer le transformer lourd.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd4b94d8-163c-4709-a5b3-e3109507a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 PIPELINE EXCEL TRANSFORMER - VERSION NOTEBOOK\n",
      "============================================================\n",
      "\n",
      "1️⃣ VÉRIFICATION DE L'ENVIRONNEMENT\n",
      "✅ PyTorch: 2.7.1+cpu\n",
      "✅ NumPy: 2.3.1\n",
      "✅ Pandas: 2.3.0\n",
      "\n",
      "2️⃣ RECHERCHE DES FICHIERS JSON DANS 'embedding/data'\n",
      "📁 Trouvé 22 fichiers JSON\n",
      "\n",
      "3️⃣ ANALYSE DES FICHIERS\n",
      "  ✅ 001c766dd64f5fdad3768694b0d382b6d988d94ba248c21fb0e7930b27dacf28.json: 3372 cellules\n",
      "  ✅ 0017285f44fbc2ca3e36d830e95a0cb049eb474cf1e17ff400f8074b6c2cea1f.json: 22176 cellules\n",
      "  ✅ 002640c96a51ecb5b9d6ce18816fd01edc27c079c7667156dfa67fc706a703d7.json: 5195 cellules\n",
      "  ✅ 0024d5eb932a3ac70e343098d6a0379394997851df9d83e0850669e23320075e.json: 601 cellules\n",
      "  ✅ 00350d054fe0d85c109eb3607d8aa1dfbef4be0ecbe8e670b7cc8f2f8b236972.json: 657 cellules\n",
      "  ✅ 00013ad39833fc129f5b79553f6d6389dad9b192130ebd754f64fc47c01cef82.json: 33 cellules\n",
      "  ✅ 0014b1c74f12b7f42dc7c267c6b56e3c90dac181ab147e71441d5f6b78c99ac8.json: 392 cellules\n",
      "  ✅ 000b7dd83566a50f96006b5948980639f3382f65b3a34d6bf757ddd3d01bf003.json: 72528 cellules\n",
      "  ✅ 0022c921e3505c0980a6f3b19c9334cc889d4715bf58783beccf68c5feb7b161.json: 2032 cellules\n",
      "  ✅ 0003d90ad249104a7ba0fb6bab08e8b9e70746e0cd2c3b30a006935b55f2a07b.json: 1556 cellules\n",
      "  ✅ 003593d1064dcd41f60b311efc7d7d0fca9c433d5f244481a3e4db279a5083ef.json: 43969 cellules\n",
      "  ✅ 001c766dd64f5fdad3768694b0d382b6d988d94ba248c21fb0e7930b27dacf28.json: 3372 cellules\n",
      "  ✅ 0017285f44fbc2ca3e36d830e95a0cb049eb474cf1e17ff400f8074b6c2cea1f.json: 22176 cellules\n",
      "  ✅ 002640c96a51ecb5b9d6ce18816fd01edc27c079c7667156dfa67fc706a703d7.json: 5195 cellules\n",
      "  ✅ 0024d5eb932a3ac70e343098d6a0379394997851df9d83e0850669e23320075e.json: 601 cellules\n",
      "  ✅ 00350d054fe0d85c109eb3607d8aa1dfbef4be0ecbe8e670b7cc8f2f8b236972.json: 657 cellules\n",
      "  ✅ 00013ad39833fc129f5b79553f6d6389dad9b192130ebd754f64fc47c01cef82.json: 33 cellules\n",
      "  ✅ 0014b1c74f12b7f42dc7c267c6b56e3c90dac181ab147e71441d5f6b78c99ac8.json: 392 cellules\n",
      "  ✅ 000b7dd83566a50f96006b5948980639f3382f65b3a34d6bf757ddd3d01bf003.json: 72528 cellules\n",
      "  ✅ 0022c921e3505c0980a6f3b19c9334cc889d4715bf58783beccf68c5feb7b161.json: 2032 cellules\n",
      "  ✅ 0003d90ad249104a7ba0fb6bab08e8b9e70746e0cd2c3b30a006935b55f2a07b.json: 1556 cellules\n",
      "  ✅ 003593d1064dcd41f60b311efc7d7d0fca9c433d5f244481a3e4db279a5083ef.json: 43969 cellules\n",
      "\n",
      "📊 RÉSUMÉ DE L'ANALYSE:\n",
      "   Fichiers analysés: 22\n",
      "   Fichiers valides: 22\n",
      "   Total cellules: 305022\n",
      "   Erreurs: 0\n",
      "\n",
      "4️⃣ TEST DE BASE SUR LES DONNÉES\n",
      "✅ Test réussi:\n",
      "   Cellules extraites: 30743\n",
      "   Feuilles trouvées: 24\n",
      "   Formules trouvées: 0\n",
      "\n",
      "5️⃣ SIMULATION D'ENTRAÎNEMENT\n",
      "📊 Types de cellules détectés:\n",
      "   empty: 23748 (77.2%)\n",
      "   text: 3606 (11.7%)\n",
      "   number: 3389 (11.0%)\n",
      "   formula: 0 (0.0%)\n",
      "\n",
      "6️⃣ SIMULATION DE PRÉDICTIONS\n",
      "🔮 Exemples de prédictions simulées:\n",
      "\n",
      "   Exemple 1 - Position (1,1) (Text):\n",
      "      Vraie valeur: 'Перечень предприятий, предоставляющих форму 2-услуги (квартальная) за 4 квартал 2024 года.                                                                                                                   Срок  предоставления до 27 января  2025 года. '\n",
      "      Top 3 prédictions:\n",
      "         🎯 Перечень предприятий (42.2%)\n",
      "         2. Item                 (41.1%)\n",
      "         3. Text                 (10.4%)\n",
      "\n",
      "   Exemple 2 - Position (3,1) (Text):\n",
      "      Vraie valeur: 'КАТО'\n",
      "      Top 3 prédictions:\n",
      "         1. Item                 (42.8%)\n",
      "         2. КАТО_copy            (29.7%)\n",
      "         🎯 КАТО                 (13.3%)\n",
      "\n",
      "   Exemple 3 - Position (3,2) (Text):\n",
      "      Vraie valeur: 'БИН/ИИН'\n",
      "      Top 3 prédictions:\n",
      "         🎯 БИН/ИИН              (49.1%)\n",
      "         2. Data                 (27.5%)\n",
      "         3. Item                 (14.2%)\n",
      "\n",
      "   Exemple 4 - Position (0,0) (Text):\n",
      "      Vraie valeur: 'Item No. (BOLD is a module)'\n",
      "      Top 3 prédictions:\n",
      "         1. Data                 (48.4%)\n",
      "         2. Item                 (28.5%)\n",
      "         🎯 Item No. (BOLD is a  (14.9%)\n",
      "\n",
      "   Exemple 5 - Position (0,1) (Empty):\n",
      "      Vraie valeur: ''\n",
      "      Top 3 prédictions:\n",
      "         🎯                      (60.8%)\n",
      "         2. N/A                  (15.6%)\n",
      "         3. 0                    (12.9%)\n",
      "\n",
      "7️⃣ RAPPORT DE FAISABILITÉ\n",
      "📊 Score de faisabilité: 80/100\n",
      "🟢 FAISABILITÉ ÉLEVÉE - Entraînement recommandé\n",
      "\n",
      "💡 RECOMMANDATIONS:\n",
      "   ✅ Nombre suffisant de fichiers pour l'entraînement\n",
      "   ✅ Nombre suffisant de cellules pour l'entraînement\n",
      "   ⚠️ Aucune formule - apprentissage limité aux valeurs\n",
      "   ✅ Aucune erreur de format\n",
      "\n",
      "8️⃣ PROCHAINES ÉTAPES\n",
      "Pour lancer l'entraînement complet:\n",
      "1. 🚀 Utilisez la pipeline complète avec vos données\n",
      "2. 📊 Ajustez les hyperparamètres selon la taille de vos données\n",
      "3. 🔄 Itérez sur différentes stratégies de masquage\n",
      "4. 📈 Évaluez les performances sur un ensemble de test\n",
      "\n",
      "🎉 ANALYSE TERMINÉE!\n",
      "📋 Résultat stocké dans la variable 'result'\n",
      "📄 Rapport HTML sauvegardé: data_report_notebook.html\n"
     ]
    }
   ],
   "source": [
    "# Analyser tous vos fichiers JSON\n",
    "result = analyze_my_data(\"embedding/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1141516f-0963-406a-b360-352e753ae389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 ENTRAÎNEMENT COMPLET SUR VOS DONNÉES\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1000) must match the size of tensor b (128) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 288\u001b[39m\n\u001b[32m    285\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m💡 Lancez d\u001b[39m\u001b[33m'\u001b[39m\u001b[33mabord l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mentraînement avec run_optimized_training()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# Lancer l'entraînement\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m model, trainer = \u001b[43mrun_full_training_on_your_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mrun_full_training_on_your_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     19\u001b[39m transformer_builder = JSONToGraphTransformer(\n\u001b[32m     20\u001b[39m     embedding_config=config,\n\u001b[32m     21\u001b[39m     max_cells_per_sheet=\u001b[32m500\u001b[39m,  \u001b[38;5;66;03m# Augmenté pour vos gros fichiers\u001b[39;00m\n\u001b[32m     22\u001b[39m     include_empty_cells=\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Ignorer les 77% de cellules vides\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Modèle plus robuste\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m excel_transformer = \u001b[43mExcelGraphTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Plus de couches\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43md_ff\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# FFN plus grande\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m predictor = MaskedCellPredictor(excel_transformer, num_candidates=\u001b[32m10\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Charger vos données\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 116\u001b[39m, in \u001b[36mExcelGraphTransformer.__init__\u001b[39m\u001b[34m(self, config, num_layers, n_heads, d_ff, dropout, max_nodes)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.edge_embedder = EdgeEmbedder(config.embedding_dim)\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Encodage positionnel 2D (row, col)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28mself\u001b[39m.pos_encoding_2d = \u001b[43mPositionalEncoding2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Couches Transformer\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.transformer_layers = nn.ModuleList([\n\u001b[32m    120\u001b[39m     GraphTransformerLayer(\u001b[38;5;28mself\u001b[39m.d_model, n_heads, d_ff, dropout)\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers)\n\u001b[32m    122\u001b[39m ])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 301\u001b[39m, in \u001b[36mPositionalEncoding2D.__init__\u001b[39m\u001b[34m(self, d_model, max_len)\u001b[39m\n\u001b[32m    296\u001b[39m div_term_col = torch.exp(torch.arange(\u001b[32m0\u001b[39m, dim_per_component, \u001b[32m2\u001b[39m).float() * \n\u001b[32m    297\u001b[39m                        -(math.log(\u001b[32m10000.0\u001b[39m) / dim_per_component))\n\u001b[32m    299\u001b[39m start_idx = dim_per_component\n\u001b[32m    300\u001b[39m pe[:, :, start_idx::\u001b[32m2\u001b[39m][:, :, :dim_per_component//\u001b[32m2\u001b[39m] = torch.sin(\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     \u001b[43mposition_col\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiv_term_col\u001b[49m\n\u001b[32m    302\u001b[39m ).unsqueeze(\u001b[32m0\u001b[39m).expand(max_len, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    303\u001b[39m pe[:, :, start_idx+\u001b[32m1\u001b[39m::\u001b[32m2\u001b[39m][:, :, :dim_per_component//\u001b[32m2\u001b[39m] = torch.cos(\n\u001b[32m    304\u001b[39m     position_col * div_term_col\n\u001b[32m    305\u001b[39m ).unsqueeze(\u001b[32m0\u001b[39m).expand(max_len, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    307\u001b[39m \u001b[38;5;28mself\u001b[39m.register_buffer(\u001b[33m'\u001b[39m\u001b[33mpe\u001b[39m\u001b[33m'\u001b[39m, pe)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (1000) must match the size of tensor b (128) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Lancer la pipeline complète sur vos données\n",
    "# Cette fonction utilisera vos 22 fichiers pour un vrai entraînement\n",
    "\n",
    "# Configuration optimisée pour vos données\n",
    "class YourDataConfig:\n",
    "    \"\"\"Configuration spécialement adaptée à vos données\"\"\"\n",
    "    embedding_dim = 384  # Divisible par 4 et 8\n",
    "    position_embedding_dim = 48\n",
    "    type_embedding_dim = 16\n",
    "    max_position = 2000  # Pour vos gros fichiers\n",
    "    color_vocab_size = 300\n",
    "    align_vocab_size = 5\n",
    "    border_vocab_size = 10\n",
    "    font_vocab_size = 30\n",
    "    max_font_size = 72\n",
    "\n",
    "def run_optimized_training():\n",
    "    \"\"\"Lance l'entraînement optimisé sur vos données avec corrections\"\"\"\n",
    "    \n",
    "    print(\"🚀 ENTRAÎNEMENT OPTIMISÉ SUR VOS DONNÉES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Configuration\n",
    "    print(\"\\n1️⃣ CONFIGURATION DU MODÈLE\")\n",
    "    config = YourDataConfig()\n",
    "    \n",
    "    print(f\"   Embedding dimension: {config.embedding_dim}\")\n",
    "    print(f\"   Position max: {config.max_position}\")\n",
    "    print(f\"   Vocabulaire couleurs: {config.color_vocab_size}\")\n",
    "    \n",
    "    # 2. Création du transformer builder\n",
    "    print(\"\\n2️⃣ CRÉATION DU TRANSFORMER BUILDER\")\n",
    "    \n",
    "    transformer_builder = JSONToGraphTransformer(\n",
    "        embedding_config=config,\n",
    "        max_cells_per_sheet=300,  # Réduit pour éviter les problèmes de mémoire\n",
    "        include_empty_cells=False\n",
    "    )\n",
    "    \n",
    "    # 3. Modèle avec encodage positionnel corrigé\n",
    "    print(\"\\n3️⃣ INITIALISATION DU MODÈLE\")\n",
    "    \n",
    "    class FixedExcelGraphTransformer(nn.Module):\n",
    "        \"\"\"Version corrigée du transformer\"\"\"\n",
    "        \n",
    "        def __init__(self, config, num_layers=4, n_heads=8, d_ff=768, dropout=0.1):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.config = config\n",
    "            self.d_model = config.embedding_dim\n",
    "            \n",
    "            # Embedder de cellules\n",
    "            self.cell_embedder = self._create_cell_embedder(config)\n",
    "            \n",
    "            # Embedder d'arêtes\n",
    "            self.edge_embedder = EdgeEmbedder(config.embedding_dim)\n",
    "            \n",
    "            # Encodage positionnel 2D CORRIGÉ\n",
    "            self.pos_encoding_2d = FixedPositionalEncoding2D(config.embedding_dim)\n",
    "            \n",
    "            # Couches Transformer\n",
    "            self.transformer_layers = nn.ModuleList([\n",
    "                GraphTransformerLayer(self.d_model, n_heads, d_ff, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "            \n",
    "            # Projection finale\n",
    "            self.output_projection = nn.Linear(self.d_model, self.d_model)\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        def _create_cell_embedder(self, config):\n",
    "            \"\"\"Crée un embedder simplifié\"\"\"\n",
    "            # Utiliser l'embedder existant mais avec la bonne config\n",
    "            return ExcelCellEmbedder(config)\n",
    "        \n",
    "        def forward(self, excel_graph, mask_indices=None):\n",
    "            \"\"\"Forward pass corrigé\"\"\"\n",
    "            # Features des nœuds\n",
    "            node_features = excel_graph.cell_embeddings.unsqueeze(0)\n",
    "            edge_indices = excel_graph.edge_indices  \n",
    "            edge_features = excel_graph.edge_embeddings\n",
    "            \n",
    "            # Encodage positionnel 2D\n",
    "            positions = [(pos[0], pos[1]) for pos in excel_graph.cell_positions]\n",
    "            pos_encoding = self.pos_encoding_2d(positions, node_features.device)\n",
    "            node_features = node_features + pos_encoding.unsqueeze(0)\n",
    "            \n",
    "            # Couches transformer\n",
    "            x = node_features\n",
    "            for layer in self.transformer_layers:\n",
    "                x = layer(x, edge_indices, edge_features)\n",
    "            \n",
    "            # Projection finale\n",
    "            output_embeddings = self.output_projection(x)\n",
    "            \n",
    "            return {\n",
    "                'embeddings': output_embeddings,\n",
    "                'hidden_states': x,\n",
    "                'masked_indices': mask_indices\n",
    "            }\n",
    "    \n",
    "    # Créer le modèle corrigé\n",
    "    excel_transformer = FixedExcelGraphTransformer(\n",
    "        config, \n",
    "        num_layers=4,  # Réduit pour commencer\n",
    "        n_heads=8, \n",
    "        d_ff=768\n",
    "    )\n",
    "    \n",
    "    predictor = MaskedCellPredictor(excel_transformer, num_candidates=10)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in predictor.parameters())\n",
    "    print(f\"✅ Modèle créé: {total_params:,} paramètres\")\n",
    "    \n",
    "    # 4. Préparation des données\n",
    "    print(\"\\n4️⃣ PRÉPARATION DES DONNÉES\")\n",
    "    \n",
    "    # Charger vos fichiers\n",
    "    json_files, file_paths = load_json_files(\"data\")\n",
    "    print(f\"   Fichiers chargés: {len(json_files)}\")\n",
    "    \n",
    "    # Limiter pour le test initial\n",
    "    if len(json_files) > 10:\n",
    "        json_files = json_files[:10]\n",
    "        print(f\"   Limitation à {len(json_files)} fichiers pour le test\")\n",
    "    \n",
    "    # Créer le dataset\n",
    "    try:\n",
    "        dataset = ExcelMaskedDataset(\n",
    "            json_files,\n",
    "            transformer_builder,\n",
    "            mask_ratio=0.15,  # 15% des cellules non-vides\n",
    "            num_candidates=10\n",
    "        )\n",
    "        print(f\"✅ Dataset créé: {len(dataset)} échantillons\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur dataset: {e}\")\n",
    "        print(\"🔧 Tentative avec des paramètres plus conservateurs...\")\n",
    "        \n",
    "        # Transformer builder plus conservateur\n",
    "        transformer_builder = JSONToGraphTransformer(\n",
    "            embedding_config=config,\n",
    "            max_cells_per_sheet=100,  # Encore plus réduit\n",
    "            include_empty_cells=False\n",
    "        )\n",
    "        \n",
    "        dataset = ExcelMaskedDataset(\n",
    "            json_files[:5],  # Encore moins de fichiers\n",
    "            transformer_builder,\n",
    "            mask_ratio=0.1,  # Moins de masquage\n",
    "            num_candidates=10\n",
    "        )\n",
    "        print(f\"✅ Dataset réduit créé: {len(dataset)} échantillons\")\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"❌ Dataset vide après filtrage!\")\n",
    "        return None, None\n",
    "    \n",
    "    # 5. Entraînement\n",
    "    print(\"\\n5️⃣ LANCEMENT DE L'ENTRAÎNEMENT\")\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    trainer = MaskedPredictionTrainer(predictor)\n",
    "    \n",
    "    # Entraînement sur 5 époques d'abord\n",
    "    num_epochs = 5\n",
    "    print(f\"   Entraînement sur {num_epochs} époques...\")\n",
    "    \n",
    "    training_results = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\n📚 Époque {epoch + 1}/{num_epochs}:\")\n",
    "            \n",
    "            epoch_metrics = trainer.train_epoch(dataloader, epoch)\n",
    "            training_results.append(epoch_metrics)\n",
    "            \n",
    "            # Affichage des métriques\n",
    "            print(f\"   Loss: {epoch_metrics['loss']:.4f}\")\n",
    "            print(f\"   Accuracy: {epoch_metrics['accuracy']:.1%}\")\n",
    "            print(f\"   Top-3: {epoch_metrics['top3_accuracy']:.1%}\")\n",
    "            print(f\"   Top-5: {epoch_metrics['top5_accuracy']:.1%}\")\n",
    "            print(f\"   Prédictions: {epoch_metrics['total_predictions']}\")\n",
    "            \n",
    "            if epoch_metrics['accuracy'] > best_accuracy:\n",
    "                best_accuracy = epoch_metrics['accuracy']\n",
    "                print(f\"   ⭐ Nouveau record: {best_accuracy:.1%}\")\n",
    "                \n",
    "                # Sauvegarder le meilleur modèle\n",
    "                torch.save(predictor.state_dict(), \"best_model_your_data.pt\")\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\n⏱️ Entraînement terminé en {training_time:.1f}s\")\n",
    "        print(f\"🏆 Meilleure accuracy: {best_accuracy:.1%}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur pendant l'entraînement: {e}\")\n",
    "        print(\"🔍 Détails:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "    \n",
    "    # 6. Test rapide\n",
    "    print(\"\\n6️⃣ TEST RAPIDE DU MODÈLE ENTRAÎNÉ\")\n",
    "    \n",
    "    if len(dataset) > 0:\n",
    "        try:\n",
    "            # Prendre un échantillon\n",
    "            sample = dataset[0]\n",
    "            if sample is not None:\n",
    "                graph = sample['graph']\n",
    "                mask_indices = sample['mask_indices']\n",
    "                candidates = sample['candidates']\n",
    "                \n",
    "                # Prédiction\n",
    "                predictions = predictor.predict_top_candidates(graph, mask_indices, candidates)\n",
    "                \n",
    "                print(\"🔮 Exemple de prédiction après entraînement:\")\n",
    "                for i, pred in enumerate(predictions[:2]):  # 2 premiers\n",
    "                    print(f\"\\n   Cellule {pred['cell_index']}:\")\n",
    "                    for rank, cand in enumerate(pred['candidates_ranked'][:3]):\n",
    "                        print(f\"     {rank+1}. {cand['value'][:30]:30s} ({cand['probability']:.1%})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erreur test: {e}\")\n",
    "    \n",
    "    # 7. Résumé final\n",
    "    print(f\"\\n7️⃣ RÉSUMÉ FINAL\")\n",
    "    print(f\"   Fichiers traités: {len(json_files)}\")\n",
    "    print(f\"   Échantillons d'entraînement: {len(dataset)}\")\n",
    "    print(f\"   Époques complétées: {len(training_results)}\")\n",
    "    print(f\"   Meilleure accuracy: {best_accuracy:.1%}\")\n",
    "    print(f\"   Modèle sauvegardé: best_model_your_data.pt\")\n",
    "    \n",
    "    return predictor, training_results\n",
    "\n",
    "def quick_test_trained_model():\n",
    "    \"\"\"Test rapide du modèle entraîné\"\"\"\n",
    "    \n",
    "    print(\"\\n🧪 TEST DU MODÈLE ENTRAÎNÉ\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Charger le modèle sauvegardé\n",
    "        config = YourDataConfig()\n",
    "        \n",
    "        # Recréer l'architecture\n",
    "        excel_transformer = FixedExcelGraphTransformer(config, num_layers=4, n_heads=8)\n",
    "        predictor = MaskedCellPredictor(excel_transformer, num_candidates=10)\n",
    "        \n",
    "        # Charger les poids\n",
    "        predictor.load_state_dict(torch.load(\"best_model_your_data.pt\"))\n",
    "        predictor.eval()\n",
    "        \n",
    "        print(\"✅ Modèle chargé avec succès\")\n",
    "        \n",
    "        # Test sur un fichier de vos données\n",
    "        json_files, file_paths = load_json_files(\"data\")\n",
    "        if json_files:\n",
    "            test_file = json_files[0]\n",
    "            filename = os.path.basename(file_paths[0])\n",
    "            \n",
    "            print(f\"🔍 Test sur: {filename}\")\n",
    "            \n",
    "            # Créer l'évaluateur\n",
    "            transformer_builder = JSONToGraphTransformer(embedding_config=config)\n",
    "            evaluator = ExcelMaskedEvaluator(predictor, transformer_builder)\n",
    "            \n",
    "            # Test interactif\n",
    "            evaluator.interactive_test(test_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur: {e}\")\n",
    "        print(\"💡 Lancez d'abord l'entraînement avec run_optimized_training()\")\n",
    "\n",
    "# Lancer l'entraînement\n",
    "model, trainer = run_full_training_on_your_data()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e9290f3-c705-430d-b6c8-0bdac51331aa",
   "metadata": {},
   "source": [
    "Interface d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da47f6c-a946-435b-85ab-3abf8114e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class ExcelMaskedEvaluator:\n",
    "    \"\"\"Évaluateur pour la tâche de masked prediction avec analyses détaillées\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: 'MaskedCellPredictor',\n",
    "                 transformer_builder: 'JSONToGraphTransformer'):\n",
    "        self.model = model\n",
    "        self.transformer_builder = transformer_builder\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Stockage des résultats d'évaluation\n",
    "        self.evaluation_results = []\n",
    "        self.aggregated_metrics = defaultdict(list)\n",
    "        \n",
    "    def evaluate_excel_file(self, \n",
    "                           json_data: Dict[str, Any],\n",
    "                           strategies: List[str] = ['random', 'strategic'],\n",
    "                           num_candidates: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Évalue le modèle sur un fichier Excel complet\n",
    "        \n",
    "        Args:\n",
    "            json_data: Données Excel en JSON\n",
    "            strategies: Stratégies de masquage à tester\n",
    "            num_candidates: Nombre de candidats à générer\n",
    "            \n",
    "        Returns:\n",
    "            Résultats détaillés de l'évaluation\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'file_summary': {},\n",
    "            'strategy_results': {},\n",
    "            'cell_analysis': [],\n",
    "            'error_analysis': []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Extraire et filtrer les cellules\n",
    "            cells = self.transformer_builder._extract_cells_from_json(json_data)\n",
    "            cells = self.transformer_builder._filter_cells(cells, max_total_cells=100)\n",
    "            \n",
    "            if not cells:\n",
    "                return {'error': 'Aucune cellule trouvée'}\n",
    "            \n",
    "            # Créer le graphe\n",
    "            graph = self.transformer_builder.graph_embedder(cells)\n",
    "            \n",
    "            # Résumé du fichier\n",
    "            results['file_summary'] = {\n",
    "                'total_cells': len(cells),\n",
    "                'num_nodes': graph.num_nodes,\n",
    "                'num_edges': graph.num_edges,\n",
    "                'sheets': list(set(cell.sheet_name for cell in cells)),\n",
    "                'cell_types': {\n",
    "                    'empty': sum(1 for c in cells if c.cell_type == 0),\n",
    "                    'text': sum(1 for c in cells if c.cell_type == 1),\n",
    "                    'number': sum(1 for c in cells if c.cell_type == 2),\n",
    "                    'formula': sum(1 for c in cells if c.cell_type == 3)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Tester chaque stratégie de masquage\n",
    "            for strategy in strategies:\n",
    "                strategy_result = self._evaluate_strategy(\n",
    "                    graph, cells, strategy, num_candidates\n",
    "                )\n",
    "                results['strategy_results'][strategy] = strategy_result\n",
    "                \n",
    "                # Ajouter à l'analyse par cellule\n",
    "                for cell_result in strategy_result['cell_predictions']:\n",
    "                    cell_result['strategy'] = strategy\n",
    "                    cell_result['file_id'] = id(json_data)\n",
    "                    results['cell_analysis'].append(cell_result)\n",
    "            \n",
    "            # Analyse des erreurs\n",
    "            results['error_analysis'] = self._analyze_errors(results['cell_analysis'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            results['error'] = str(e)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_strategy(self, \n",
    "                          graph: 'ExcelGraph',\n",
    "                          cells: List['FullCellInfo'],\n",
    "                          strategy: str,\n",
    "                          num_candidates: int) -> Dict[str, Any]:\n",
    "        \"\"\"Évalue une stratégie de masquage spécifique\"\"\"\n",
    "        \n",
    "        # Choisir les cellules à masquer selon la stratégie\n",
    "        if strategy == 'random':\n",
    "            mask_indices = ExcelMaskingStrategy.random_masking(cells, mask_ratio=0.2)\n",
    "        elif strategy == 'strategic':\n",
    "            mask_indices = ExcelMaskingStrategy.strategic_masking(cells)\n",
    "        else:\n",
    "            mask_indices = [0]  # Par défaut\n",
    "        \n",
    "        if not mask_indices:\n",
    "            return {'error': 'Aucune cellule à masquer'}\n",
    "        \n",
    "        # Générer les candidats\n",
    "        candidates = []\n",
    "        ground_truth_info = []\n",
    "        \n",
    "        for mask_idx in mask_indices:\n",
    "            cell = cells[mask_idx]\n",
    "            cell_candidates = generate_candidates(cell, num_candidates)\n",
    "            \n",
    "            # Informations sur la vérité terrain\n",
    "            true_value = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"\"\n",
    "            true_position = -1\n",
    "            \n",
    "            # Trouver la position de la vraie valeur dans les candidats\n",
    "            for i, candidate in enumerate(cell_candidates):\n",
    "                if candidate == true_value:\n",
    "                    true_position = i\n",
    "                    break\n",
    "            \n",
    "            # Si pas trouvée, l'insérer à une position aléatoire pour le test\n",
    "            if true_position == -1 and true_value:\n",
    "                true_position = 0\n",
    "                cell_candidates[0] = true_value\n",
    "            \n",
    "            candidates.append(cell_candidates)\n",
    "            ground_truth_info.append({\n",
    "                'cell_index': mask_idx,\n",
    "                'true_value': true_value,\n",
    "                'true_position': true_position,\n",
    "                'cell_type': cell.cell_type,\n",
    "                'position': (cell.row, cell.col),\n",
    "                'sheet': cell.sheet_name\n",
    "            })\n",
    "        \n",
    "        # Prédiction du modèle\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model.predict_top_candidates(graph, mask_indices, candidates)\n",
    "        \n",
    "        # Calculer les métriques\n",
    "        metrics = self._calculate_metrics(predictions, ground_truth_info)\n",
    "        \n",
    "        # Analyser chaque prédiction\n",
    "        cell_predictions = []\n",
    "        for i, (prediction, gt_info) in enumerate(zip(predictions, ground_truth_info)):\n",
    "            cell_pred = self._analyze_cell_prediction(prediction, gt_info, candidates[i])\n",
    "            cell_predictions.append(cell_pred)\n",
    "        \n",
    "        return {\n",
    "            'strategy': strategy,\n",
    "            'num_masked': len(mask_indices),\n",
    "            'metrics': metrics,\n",
    "            'cell_predictions': cell_predictions\n",
    "        }\n",
    "    \n",
    "    def _calculate_metrics(self, \n",
    "                          predictions: List[Dict],\n",
    "                          ground_truth_info: List[Dict]) -> Dict[str, float]:\n",
    "        \"\"\"Calcule les métriques de performance\"\"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy_top1': 0.0,\n",
    "            'accuracy_top3': 0.0,\n",
    "            'accuracy_top5': 0.0,\n",
    "            'mrr': 0.0,  # Mean Reciprocal Rank\n",
    "            'avg_confidence': 0.0,\n",
    "            'by_type': {}\n",
    "        }\n",
    "        \n",
    "        if not predictions:\n",
    "            return metrics\n",
    "        \n",
    "        total = len(predictions)\n",
    "        top1_correct = 0\n",
    "        top3_correct = 0\n",
    "        top5_correct = 0\n",
    "        reciprocal_ranks = []\n",
    "        confidences = []\n",
    "        \n",
    "        # Métriques par type de cellule\n",
    "        type_metrics = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "        \n",
    "        for pred, gt_info in zip(predictions, ground_truth_info):\n",
    "            true_value = gt_info['true_value']\n",
    "            cell_type = gt_info['cell_type']\n",
    "            \n",
    "            # Trouver le rang de la vraie valeur\n",
    "            true_rank = None\n",
    "            for rank, candidate_info in enumerate(pred['candidates_ranked']):\n",
    "                if candidate_info['value'] == true_value:\n",
    "                    true_rank = rank + 1\n",
    "                    break\n",
    "            \n",
    "            if true_rank is not None:\n",
    "                # Accuracy\n",
    "                if true_rank == 1:\n",
    "                    top1_correct += 1\n",
    "                    type_metrics[cell_type]['correct'] += 1\n",
    "                if true_rank <= 3:\n",
    "                    top3_correct += 1\n",
    "                if true_rank <= 5:\n",
    "                    top5_correct += 1\n",
    "                \n",
    "                # MRR\n",
    "                reciprocal_ranks.append(1.0 / true_rank)\n",
    "            else:\n",
    "                reciprocal_ranks.append(0.0)\n",
    "            \n",
    "            type_metrics[cell_type]['total'] += 1\n",
    "            \n",
    "            # Confiance de la prédiction top-1\n",
    "            if pred['candidates_ranked']:\n",
    "                confidences.append(pred['candidates_ranked'][0]['probability'])\n",
    "        \n",
    "        # Calculer les métriques finales\n",
    "        metrics['accuracy_top1'] = top1_correct / total\n",
    "        metrics['accuracy_top3'] = top3_correct / total\n",
    "        metrics['accuracy_top5'] = top5_correct / total\n",
    "        metrics['mrr'] = np.mean(reciprocal_ranks)\n",
    "        metrics['avg_confidence'] = np.mean(confidences) if confidences else 0.0\n",
    "        \n",
    "        # Métriques par type\n",
    "        type_names = {0: 'empty', 1: 'text', 2: 'number', 3: 'formula'}\n",
    "        for cell_type, stats in type_metrics.items():\n",
    "            type_name = type_names.get(cell_type, f'type_{cell_type}')\n",
    "            if stats['total'] > 0:\n",
    "                metrics['by_type'][type_name] = stats['correct'] / stats['total']\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _analyze_cell_prediction(self, \n",
    "                                prediction: Dict,\n",
    "                                gt_info: Dict,\n",
    "                                candidates: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyse détaillée d'une prédiction de cellule\"\"\"\n",
    "        \n",
    "        true_value = gt_info['true_value']\n",
    "        cell_type = gt_info['cell_type']\n",
    "        \n",
    "        # Trouver la vraie valeur dans les prédictions\n",
    "        true_rank = None\n",
    "        true_confidence = 0.0\n",
    "        \n",
    "        for rank, candidate_info in enumerate(prediction['candidates_ranked']):\n",
    "            if candidate_info['value'] == true_value:\n",
    "                true_rank = rank + 1\n",
    "                true_confidence = candidate_info['probability']\n",
    "                break\n",
    "        \n",
    "        # Analyser la distribution des probabilités\n",
    "        probs = [c['probability'] for c in prediction['candidates_ranked']]\n",
    "        prob_analysis = {\n",
    "            'entropy': -sum(p * np.log(p + 1e-10) for p in probs),\n",
    "            'max_prob': max(probs),\n",
    "            'min_prob': min(probs),\n",
    "            'std_prob': np.std(probs)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'cell_index': gt_info['cell_index'],\n",
    "            'position': gt_info['position'],\n",
    "            'sheet': gt_info['sheet'],\n",
    "            'cell_type': cell_type,\n",
    "            'true_value': true_value,\n",
    "            'predicted_value': prediction['candidates_ranked'][0]['value'],\n",
    "            'predicted_confidence': prediction['candidates_ranked'][0]['probability'],\n",
    "            'true_rank': true_rank,\n",
    "            'true_confidence': true_confidence,\n",
    "            'is_correct': true_rank == 1 if true_rank else False,\n",
    "            'prob_analysis': prob_analysis,\n",
    "            'all_candidates': candidates,\n",
    "            'top5_predictions': prediction['candidates_ranked'][:5]\n",
    "        }\n",
    "    \n",
    "    def _analyze_errors(self, cell_analyses: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyse des erreurs et patterns de performance\"\"\"\n",
    "        \n",
    "        error_analysis = {\n",
    "            'common_errors': defaultdict(int),\n",
    "            'error_by_type': defaultdict(int),\n",
    "            'error_by_position': defaultdict(int),\n",
    "            'confidence_errors': [],\n",
    "            'patterns': {}\n",
    "        }\n",
    "        \n",
    "        correct_predictions = []\n",
    "        incorrect_predictions = []\n",
    "        \n",
    "        for analysis in cell_analyses:\n",
    "            if analysis['is_correct']:\n",
    "                correct_predictions.append(analysis)\n",
    "            else:\n",
    "                incorrect_predictions.append(analysis)\n",
    "                \n",
    "                # Analyser les types d'erreurs\n",
    "                true_val = analysis['true_value']\n",
    "                pred_val = analysis['predicted_value']\n",
    "                cell_type = analysis['cell_type']\n",
    "                \n",
    "                error_analysis['error_by_type'][cell_type] += 1\n",
    "                \n",
    "                # Erreurs de confiance élevée (confiant mais faux)\n",
    "                if analysis['predicted_confidence'] > 0.7:\n",
    "                    error_analysis['confidence_errors'].append(analysis)\n",
    "                \n",
    "                # Patterns d'erreurs communes\n",
    "                if cell_type == 2:  # Nombres\n",
    "                    try:\n",
    "                        true_num = float(true_val) if true_val else 0\n",
    "                        pred_num = float(pred_val) if pred_val else 0\n",
    "                        if abs(true_num - pred_num) < 10:\n",
    "                            error_analysis['common_errors']['close_number'] += 1\n",
    "                        else:\n",
    "                            error_analysis['common_errors']['far_number'] += 1\n",
    "                    except:\n",
    "                        error_analysis['common_errors']['invalid_number'] += 1\n",
    "                \n",
    "                elif cell_type == 1:  # Texte\n",
    "                    if len(true_val) == len(pred_val):\n",
    "                        error_analysis['common_errors']['same_length_text'] += 1\n",
    "                    elif true_val.lower() in pred_val.lower() or pred_val.lower() in true_val.lower():\n",
    "                        error_analysis['common_errors']['partial_text_match'] += 1\n",
    "                    else:\n",
    "                        error_analysis['common_errors']['different_text'] += 1\n",
    "                \n",
    "                elif cell_type == 3:  # Formule\n",
    "                    if '=' in pred_val:\n",
    "                        error_analysis['common_errors']['wrong_formula'] += 1\n",
    "                    else:\n",
    "                        error_analysis['common_errors']['formula_as_value'] += 1\n",
    "        \n",
    "        # Patterns généraux\n",
    "        if correct_predictions and incorrect_predictions:\n",
    "            avg_conf_correct = np.mean([p['predicted_confidence'] for p in correct_predictions])\n",
    "            avg_conf_incorrect = np.mean([p['predicted_confidence'] for p in incorrect_predictions])\n",
    "            \n",
    "            error_analysis['patterns'] = {\n",
    "                'avg_confidence_correct': avg_conf_correct,\n",
    "                'avg_confidence_incorrect': avg_conf_incorrect,\n",
    "                'confidence_separation': avg_conf_correct - avg_conf_incorrect,\n",
    "                'total_errors': len(incorrect_predictions),\n",
    "                'error_rate': len(incorrect_predictions) / len(cell_analyses)\n",
    "            }\n",
    "        \n",
    "        return error_analysis\n",
    "    \n",
    "    def generate_evaluation_report(self, \n",
    "                                  json_files: List[Dict],\n",
    "                                  output_file: str = \"evaluation_report.html\") -> str:\n",
    "        \"\"\"Génère un rapport d'évaluation complet en HTML\"\"\"\n",
    "        \n",
    "        print(\"🔍 Génération du rapport d'évaluation...\")\n",
    "        \n",
    "        all_results = []\n",
    "        aggregated_metrics = defaultdict(list)\n",
    "        \n",
    "        # Évaluer tous les fichiers\n",
    "        for i, json_data in enumerate(json_files):\n",
    "            print(f\"  Évaluation {i+1}/{len(json_files)}\")\n",
    "            \n",
    "            result = self.evaluate_excel_file(json_data)\n",
    "            if 'error' not in result:\n",
    "                all_results.append(result)\n",
    "                \n",
    "                # Agréger les métriques\n",
    "                for strategy, strategy_result in result['strategy_results'].items():\n",
    "                    if 'metrics' in strategy_result:\n",
    "                        for metric, value in strategy_result['metrics'].items():\n",
    "                            if isinstance(value, (int, float)):\n",
    "                                aggregated_metrics[f\"{strategy}_{metric}\"].append(value)\n",
    "        \n",
    "        # Créer le rapport HTML\n",
    "        html_content = self._create_html_report(all_results, aggregated_metrics)\n",
    "        \n",
    "        # Sauvegarder\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        print(f\"✅ Rapport sauvegardé: {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    def _create_html_report(self, \n",
    "                           all_results: List[Dict],\n",
    "                           aggregated_metrics: Dict) -> str:\n",
    "        \"\"\"Crée le contenu HTML du rapport\"\"\"\n",
    "        \n",
    "        # Calculer les statistiques globales\n",
    "        total_files = len(all_results)\n",
    "        total_predictions = sum(\n",
    "            len(result['cell_analysis']) \n",
    "            for result in all_results\n",
    "        )\n",
    "        \n",
    "        # Métriques moyennes\n",
    "        avg_metrics = {}\n",
    "        for metric, values in aggregated_metrics.items():\n",
    "            if values:\n",
    "                avg_metrics[metric] = {\n",
    "                    'mean': np.mean(values),\n",
    "                    'std': np.std(values),\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values)\n",
    "                }\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html lang=\"fr\">\n",
    "        <head>\n",
    "            <meta charset=\"UTF-8\">\n",
    "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "            <title>Rapport d'Évaluation - Excel Masked Prediction</title>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "                .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 5px; }}\n",
    "                .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}\n",
    "                .metric {{ display: inline-block; margin: 10px; padding: 10px; background: #f8f9fa; border-radius: 3px; }}\n",
    "                .good {{ background: #d4edda; }}\n",
    "                .warning {{ background: #fff3cd; }}\n",
    "                .error {{ background: #f8d7da; }}\n",
    "                table {{ width: 100%; border-collapse: collapse; margin: 10px 0; }}\n",
    "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "                th {{ background-color: #f2f2f2; }}\n",
    "                .chart {{ margin: 20px 0; text-align: center; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"header\">\n",
    "                <h1>📊 Rapport d'Évaluation - Excel Masked Prediction</h1>\n",
    "                <p>Analyse de performance du transformer sur {total_files} fichiers Excel</p>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>📈 Résumé Exécutif</h2>\n",
    "                <div class=\"metric good\">\n",
    "                    <strong>Fichiers analysés:</strong> {total_files}\n",
    "                </div>\n",
    "                <div class=\"metric good\">\n",
    "                    <strong>Prédictions totales:</strong> {total_predictions}\n",
    "                </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ajouter les métriques principales\n",
    "        for strategy in ['random', 'strategic']:\n",
    "            acc_key = f\"{strategy}_accuracy_top1\"\n",
    "            if acc_key in avg_metrics:\n",
    "                acc = avg_metrics[acc_key]['mean']\n",
    "                css_class = \"good\" if acc > 0.7 else \"warning\" if acc > 0.4 else \"error\"\n",
    "                html += f\"\"\"\n",
    "                <div class=\"metric {css_class}\">\n",
    "                    <strong>Accuracy {strategy}:</strong> {acc:.1%} ± {avg_metrics[acc_key]['std']:.1%}\n",
    "                </div>\n",
    "                \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>📊 Métriques Détaillées</h2>\n",
    "                <table>\n",
    "                    <tr>\n",
    "                        <th>Métrique</th>\n",
    "                        <th>Stratégie</th>\n",
    "                        <th>Moyenne</th>\n",
    "                        <th>Écart-type</th>\n",
    "                        <th>Min</th>\n",
    "                        <th>Max</th>\n",
    "                    </tr>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Table des métriques\n",
    "        metric_names = {\n",
    "            'accuracy_top1': 'Accuracy Top-1',\n",
    "            'accuracy_top3': 'Accuracy Top-3', \n",
    "            'accuracy_top5': 'Accuracy Top-5',\n",
    "            'mrr': 'Mean Reciprocal Rank',\n",
    "            'avg_confidence': 'Confiance Moyenne'\n",
    "        }\n",
    "        \n",
    "        for strategy in ['random', 'strategic']:\n",
    "            for metric, display_name in metric_names.items():\n",
    "                key = f\"{strategy}_{metric}\"\n",
    "                if key in avg_metrics:\n",
    "                    stats = avg_metrics[key]\n",
    "                    html += f\"\"\"\n",
    "                    <tr>\n",
    "                        <td>{display_name}</td>\n",
    "                        <td>{strategy.title()}</td>\n",
    "                        <td>{stats['mean']:.3f}</td>\n",
    "                        <td>{stats['std']:.3f}</td>\n",
    "                        <td>{stats['min']:.3f}</td>\n",
    "                        <td>{stats['max']:.3f}</td>\n",
    "                    </tr>\n",
    "                    \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                </table>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>🔍 Analyse des Erreurs</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Analyse des erreurs les plus communes\n",
    "        all_errors = defaultdict(int)\n",
    "        for result in all_results:\n",
    "            if 'error_analysis' in result:\n",
    "                for error_type, count in result['error_analysis']['common_errors'].items():\n",
    "                    all_errors[error_type] += count\n",
    "        \n",
    "        if all_errors:\n",
    "            html += \"<h3>Erreurs les plus fréquentes:</h3><ul>\"\n",
    "            sorted_errors = sorted(all_errors.items(), key=lambda x: x[1], reverse=True)\n",
    "            for error_type, count in sorted_errors[:5]:\n",
    "                html += f\"<li><strong>{error_type}:</strong> {count} occurrences</li>\"\n",
    "            html += \"</ul>\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>📋 Exemples de Prédictions</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Quelques exemples de prédictions\n",
    "        example_count = 0\n",
    "        for result in all_results[:3]:  # Premiers 3 fichiers\n",
    "            if 'cell_analysis' in result:\n",
    "                html += f\"<h3>Fichier {example_count + 1}:</h3>\"\n",
    "                for cell in result['cell_analysis'][:2]:  # 2 cellules par fichier\n",
    "                    status = \"✅ Correct\" if cell['is_correct'] else \"❌ Incorrect\"\n",
    "                    html += f\"\"\"\n",
    "                    <div style=\"margin: 10px 0; padding: 10px; border-left: 3px solid {'green' if cell['is_correct'] else 'red'};\">\n",
    "                        <strong>{status}</strong> - Cellule ({cell['position'][0]}, {cell['position'][1]})<br>\n",
    "                        <strong>Vraie valeur:</strong> \"{cell['true_value']}\"<br>\n",
    "                        <strong>Prédiction:</strong> \"{cell['predicted_value']}\" ({cell['predicted_confidence']:.1%})<br>\n",
    "                        <strong>Type:</strong> {['Vide', 'Texte', 'Nombre', 'Formule'][cell['cell_type']]}\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                example_count += 1\n",
    "                if example_count >= 3:\n",
    "                    break\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>🎯 Recommandations</h2>\n",
    "                <ul>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Générer des recommandations basées sur les résultats\n",
    "        recommendations = []\n",
    "        \n",
    "        # Vérifier la performance globale\n",
    "        if 'random_accuracy_top1' in avg_metrics:\n",
    "            acc = avg_metrics['random_accuracy_top1']['mean']\n",
    "            if acc < 0.5:\n",
    "                recommendations.append(\"🔴 Performance faible (<50%): Augmenter la taille du modèle ou améliorer les données d'entraînement\")\n",
    "            elif acc < 0.7:\n",
    "                recommendations.append(\"🟡 Performance modérée: Optimiser l'architecture ou les hyperparamètres\")\n",
    "            else:\n",
    "                recommendations.append(\"🟢 Performance satisfaisante: Continuer l'entraînement pour améliorer la stabilité\")\n",
    "        \n",
    "        # Vérifier la différence entre stratégies\n",
    "        if ('random_accuracy_top1' in avg_metrics and \n",
    "            'strategic_accuracy_top1' in avg_metrics):\n",
    "            diff = (avg_metrics['strategic_accuracy_top1']['mean'] - \n",
    "                   avg_metrics['random_accuracy_top1']['mean'])\n",
    "            if abs(diff) < 0.05:\n",
    "                recommendations.append(\"⚪ Peu de différence entre stratégies: Le modèle pourrait bénéficier d'un meilleur encodage du contexte\")\n",
    "        \n",
    "        # Analyser la confiance\n",
    "        if 'random_avg_confidence' in avg_metrics:\n",
    "            conf = avg_metrics['random_avg_confidence']['mean']\n",
    "            if conf < 0.3:\n",
    "                recommendations.append(\"🔵 Confiance faible: Revoir la calibration du modèle\")\n",
    "            elif conf > 0.9:\n",
    "                recommendations.append(\"🟠 Confiance très élevée: Risque de sur-confiance, vérifier la diversité des données\")\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations.append(\"✨ Aucune recommandation spécifique - Continuer le monitoring\")\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            html += f\"<li>{rec}</li>\"\n",
    "        \n",
    "        html += f\"\"\"\n",
    "                </ul>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>ℹ️ Informations Techniques</h2>\n",
    "                <p><strong>Modèle:</strong> Excel Graph Transformer avec Masked Cell Prediction</p>\n",
    "                <p><strong>Date d'évaluation:</strong> {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "                <p><strong>Nombre de paramètres:</strong> {sum(p.numel() for p in self.model.parameters()):,}</p>\n",
    "                <p><strong>Stratégies testées:</strong> Random masking, Strategic masking</p>\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        return html\n",
    "    \n",
    "    def interactive_test(self, json_data: Dict[str, Any]):\n",
    "        \"\"\"Test interactif sur un fichier Excel\"\"\"\n",
    "        \n",
    "        print(\"\\n🎮 MODE INTERACTIF - Test de Prédiction\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Préparer les données\n",
    "            cells = self.transformer_builder._extract_cells_from_json(json_data)\n",
    "            cells = self.transformer_builder._filter_cells(cells, max_total_cells=50)\n",
    "            \n",
    "            if not cells:\n",
    "                print(\"❌ Aucune cellule trouvée dans le fichier\")\n",
    "                return\n",
    "            \n",
    "            graph = self.transformer_builder.graph_embedder(cells)\n",
    "            \n",
    "            print(f\"📊 Fichier chargé: {graph.num_nodes} cellules, {graph.num_edges} relations\")\n",
    "            print(f\"📋 Feuilles: {', '.join(set(cell.sheet_name for cell in cells))}\")\n",
    "            \n",
    "            # Afficher les cellules disponibles\n",
    "            print(\"\\n📱 Cellules disponibles:\")\n",
    "            for i, cell in enumerate(cells[:10]):  # Afficher les 10 premières\n",
    "                content = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"[vide]\"\n",
    "                type_name = ['Vide', 'Texte', 'Nombre', 'Formule'][cell.cell_type]\n",
    "                print(f\"  {i:2d}. ({cell.row:2d},{cell.col:2d}) {type_name:8s} | {content[:30]}\")\n",
    "            \n",
    "            if len(cells) > 10:\n",
    "                print(f\"  ... et {len(cells) - 10} autres cellules\")\n",
    "            \n",
    "            # Interface interactive\n",
    "            while True:\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                choice = input(\"Choisir une action:\\n\"\n",
    "                             \"  1. Masquer une cellule spécifique\\n\"\n",
    "                             \"  2. Masquage aléatoire\\n\"\n",
    "                             \"  3. Masquage stratégique\\n\"\n",
    "                             \"  4. Quitter\\n\"\n",
    "                             \"Votre choix (1-4): \").strip()\n",
    "                \n",
    "                if choice == '4':\n",
    "                    print(\"👋 Au revoir !\")\n",
    "                    break\n",
    "                \n",
    "                elif choice == '1':\n",
    "                    try:\n",
    "                        cell_idx = int(input(f\"Index de la cellule à masquer (0-{len(cells)-1}): \"))\n",
    "                        if 0 <= cell_idx < len(cells):\n",
    "                            mask_indices = [cell_idx]\n",
    "                        else:\n",
    "                            print(\"❌ Index invalide\")\n",
    "                            continue\n",
    "                    except ValueError:\n",
    "                        print(\"❌ Veuillez entrer un nombre\")\n",
    "                        continue\n",
    "                \n",
    "                elif choice == '2':\n",
    "                    mask_indices = ExcelMaskingStrategy.random_masking(cells, mask_ratio=0.1)\n",
    "                    print(f\"🎲 Masquage aléatoire: cellules {mask_indices}\")\n",
    "                \n",
    "                elif choice == '3':\n",
    "                    mask_indices = ExcelMaskingStrategy.strategic_masking(cells)\n",
    "                    print(f\"🎯 Masquage stratégique: cellules {mask_indices}\")\n",
    "                \n",
    "                else:\n",
    "                    print(\"❌ Choix invalide\")\n",
    "                    continue\n",
    "                \n",
    "                if not mask_indices:\n",
    "                    print(\"❌ Aucune cellule à masquer\")\n",
    "                    continue\n",
    "                \n",
    "                # Effectuer la prédiction\n",
    "                candidates = [generate_candidates(cells[idx], 10) for idx in mask_indices]\n",
    "                predictions = self.model.predict_top_candidates(graph, mask_indices, candidates)\n",
    "                \n",
    "                # Afficher les résultats\n",
    "                print(f\"\\n🔮 RÉSULTATS DE PRÉDICTION\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                for i, (mask_idx, prediction) in enumerate(zip(mask_indices, predictions)):\n",
    "                    cell = cells[mask_idx]\n",
    "                    true_value = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"[vide]\"\n",
    "                    \n",
    "                    print(f\"\\n📍 Cellule {mask_idx} - Position ({cell.row},{cell.col})\")\n",
    "                    print(f\"   Type: {['Vide', 'Texte', 'Nombre', 'Formule'][cell.cell_type]}\")\n",
    "                    print(f\"   Vraie valeur: '{true_value}'\")\n",
    "                    print(f\"   Top 5 prédictions:\")\n",
    "                    \n",
    "                    for rank, candidate in enumerate(prediction['candidates_ranked'][:5]):\n",
    "                        marker = \"🎯\" if candidate['value'] == true_value else f\"{rank+1}.\"\n",
    "                        confidence = candidate['probability']\n",
    "                        bar_length = int(confidence * 20)\n",
    "                        bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
    "                        \n",
    "                        print(f\"     {marker:3s} {candidate['value'][:25]:25s} │{bar}│ {confidence:.1%}\")\n",
    "                    \n",
    "                    # Trouver le rang de la vraie valeur\n",
    "                    true_rank = None\n",
    "                    for rank, candidate in enumerate(prediction['candidates_ranked']):\n",
    "                        if candidate['value'] == true_value:\n",
    "                            true_rank = rank + 1\n",
    "                            break\n",
    "                    \n",
    "                    if true_rank:\n",
    "                        if true_rank == 1:\n",
    "                            print(f\"   ✅ Prédiction correcte ! (rang {true_rank})\")\n",
    "                        elif true_rank <= 3:\n",
    "                            print(f\"   🟡 Dans le top 3 (rang {true_rank})\")\n",
    "                        elif true_rank <= 5:\n",
    "                            print(f\"   🟠 Dans le top 5 (rang {true_rank})\")\n",
    "                        else:\n",
    "                            print(f\"   ❌ Hors du top 5 (rang {true_rank})\")\n",
    "                    else:\n",
    "                        print(f\"   ❌ Vraie valeur non trouvée dans les candidats\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur: {e}\")\n",
    "\n",
    "# Fonction utilitaire pour lancer une évaluation complète\n",
    "def run_complete_evaluation(json_files: List[Dict], \n",
    "                           model: 'MaskedCellPredictor',\n",
    "                           transformer_builder: 'JSONToGraphTransformer') -> str:\n",
    "    \"\"\"Lance une évaluation complète et génère le rapport\"\"\"\n",
    "    \n",
    "    evaluator = ExcelMaskedEvaluator(model, transformer_builder)\n",
    "    \n",
    "    # Générer le rapport\n",
    "    report_file = evaluator.generate_evaluation_report(json_files)\n",
    "    \n",
    "    # Afficher un résumé\n",
    "    print(\"\\n📊 RÉSUMÉ DE L'ÉVALUATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    sample_result = evaluator.evaluate_excel_file(json_files[0] if json_files else {})\n",
    "    if 'error' not in sample_result and 'strategy_results' in sample_result:\n",
    "        for strategy, result in sample_result['strategy_results'].items():\n",
    "            if 'metrics' in result:\n",
    "                metrics = result['metrics']\n",
    "                print(f\"\\n{strategy.upper()} MASKING:\")\n",
    "                print(f\"  Accuracy Top-1: {metrics.get('accuracy_top1', 0):.1%}\")\n",
    "                print(f\"  Accuracy Top-3: {metrics.get('accuracy_top3', 0):.1%}\")\n",
    "                print(f\"  MRR: {metrics.get('mrr', 0):.3f}\")\n",
    "                print(f\"  Confiance moy.: {metrics.get('avg_confidence', 0):.1%}\")\n",
    "    \n",
    "    return report_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"📋 Module d'évaluation Excel Masked Prediction chargé\")\n",
    "    print(\"Utilisez run_complete_evaluation() pour une évaluation complète\")\n",
    "    print(\"Ou ExcelMaskedEvaluator.interactive_test() pour un test interactif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
