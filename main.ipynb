{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbd9740e-606f-488c-adc6-450f320dae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.12/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cae94c70-d297-474f-904a-ba2ebc62a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Set\n",
    "from enum import Enum\n",
    "import math\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "data_folder = \"data/\"\n",
    "jsons_path = \"data/*.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a807f4-ada1-46e4-82ac-d78a74271261",
   "metadata": {},
   "source": [
    "Création de la classe FullCellInfo récupérant l'ensmeble des informations d'une cellule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cfa8d38-bca5-4b48-9f44-50e11f331653",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FullCellInfo:\n",
    "    \"\"\"Structure complète d'une cellule Excel avec les informations disponibles dans le JSON Univer\"\"\"\n",
    "    # Contenu (disponible dans le JSON)\n",
    "    raw_value: Any = \"\"\n",
    "    cell_type: int = 0  # 1=text, 2=number, 3=formula (inféré)\n",
    "    formula: str = \"\"   # \"f\" - formule si présente (avec = au début)\n",
    "    \n",
    "    # Position\n",
    "    row: int = 0\n",
    "    col: int = 0\n",
    "    sheet_id: str = \"default\"\n",
    "    sheet_name: str = \"\"\n",
    "    \n",
    "    # Style complet (basé sur le format Univer optimisé)\n",
    "    style_id: str = \"\"  # Peut être vide si pas de style\n",
    "    \n",
    "    # Formatage de texte\n",
    "    bold: bool = False          # \"bl\": 1\n",
    "    italic: bool = False        # \"it\": 1  \n",
    "    underline: bool = False     # \"ul\": {\"s\": 1}\n",
    "    strike: bool = False        # \"st\": {\"s\": 1}\n",
    "    font_size: float = 11.0     # \"fs\": size (défaut Calibri 11)\n",
    "    font_family: str = \"Calibri\" # \"ff\": family\n",
    "    \n",
    "    # Couleurs\n",
    "    text_color: str = \"#000000\"     # \"cl\": {\"rgb\": \"#color\"}\n",
    "    background_color: str = \"#FFFFFF\"  # \"bg\": {\"rgb\": \"#color\"}\n",
    "    \n",
    "    # Bordures\n",
    "    border_top: int = 0      # \"bd\": {\"t\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_bottom: int = 0   # \"bd\": {\"b\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_left: int = 0     # \"bd\": {\"l\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_right: int = 0    # \"bd\": {\"r\": {\"s\": value, \"cl\": {\"rgb\": \"#color\"}}}\n",
    "    border_color: str = \"#000000\"\n",
    "    \n",
    "    # Alignement\n",
    "    horizontal_align: int = 0  # \"ht\": 1=left, 2=center, 3=right, 4=justify\n",
    "    vertical_align: int = 0    # \"vt\": 1=top, 2=center, 3=bottom\n",
    "    text_wrap: bool = False    # \"tb\": 3\n",
    "    \n",
    "    # Rotation/Transformation\n",
    "    text_rotation: int = 0     # \"tr\": {\"a\": angle, \"v\": 0}\n",
    "    \n",
    "    # Format de nombre\n",
    "    number_format: str = \"General\"  # \"n\": {\"pattern\": \"format\"}\n",
    "    \n",
    "    # Fusion de cellules (disponible via mergeData)\n",
    "    is_merged: bool = False\n",
    "    merge_range: Tuple[int, int, int, int] = (0, 0, 0, 0)  # (startRow, endRow, startCol, endCol)\n",
    "    \n",
    "    # Métadonnées de feuille\n",
    "    sheet_hidden: bool = False\n",
    "    sheet_tab_color: str = \"\"\n",
    "    sheet_zoom: float = 1.0\n",
    "    sheet_show_gridlines: bool = True\n",
    "    \n",
    "    # Métadonnées de ligne/colonne\n",
    "    row_height: Optional[float] = None\n",
    "    row_hidden: bool = False\n",
    "    col_width: Optional[int] = None\n",
    "    col_hidden: bool = False\n",
    "    \n",
    "    # Volets figés\n",
    "    freeze_start_row: int = -1\n",
    "    freeze_start_col: int = -1\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Post-processing après création\"\"\"\n",
    "        # Le type est défini par \"t\" dans le JSON ou inféré du contenu\n",
    "        if self.cell_type == 0:  # Si pas de type défini\n",
    "            if self.formula:\n",
    "                self.cell_type = 3\n",
    "            elif isinstance(self.raw_value, (int, float)):\n",
    "                self.cell_type = 2\n",
    "            elif isinstance(self.raw_value, str) and self.raw_value.strip():\n",
    "                self.cell_type = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef97d7-8054-4630-afd8-51c40872a5f2",
   "metadata": {},
   "source": [
    "Classe pour générer les FullCellInfo à partir d'un json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "325735e2-438e-4887-8588-8e2575063cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcelParser:\n",
    "    \"\"\"Parse les fichiers Excel JSON Univer en structures FullCellInfo\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_excel_json(excel_data: Dict) -> List['FullCellInfo']:\n",
    "        \"\"\"Convertit JSON Excel Univer en liste de FullCellInfo\"\"\"\n",
    "        cells = []  \n",
    "        \n",
    "        styles = excel_data.get('styles', {})\n",
    "        \n",
    "        for sheet_id, sheet_info in excel_data.get('sheets', {}).items():\n",
    "            sheet_name = sheet_info.get('name', \"\")\n",
    "            cell_data = sheet_info.get('cellData', {})\n",
    "            merge_data = sheet_info.get('mergeData', [])\n",
    "            row_data = sheet_info.get('rowData', {})\n",
    "            column_data = sheet_info.get('columnData', {})\n",
    "            freeze_info = sheet_info.get('freeze', {})\n",
    "            \n",
    "            # Métadonnées de feuille\n",
    "            sheet_hidden = bool(sheet_info.get('hidden', 0))\n",
    "            sheet_tab_color = sheet_info.get('tabColor', \"\")\n",
    "            sheet_zoom = sheet_info.get('zoomRatio', 1.0)\n",
    "            sheet_show_gridlines = bool(sheet_info.get('showGridlines', 1))\n",
    "            \n",
    "            # Informations de volets figés\n",
    "            freeze_start_row = freeze_info.get('startRow', -1)\n",
    "            freeze_start_col = freeze_info.get('startColumn', -1)\n",
    "            \n",
    "            # Créer un mapping des cellules fusionnées\n",
    "            merge_map = ExcelParser._create_merge_map(merge_data)\n",
    "            \n",
    "            for row_str, row_cells in cell_data.items():\n",
    "                row = int(row_str)\n",
    "                \n",
    "                # Informations de ligne\n",
    "                row_info = row_data.get(row_str, {})\n",
    "                row_height = row_info.get('h')\n",
    "                row_hidden = bool(row_info.get('hd', 0))\n",
    "                \n",
    "                for col_str, cell_info in row_cells.items():\n",
    "                    col = int(col_str)\n",
    "                    \n",
    "                    # Informations de colonne\n",
    "                    col_info = column_data.get(col_str, {})\n",
    "                    col_width = col_info.get('w')\n",
    "                    col_hidden = bool(col_info.get('hd', 0))\n",
    "                    \n",
    "                    # Extraire les informations de style\n",
    "                    style_id = cell_info.get('s', '')\n",
    "                    style = styles.get(style_id, {}) if style_id else {}\n",
    "                    \n",
    "                    # Vérifier si cette cellule fait partie d'une fusion\n",
    "                    merge_info = merge_map.get((row, col), None)\n",
    "                    \n",
    "                    cell = FullCellInfo(\n",
    "                        raw_value=cell_info.get('v', ''),\n",
    "                        cell_type=cell_info.get('t', 0),\n",
    "                        formula=cell_info.get('f', ''),\n",
    "                        row=row,\n",
    "                        col=col,\n",
    "                        sheet_id=sheet_id,\n",
    "                        sheet_name=sheet_name,\n",
    "                        style_id=style_id,\n",
    "                        is_merged=merge_info is not None,\n",
    "                        merge_range=merge_info if merge_info else (0, 0, 0, 0),\n",
    "                        sheet_hidden=sheet_hidden,\n",
    "                        sheet_tab_color=sheet_tab_color,\n",
    "                        sheet_zoom=sheet_zoom,\n",
    "                        sheet_show_gridlines=sheet_show_gridlines,\n",
    "                        row_height=row_height,\n",
    "                        row_hidden=row_hidden,\n",
    "                        col_width=col_width,\n",
    "                        col_hidden=col_hidden,\n",
    "                        freeze_start_row=freeze_start_row,\n",
    "                        freeze_start_col=freeze_start_col,\n",
    "                        **ExcelParser._parse_style(style)\n",
    "                    )\n",
    "                    \n",
    "                    cells.append(cell)  \n",
    "        \n",
    "        return cells\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_merge_map(merge_data: List[Dict]) -> Dict[Tuple[int, int], Tuple[int, int, int, int]]:\n",
    "        \"\"\"Crée un mapping des cellules fusionnées\"\"\"\n",
    "        merge_map = {}\n",
    "        \n",
    "        for merge in merge_data:\n",
    "            start_row = merge['startRow']\n",
    "            end_row = merge['endRow'] \n",
    "            start_col = merge['startColumn']\n",
    "            end_col = merge['endColumn']\n",
    "            \n",
    "            # Marquer toutes les cellules dans cette plage comme fusionnées\n",
    "            for row in range(start_row, end_row + 1):\n",
    "                for col in range(start_col, end_col + 1):\n",
    "                    merge_map[(row, col)] = (start_row, end_row, start_col, end_col)\n",
    "        \n",
    "        return merge_map\n",
    "    \n",
    "    @staticmethod\n",
    "    def _parse_style(style: Dict) -> Dict:\n",
    "        \"\"\"Parse les informations de style basé sur le format Univer optimisé\"\"\"\n",
    "        parsed = {\n",
    "            'bold': bool(style.get('bl', 0)),\n",
    "            'italic': bool(style.get('it', 0)),\n",
    "            'font_size': float(style.get('fs', 11.0)),\n",
    "            'font_family': style.get('ff', 'Calibri'),\n",
    "            'text_wrap': bool(style.get('tb', 0) == 3),  # tb: 3 = wrap\n",
    "        }\n",
    "        \n",
    "        # Underline - structure: \"ul\": {\"s\": 1}\n",
    "        ul_info = style.get('ul', {})\n",
    "        if isinstance(ul_info, dict):\n",
    "            parsed['underline'] = bool(ul_info.get('s', 0))\n",
    "        else:\n",
    "            parsed['underline'] = bool(ul_info)\n",
    "        \n",
    "        # Strike - structure: \"st\": {\"s\": 1}\n",
    "        st_info = style.get('st', {})\n",
    "        if isinstance(st_info, dict):\n",
    "            parsed['strike'] = bool(st_info.get('s', 0))\n",
    "        else:\n",
    "            parsed['strike'] = bool(st_info)\n",
    "        \n",
    "        # Couleurs\n",
    "        if 'cl' in style:  # text color\n",
    "            parsed['text_color'] = style['cl'].get('rgb', '#000000')\n",
    "        if 'bg' in style:  # background color\n",
    "            parsed['background_color'] = style['bg'].get('rgb', '#FFFFFF')\n",
    "            \n",
    "        # Bordures - structure: \"bd\": {\"t\": {\"s\": 8, \"cl\": {\"rgb\": \"#000000\"}}}\n",
    "        borders = style.get('bd', {})\n",
    "        parsed.update({\n",
    "            'border_top': borders.get('t', {}).get('s', 0),\n",
    "            'border_bottom': borders.get('b', {}).get('s', 0),\n",
    "            'border_left': borders.get('l', {}).get('s', 0),\n",
    "            'border_right': borders.get('r', {}).get('s', 0),\n",
    "        })\n",
    "        \n",
    "        # Couleur de bordure (prendre la première trouvée)\n",
    "        border_color = \"#000000\"\n",
    "        for border_side in ['t', 'b', 'l', 'r']:\n",
    "            if border_side in borders and 'cl' in borders[border_side]:\n",
    "                border_color = borders[border_side]['cl'].get('rgb', '#000000')\n",
    "                break\n",
    "        parsed['border_color'] = border_color\n",
    "        \n",
    "        # Alignement (mapping exact du convertisseur)\n",
    "        parsed.update({\n",
    "            'horizontal_align': style.get('ht', 0),  # 1=left, 2=center, 3=right, 4=justify\n",
    "            'vertical_align': style.get('vt', 0),    # 1=top, 2=center, 3=bottom\n",
    "        })\n",
    "        \n",
    "        # Rotation/Transformation - \"tr\": {\"a\": angle, \"v\": 0}\n",
    "        tr_info = style.get('tr', {})\n",
    "        if isinstance(tr_info, dict):\n",
    "            parsed['text_rotation'] = tr_info.get('a', 0)  # angle\n",
    "        else:\n",
    "            parsed['text_rotation'] = 0\n",
    "        \n",
    "        # Format de nombre - structure: \"n\": {\"pattern\": \"format\"}\n",
    "        number_info = style.get('n', {})\n",
    "        if isinstance(number_info, dict):\n",
    "            parsed['number_format'] = number_info.get('pattern', 'General')\n",
    "        else:\n",
    "            parsed['number_format'] = 'General'\n",
    "        \n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c348c-af2f-43bb-9bc3-9b8cf5421447",
   "metadata": {},
   "source": [
    "Tokenisation d'un classeur : [POS:1,0][TYPE:TEXT][STYLE:B,I,BG:#4470C4][VALUE:Map brief][MERGE:1,2,0,6][LAYOUT:RH:25.2,CW:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "401e09af-a884-4155-b3dd-c0bc83ebbe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcelDataProcessor:\n",
    "    \"\"\"Classe pour préparer les données Excel pour l'entraînement de transformers\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def cells_to_text_sequence(cells: List[FullCellInfo], include_empty_cells: bool = False) -> str:\n",
    "        \"\"\"Convertit une liste de cellules en séquence de texte pour l'entraînement\"\"\"\n",
    "        sequences = []\n",
    "        \n",
    "        # Regrouper par feuille et position\n",
    "        sheets = {}\n",
    "        for cell in cells:\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append(cell)\n",
    "        \n",
    "        for sheet_name, sheet_cells in sheets.items():\n",
    "            # Trier par position (row, col)\n",
    "            sheet_cells.sort(key=lambda c: (c.row, c.col))\n",
    "            \n",
    "            # Métadonnées de feuille enrichies\n",
    "            sheet_meta = f\"[SHEET:{sheet_name}\"\n",
    "            if sheet_cells:\n",
    "                first_cell = sheet_cells[0]\n",
    "                if first_cell.sheet_hidden:\n",
    "                    sheet_meta += \",HIDDEN\"\n",
    "                if first_cell.sheet_tab_color:\n",
    "                    sheet_meta += f\",TAB:{first_cell.sheet_tab_color}\"\n",
    "                if first_cell.sheet_zoom != 1.0:\n",
    "                    sheet_meta += f\",ZOOM:{first_cell.sheet_zoom}\"\n",
    "                if not first_cell.sheet_show_gridlines:\n",
    "                    sheet_meta += \",NO_GRID\"\n",
    "                if first_cell.freeze_start_row >= 0 or first_cell.freeze_start_col >= 0:\n",
    "                    sheet_meta += f\",FREEZE:{first_cell.freeze_start_row},{first_cell.freeze_start_col}\"\n",
    "            sheet_meta += \"]\"\n",
    "            \n",
    "            sheet_text = sheet_meta\n",
    "            for cell in sheet_cells:\n",
    "                if not include_empty_cells and not cell.raw_value and not cell.is_merged and not cell.style_id:\n",
    "                    continue\n",
    "                cell_repr = ExcelDataProcessor._cell_to_token(cell)\n",
    "                sheet_text += f\" {cell_repr}\"\n",
    "            \n",
    "            sequences.append(sheet_text)\n",
    "        \n",
    "        return \" [SHEET_END] \".join(sequences)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _cell_to_token(cell: FullCellInfo) -> str:\n",
    "        \"\"\"Convertit une cellule en token enrichi pour le transformer\"\"\"\n",
    "        # Format: [POS:row,col][TYPE:t][STYLE:...][VALUE:...][MERGE:...][ROW/COL:...]\n",
    "        pos = f\"[POS:{cell.row},{cell.col}]\"\n",
    "        \n",
    "        # Type de cellule\n",
    "        type_map = {0: \"EMPTY\", 1: \"TEXT\", 2: \"NUMBER\", 3: \"FORMULA\"}\n",
    "        cell_type = f\"[TYPE:{type_map.get(cell.cell_type, 'UNKNOWN')}]\"\n",
    "        \n",
    "        # Style simplifié pour le token\n",
    "        style_parts = []\n",
    "        if cell.bold: style_parts.append(\"B\")\n",
    "        if cell.italic: style_parts.append(\"I\") \n",
    "        if cell.underline: style_parts.append(\"U\")\n",
    "        if cell.strike: style_parts.append(\"S\")\n",
    "        if cell.background_color != \"#FFFFFF\": \n",
    "            style_parts.append(f\"BG:{cell.background_color}\")\n",
    "        if cell.text_rotation != 0: \n",
    "            style_parts.append(f\"ROT:{cell.text_rotation}\")\n",
    "        if any([cell.border_top, cell.border_bottom, cell.border_left, cell.border_right]):\n",
    "            style_parts.append(\"BORDER\")\n",
    "        if cell.horizontal_align != 0:\n",
    "            align_map = {1: \"LEFT\", 2: \"CENTER\", 3: \"RIGHT\", 4: \"JUSTIFY\"}\n",
    "            style_parts.append(f\"ALIGN:{align_map.get(cell.horizontal_align, 'UNKNOWN')}\")\n",
    "        if cell.text_wrap:\n",
    "            style_parts.append(\"WRAP\")\n",
    "        if cell.font_size != 11.0:\n",
    "            style_parts.append(f\"SIZE:{cell.font_size}\")\n",
    "        if cell.font_family != \"Calibri\":\n",
    "            style_parts.append(f\"FONT:{cell.font_family}\")\n",
    "        \n",
    "        style = f\"[STYLE:{','.join(style_parts)}]\" if style_parts else \"[STYLE:NONE]\"\n",
    "        \n",
    "        # Valeur (formule ou valeur)\n",
    "        if cell.formula:\n",
    "            # Formule avec = au début selon le convertisseur\n",
    "            formula_clean = cell.formula.lstrip('=')\n",
    "            value = f\"[FORMULA:={formula_clean}]\"\n",
    "        else:\n",
    "            value = f\"[VALUE:{cell.raw_value}]\"\n",
    "        \n",
    "        # Ajout information de fusion\n",
    "        merge = \"\"\n",
    "        if cell.is_merged:\n",
    "            sr, er, sc, ec = cell.merge_range\n",
    "            merge = f\"[MERGE:{sr},{er},{sc},{ec}]\"\n",
    "        \n",
    "        # Informations de ligne/colonne si non-standard\n",
    "        layout = \"\"\n",
    "        layout_parts = []\n",
    "        if cell.row_height is not None:\n",
    "            layout_parts.append(f\"RH:{cell.row_height}\")\n",
    "        if cell.row_hidden:\n",
    "            layout_parts.append(\"ROW_HIDDEN\")\n",
    "        if cell.col_width is not None:\n",
    "            layout_parts.append(f\"CW:{cell.col_width}\")\n",
    "        if cell.col_hidden:\n",
    "            layout_parts.append(\"COL_HIDDEN\")\n",
    "        \n",
    "        if layout_parts:\n",
    "            layout = f\"[LAYOUT:{','.join(layout_parts)}]\"\n",
    "        \n",
    "        return f\"{pos}{cell_type}{style}{value}{merge}{layout}\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_workbook_metadata(cells: List[FullCellInfo]) -> Dict[str, Any]:\n",
    "        \"\"\"Extrait les métadonnées complètes du classeur\"\"\"\n",
    "        if not cells:\n",
    "            return {}\n",
    "        \n",
    "        sheet_metadata = {}\n",
    "        \n",
    "        for cell in cells:\n",
    "            if cell.sheet_name not in sheet_metadata:\n",
    "                sheet_metadata[cell.sheet_name] = {\n",
    "                    'sheet_id': cell.sheet_id,\n",
    "                    'hidden': cell.sheet_hidden,\n",
    "                    'tab_color': cell.sheet_tab_color,\n",
    "                    'zoom': cell.sheet_zoom,\n",
    "                    'show_gridlines': cell.sheet_show_gridlines,\n",
    "                    'freeze_panes': (cell.freeze_start_row, cell.freeze_start_col) if cell.freeze_start_row >= 0 or cell.freeze_start_col >= 0 else None,\n",
    "                    'cell_count': 0,\n",
    "                    'merged_count': 0,\n",
    "                    'formula_count': 0,\n",
    "                    'styles_used': set(),\n",
    "                    'max_row': 0,\n",
    "                    'max_col': 0,\n",
    "                    'custom_row_heights': 0,\n",
    "                    'custom_col_widths': 0,\n",
    "                    'hidden_rows': 0,\n",
    "                    'hidden_cols': 0\n",
    "                }\n",
    "            \n",
    "            meta = sheet_metadata[cell.sheet_name]\n",
    "            meta['cell_count'] += 1\n",
    "            meta['max_row'] = max(meta['max_row'], cell.row)\n",
    "            meta['max_col'] = max(meta['max_col'], cell.col)\n",
    "            \n",
    "            if cell.is_merged:\n",
    "                meta['merged_count'] += 1\n",
    "            if cell.formula:\n",
    "                meta['formula_count'] += 1\n",
    "            if cell.style_id:\n",
    "                meta['styles_used'].add(cell.style_id)\n",
    "            if cell.row_height is not None:\n",
    "                meta['custom_row_heights'] += 1\n",
    "            if cell.col_width is not None:\n",
    "                meta['custom_col_widths'] += 1\n",
    "            if cell.row_hidden:\n",
    "                meta['hidden_rows'] += 1\n",
    "            if cell.col_hidden:\n",
    "                meta['hidden_cols'] += 1\n",
    "        \n",
    "        # Convertir les sets en listes pour la sérialisation\n",
    "        for meta in sheet_metadata.values():\n",
    "            meta['styles_used'] = list(meta['styles_used'])\n",
    "        \n",
    "        return {\n",
    "            'sheets': sheet_metadata,\n",
    "            'total_cells': len(cells),\n",
    "            'total_sheets': len(sheet_metadata),\n",
    "            'total_merged_cells': sum(meta['merged_count'] for meta in sheet_metadata.values()),\n",
    "            'total_formulas': sum(meta['formula_count'] for meta in sheet_metadata.values()),\n",
    "            'total_styles': len(set(cell.style_id for cell in cells if cell.style_id))\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748e56d-a71b-4c4f-b48f-ce17391fc9a0",
   "metadata": {},
   "source": [
    "Embedder depuis FullCellInfo : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c13001e0-ba4b-42fd-bccb-06ab8dcd3ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dimension avant projection: 616\n",
      "Embedding shape: torch.Size([256])\n",
      "Embedding (premiers 10 éléments): tensor([-0.2624,  0.6277, -0.1341, -0.0217, -1.5651, -1.6880, -0.9782,  1.3257,\n",
      "        -1.0761,  0.7506])\n",
      "Batch embedding shape: torch.Size([3, 256])\n",
      "Nombre total de paramètres: 562,320\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class EmbeddingConfig:\n",
    "    \"\"\"Configuration pour l'embedder Excel\"\"\"\n",
    "    # Dimensions\n",
    "    embedding_dim: int = 256\n",
    "    position_embedding_dim: int = 24\n",
    "    type_embedding_dim: int = 16\n",
    "    \n",
    "    # Vocabulaires fixes\n",
    "    max_position: int = 1000  # pour row/col\n",
    "    max_value_length: int = 100\n",
    "    max_font_size: int = 72\n",
    "    \n",
    "    # Couleurs (nombre de couleurs possibles)\n",
    "    color_vocab_size: int = 100\n",
    "    \n",
    "    # Alignements, bordures, etc.\n",
    "    align_vocab_size: int = 5\n",
    "    border_vocab_size: int = 10\n",
    "    font_vocab_size: int = 20\n",
    "\n",
    "class ExcelCellEmbedder(nn.Module):\n",
    "    \"\"\"Embedder direct pour FullCellInfo avec dimensions corrigées\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Position et Type\n",
    "        self.row_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "        self.col_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "        self.type_embedding = nn.Embedding(4, config.type_embedding_dim)\n",
    "        \n",
    "        # Contenu (valeur/formule)\n",
    "        self.value_encoder = ValueEncoder(config)\n",
    "        \n",
    "        # Formatage booléen\n",
    "        self.bool_embedding = nn.Embedding(2, 8)\n",
    "        \n",
    "        # Police\n",
    "        self.font_size_embedding = nn.Embedding(config.max_font_size + 1, 16)\n",
    "        self.font_family_embedding = nn.Embedding(config.font_vocab_size, 32)\n",
    "        \n",
    "        # Couleurs\n",
    "        self.color_embedding = nn.Embedding(config.color_vocab_size, 24)\n",
    "        \n",
    "        # Alignement\n",
    "        self.align_h_embedding = nn.Embedding(config.align_vocab_size, 16)\n",
    "        self.align_v_embedding = nn.Embedding(config.align_vocab_size, 16)\n",
    "        self.rotation_embedding = nn.Embedding(361, 16)\n",
    "        \n",
    "        # Bordures\n",
    "        self.border_embedding = nn.Embedding(config.border_vocab_size, 16)\n",
    "        \n",
    "        # Fusion\n",
    "        self.merge_encoder = MergeEncoder(config)\n",
    "        \n",
    "        # CALCUL CORRECT DES DIMENSIONS\n",
    "        total_dim = (\n",
    "            2 * config.position_embedding_dim +    # row(32) + col(32) = 64\n",
    "            config.type_embedding_dim +            # type = 16\n",
    "            self.value_encoder.output_dim +        # value = 256\n",
    "            4 * 8 +                                # 4 bools = 32\n",
    "            16 + 32 +                              # font_size + font_family = 48\n",
    "            2 * 24 +                               # 2 colors = 48\n",
    "            2 * 16 + 8 + 16 +                     # align_h + align_v + wrap + rotation = 56\n",
    "            4 * 16 +                               # 4 borders = 64\n",
    "            self.merge_encoder.output_dim          # merge = 32\n",
    "        )  # Total = 64+16+256+32+48+48+56+64+32 = 616\n",
    "        \n",
    "        print(f\"Total dimension avant projection: {total_dim}\")\n",
    "        \n",
    "        # Projection finale\n",
    "        self.projection = nn.Linear(total_dim, config.embedding_dim)\n",
    "        self.layer_norm = nn.LayerNorm(config.embedding_dim)\n",
    "        \n",
    "        # Vocabulaires pour la conversion\n",
    "        self._build_vocabularies()\n",
    "    \n",
    "    def _calculate_total_dim(self) -> int:\n",
    "        \"\"\"Calcule la dimension totale avant projection\"\"\"\n",
    "        return (\n",
    "            2 * self.config.position_embedding_dim +\n",
    "            self.config.type_embedding_dim +\n",
    "            self.value_encoder.output_dim +\n",
    "            4 * 8 +                    # bools\n",
    "            16 + 32 +                  # font\n",
    "            2 * 24 +                   # colors\n",
    "            2 * 16 + 8 + 16 +         # alignment\n",
    "            4 * 16 +                   # borders\n",
    "            32                         # merge (fixed size)\n",
    "        )\n",
    "    \n",
    "    def _build_vocabularies(self):\n",
    "        \"\"\"Construit les vocabulaires de conversion\"\"\"\n",
    "        self.font_families = [\n",
    "            \"Calibri\", \"Arial\", \"Times New Roman\", \"Helvetica\", \"Verdana\",\n",
    "            \"Georgia\", \"Courier New\", \"Tahoma\", \"Comic Sans MS\", \"Impact\"\n",
    "        ]\n",
    "        self.font_family_to_id = {font: i for i, font in enumerate(self.font_families)}\n",
    "    \n",
    "    def forward(self, cells: Union['FullCellInfo', List['FullCellInfo']]) -> torch.Tensor:\n",
    "        if not isinstance(cells, list):\n",
    "            cells = [cells]\n",
    "        \n",
    "        embeddings = []\n",
    "        \n",
    "        for cell in cells:\n",
    "            # Position\n",
    "            row_emb = self.row_embedding(torch.clamp(torch.tensor(cell.row), 0, self.config.max_position - 1))\n",
    "            col_emb = self.col_embedding(torch.clamp(torch.tensor(cell.col), 0, self.config.max_position - 1))\n",
    "            \n",
    "            # Type\n",
    "            type_emb = self.type_embedding(torch.tensor(cell.cell_type))\n",
    "            \n",
    "            # Contenu\n",
    "            value_emb = self.value_encoder(cell)\n",
    "            \n",
    "            # Formatage booléen\n",
    "            bold_emb = self.bool_embedding(torch.tensor(int(cell.bold)))\n",
    "            italic_emb = self.bool_embedding(torch.tensor(int(cell.italic)))\n",
    "            underline_emb = self.bool_embedding(torch.tensor(int(cell.underline)))\n",
    "            strike_emb = self.bool_embedding(torch.tensor(int(cell.strike)))\n",
    "            \n",
    "            # Police\n",
    "            font_size = min(int(cell.font_size), self.config.max_font_size)\n",
    "            font_size_emb = self.font_size_embedding(torch.tensor(font_size))\n",
    "            \n",
    "            font_id = self.font_family_to_id.get(cell.font_family, 0)\n",
    "            font_family_emb = self.font_family_embedding(torch.tensor(font_id))\n",
    "            \n",
    "            # Couleurs\n",
    "            text_color_id = self._color_to_id(cell.text_color)\n",
    "            bg_color_id = self._color_to_id(cell.background_color)\n",
    "            text_color_emb = self.color_embedding(torch.tensor(text_color_id))\n",
    "            bg_color_emb = self.color_embedding(torch.tensor(bg_color_id))\n",
    "            \n",
    "            # Alignement\n",
    "            align_h_emb = self.align_h_embedding(torch.tensor(cell.horizontal_align))\n",
    "            align_v_emb = self.align_v_embedding(torch.tensor(cell.vertical_align))\n",
    "            wrap_emb = self.bool_embedding(torch.tensor(int(cell.text_wrap)))\n",
    "            rotation = min(abs(cell.text_rotation), 360)\n",
    "            rotation_emb = self.rotation_embedding(torch.tensor(rotation))\n",
    "            \n",
    "            # Bordures\n",
    "            border_top_emb = self.border_embedding(torch.tensor(self._border_to_id(cell.border_top)))\n",
    "            border_bottom_emb = self.border_embedding(torch.tensor(self._border_to_id(cell.border_bottom)))\n",
    "            border_left_emb = self.border_embedding(torch.tensor(self._border_to_id(cell.border_left)))\n",
    "            border_right_emb = self.border_embedding(torch.tensor(self._border_to_id(cell.border_right)))\n",
    "            \n",
    "            # Fusion\n",
    "            merge_emb = self.merge_encoder(cell)\n",
    "            \n",
    "            # Concaténer tous les embeddings\n",
    "            cell_embedding = torch.cat([\n",
    "                row_emb, col_emb, type_emb, value_emb,\n",
    "                bold_emb, italic_emb, underline_emb, strike_emb,\n",
    "                font_size_emb, font_family_emb,\n",
    "                text_color_emb, bg_color_emb,\n",
    "                align_h_emb, align_v_emb, wrap_emb, rotation_emb,\n",
    "                border_top_emb, border_bottom_emb, border_left_emb, border_right_emb,\n",
    "                merge_emb\n",
    "            ], dim=0)\n",
    "            \n",
    "            embeddings.append(cell_embedding)\n",
    "        \n",
    "        # Stack et projeter\n",
    "        batch_embeddings = torch.stack(embeddings)\n",
    "        projected = self.projection(batch_embeddings)\n",
    "        normalized = self.layer_norm(projected)\n",
    "        \n",
    "        return normalized.squeeze(0) if len(cells) == 1 else normalized\n",
    "    \n",
    "    def _color_to_id(self, color: str) -> int:\n",
    "        \"\"\"Convertit une couleur hex en ID\"\"\"\n",
    "        if not color or color == \"#FFFFFF\":\n",
    "            return 0\n",
    "        try:\n",
    "            hex_val = int(color.replace(\"#\", \"\"), 16)\n",
    "            return (hex_val % (self.config.color_vocab_size - 1)) + 1\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def _border_to_id(self, border_style: int) -> int:\n",
    "        \"\"\"Convertit un style de bordure en ID\"\"\"\n",
    "        border_map = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 7: 5, 8: 6, 13: 7}\n",
    "        return border_map.get(border_style, 0)\n",
    "\n",
    "@dataclass\n",
    "class EmbeddingConfig:\n",
    "    \"\"\"Configuration pour l'embedder Excel - CORRIGÉE\"\"\"\n",
    "    # Dimensions principales\n",
    "    embedding_dim: int = 256\n",
    "    position_embedding_dim: int = 32\n",
    "    type_embedding_dim: int = 16\n",
    "    \n",
    "    # Vocabulaires fixes\n",
    "    max_position: int = 1000\n",
    "    max_font_size: int = 72\n",
    "    color_vocab_size: int = 100\n",
    "    align_vocab_size: int = 5\n",
    "    border_vocab_size: int = 10\n",
    "    font_vocab_size: int = 20\n",
    "    \n",
    "    # AJOUT : Paramètres pour ValueEncoder\n",
    "    max_value_tokens: int = 8\n",
    "    value_token_dim: int = 32\n",
    "    value_vocab_size: int = 10000\n",
    "\n",
    "class ValueEncoder(nn.Module):\n",
    "    \"\"\"Encodeur spécialisé pour les valeurs de cellules - CORRIGÉ\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.max_tokens = config.max_value_tokens  # FIXÉ\n",
    "        self.token_dim = config.value_token_dim    # FIXÉ\n",
    "        self.output_dim = self.max_tokens * self.token_dim  # 8 * 32 = 256D\n",
    "        \n",
    "        # Tokenizer simple\n",
    "        self.vocab_size = config.value_vocab_size  # FIXÉ\n",
    "        self.token_embedding = nn.Embedding(self.vocab_size, self.token_dim)\n",
    "        \n",
    "        # Embeddings spéciaux\n",
    "        self.mask_token_id = 1000\n",
    "        self.pad_token_id = 0\n",
    "        self.unk_token_id = 1\n",
    "        self.number_token_id = 2\n",
    "        self.formula_start_id = 3\n",
    "        \n",
    "        # Encodeur de position pour les tokens\n",
    "        self.token_position_embedding = nn.Embedding(self.max_tokens, self.token_dim)\n",
    "        \n",
    "        # Classification du type de contenu\n",
    "        self.content_type_embedding = nn.Embedding(4, self.token_dim)\n",
    "        \n",
    "    def forward(self, cell: 'FullCellInfo', mask_content: bool = False) -> torch.Tensor:\n",
    "        \"\"\"Encode la valeur en séquence de tokens\"\"\"\n",
    "        if mask_content:\n",
    "            tokens = [self.mask_token_id] * self.max_tokens\n",
    "            content_type = 0\n",
    "        elif cell.formula:\n",
    "            tokens = self._tokenize_formula(cell.formula)\n",
    "            content_type = 3  # FORMULA\n",
    "        elif cell.raw_value and cell.cell_type == 2:  # Number\n",
    "            tokens = self._tokenize_number(cell.raw_value)\n",
    "            content_type = 2  # NUMBER\n",
    "        elif cell.raw_value and cell.cell_type == 1:  # Text\n",
    "            tokens = self._tokenize_text(str(cell.raw_value))\n",
    "            content_type = 1  # TEXT\n",
    "        else:\n",
    "            tokens = [self.pad_token_id] * self.max_tokens\n",
    "            content_type = 0  # EMPTY\n",
    "        \n",
    "        # Padding/truncation à max_tokens\n",
    "        if len(tokens) > self.max_tokens:\n",
    "            tokens = tokens[:self.max_tokens]\n",
    "        else:\n",
    "            tokens.extend([self.pad_token_id] * (self.max_tokens - len(tokens)))\n",
    "        \n",
    "        # Convertir en embeddings\n",
    "        token_ids = torch.tensor(tokens)\n",
    "        token_embs = self.token_embedding(token_ids)  # [max_tokens, token_dim]\n",
    "        \n",
    "        # Ajouter encodage positionnel\n",
    "        positions = torch.arange(self.max_tokens)\n",
    "        pos_embs = self.token_position_embedding(positions)\n",
    "        \n",
    "        # Ajouter type de contenu à chaque token\n",
    "        content_type_emb = self.content_type_embedding(torch.tensor(content_type))\n",
    "        content_type_emb = content_type_emb.unsqueeze(0).expand(self.max_tokens, -1)\n",
    "        \n",
    "        # Combiner\n",
    "        combined_embs = token_embs + pos_embs + content_type_emb  # [max_tokens, token_dim]\n",
    "        \n",
    "        # Aplatir pour la sortie\n",
    "        return combined_embs.flatten()  # [max_tokens * token_dim] = [256]\n",
    "    \n",
    "    def _tokenize_text(self, text: str) -> List[int]:\n",
    "        \"\"\"Tokenise le texte (version simplifiée)\"\"\"\n",
    "        words = text.lower().split()[:self.max_tokens]\n",
    "        tokens = []\n",
    "        for word in words:\n",
    "            token_id = (hash(word) % (self.vocab_size - 10)) + 10\n",
    "            tokens.append(token_id)\n",
    "        return tokens\n",
    "    \n",
    "    def _tokenize_number(self, value: Any) -> List[int]:\n",
    "        \"\"\"Tokenise un nombre\"\"\"\n",
    "        try:\n",
    "            num_str = str(float(value))\n",
    "            tokens = [self.number_token_id]\n",
    "            for char in num_str[:self.max_tokens-1]:\n",
    "                if char.isdigit():\n",
    "                    tokens.append(ord(char) - ord('0') + 4)\n",
    "                elif char == '.':\n",
    "                    tokens.append(14)\n",
    "                elif char == '-':\n",
    "                    tokens.append(15)\n",
    "            return tokens\n",
    "        except:\n",
    "            return [self.unk_token_id]\n",
    "    \n",
    "    def _tokenize_formula(self, formula: str) -> List[int]:\n",
    "        \"\"\"Tokenise une formule Excel\"\"\"\n",
    "        tokens = [self.formula_start_id]\n",
    "        # Simplification pour l'exemple\n",
    "        char_tokens = [ord(c) % 100 + 100 for c in formula[:self.max_tokens-1]]\n",
    "        tokens.extend(char_tokens)\n",
    "        return tokens\n",
    "\n",
    "        \n",
    "class MergeEncoder(nn.Module):\n",
    "    \"\"\"Encodeur pour les informations de fusion\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.output_dim = 32\n",
    "        \n",
    "        # Embeddings pour les coordonnées de fusion\n",
    "        self.merge_coord_embedding = nn.Embedding(config.max_position, 8)\n",
    "        self.merge_projection = nn.Linear(4 * 8, self.output_dim)\n",
    "        self.no_merge_embedding = nn.Parameter(torch.randn(self.output_dim))\n",
    "    \n",
    "    def forward(self, cell: 'FullCellInfo') -> torch.Tensor:\n",
    "        \"\"\"Encode les informations de fusion\"\"\"\n",
    "        if not cell.is_merged:\n",
    "            return self.no_merge_embedding\n",
    "        \n",
    "        sr, er, sc, ec = cell.merge_range\n",
    "        \n",
    "        # Limiter les coordonnées\n",
    "        sr = min(sr, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        er = min(er, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        sc = min(sc, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        ec = min(ec, self.merge_coord_embedding.num_embeddings - 1)\n",
    "        \n",
    "        # Embeddings des coordonnées\n",
    "        sr_emb = self.merge_coord_embedding(torch.tensor(sr))\n",
    "        er_emb = self.merge_coord_embedding(torch.tensor(er))\n",
    "        sc_emb = self.merge_coord_embedding(torch.tensor(sc))\n",
    "        ec_emb = self.merge_coord_embedding(torch.tensor(ec))\n",
    "        \n",
    "        # Concaténer et projeter\n",
    "        merge_vec = torch.cat([sr_emb, er_emb, sc_emb, ec_emb])\n",
    "        return self.merge_projection(merge_vec)\n",
    "\n",
    "class ExcelSheetEmbedder(nn.Module):\n",
    "    \"\"\"Embedder pour des feuilles entières\"\"\"\n",
    "    \n",
    "    def __init__(self, config: EmbeddingConfig):\n",
    "        super().__init__()\n",
    "        self.cell_embedder = ExcelCellEmbedder(config)\n",
    "        self.position_encoder = PositionalEncoder(config.embedding_dim)\n",
    "        \n",
    "    def forward(self, cells: List['FullCellInfo'], max_cells: Optional[int] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Embed une feuille entière\n",
    "        \n",
    "        Args:\n",
    "            cells: Liste de cellules\n",
    "            max_cells: Nombre maximum de cellules (pour padding)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor [num_cells, embedding_dim] ou [max_cells, embedding_dim]\n",
    "        \"\"\"\n",
    "        # Trier par position\n",
    "        sorted_cells = sorted(cells, key=lambda c: (c.row, c.col))\n",
    "        \n",
    "        if max_cells:\n",
    "            # Padding ou troncature\n",
    "            if len(sorted_cells) > max_cells:\n",
    "                sorted_cells = sorted_cells[:max_cells]\n",
    "            elif len(sorted_cells) < max_cells:\n",
    "                # Créer des cellules vides pour le padding\n",
    "                empty_cell = self._create_empty_cell()\n",
    "                sorted_cells.extend([empty_cell] * (max_cells - len(sorted_cells)))\n",
    "        \n",
    "        # Embedder toutes les cellules\n",
    "        cell_embeddings = self.cell_embedder(sorted_cells)\n",
    "        \n",
    "        # Ajouter l'encodage positionnel\n",
    "        positioned_embeddings = self.position_encoder(cell_embeddings)\n",
    "        \n",
    "        return positioned_embeddings\n",
    "    \n",
    "    def _create_empty_cell(self) -> 'FullCellInfo':\n",
    "        \"\"\"Crée une cellule vide pour le padding\"\"\"\n",
    "        # Retourner une cellule avec toutes les valeurs par défaut\n",
    "        # Cette implémentation dépend de votre classe FullCellInfo\n",
    "        pass\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    \"\"\"Encodage positionnel pour les séquences de cellules\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int, max_length: int = 10000):\n",
    "        super().__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_length, embedding_dim)\n",
    "        position = torch.arange(0, max_length).unsqueeze(1).float()\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() *\n",
    "                           -(np.log(10000.0) / embedding_dim))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Ajoute l'encodage positionnel\"\"\"\n",
    "        seq_len = x.size(0)\n",
    "        return x + self.pe[:seq_len]\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    config = EmbeddingConfig(\n",
    "        embedding_dim=256,\n",
    "        position_embedding_dim=32\n",
    "    )\n",
    "    \n",
    "    # Créer l'embedder\n",
    "    embedder = ExcelCellEmbedder(config)\n",
    "    \n",
    "    # Simuler une cellule (remplacer par votre vraie classe FullCellInfo)\n",
    "    from dataclasses import dataclass\n",
    "    from typing import Tuple\n",
    "    \n",
    "    @dataclass \n",
    "    class MockFullCellInfo:\n",
    "        raw_value: str = \"Hello\"\n",
    "        cell_type: int = 1\n",
    "        formula: str = \"\"\n",
    "        row: int = 5\n",
    "        col: int = 3\n",
    "        bold: bool = True\n",
    "        italic: bool = False\n",
    "        underline: bool = False\n",
    "        strike: bool = False\n",
    "        font_size: float = 12.0\n",
    "        font_family: str = \"Arial\"\n",
    "        text_color: str = \"#FF0000\"\n",
    "        background_color: str = \"#FFFFFF\"\n",
    "        horizontal_align: int = 1\n",
    "        vertical_align: int = 0\n",
    "        text_wrap: bool = False\n",
    "        text_rotation: int = 0\n",
    "        border_top: int = 1\n",
    "        border_bottom: int = 0\n",
    "        border_left: int = 0\n",
    "        border_right: int = 0\n",
    "        is_merged: bool = False\n",
    "        merge_range: Tuple[int, int, int, int] = (0, 0, 0, 0)\n",
    "    \n",
    "    # Créer une cellule test\n",
    "    cell = MockFullCellInfo()\n",
    "    \n",
    "    # Obtenir l'embedding\n",
    "    with torch.no_grad():\n",
    "        embedding = embedder(cell)\n",
    "        print(f\"Embedding shape: {embedding.shape}\")\n",
    "        print(f\"Embedding (premiers 10 éléments): {embedding[:10]}\")\n",
    "        \n",
    "        # Test avec plusieurs cellules\n",
    "        cells = [cell, cell, cell]\n",
    "        batch_embedding = embedder(cells)\n",
    "        print(f\"Batch embedding shape: {batch_embedding.shape}\")\n",
    "        \n",
    "        # Nombre de paramètres\n",
    "        total_params = sum(p.numel() for p in embedder.parameters())\n",
    "        print(f\"Nombre total de paramètres: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21174b58-7057-4add-9cb3-96aff6f70f20",
   "metadata": {},
   "source": [
    "Création du Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71749465-3df3-4bc5-8858-c6b5ed01a08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de cellules: 8\n",
      "Nombre d'arêtes: 52\n",
      "Nombre de feuilles: 3\n",
      "\n",
      "Position mapping (sheet, row, col) -> index:\n",
      "  ('Sheet1', 0, 0) -> 0\n",
      "  ('Sheet1', 0, 1) -> 1\n",
      "  ('Sheet1', 1, 0) -> 2\n",
      "  ('Sheet1', 1, 1) -> 3\n",
      "  ('Sheet2', 0, 0) -> 4\n",
      "\n",
      "Arêtes par type:\n",
      "  adjacent_diag: 3\n",
      "  adjacent_down: 3\n",
      "  adjacent_right: 3\n",
      "  cross_sheet: 19\n",
      "  formula_ref: 2\n",
      "  same_col: 3\n",
      "  same_row: 3\n",
      "  same_sheet: 9\n",
      "  same_value_type: 7\n",
      "\n",
      "Exemples d'arêtes de feuille:\n",
      "  same_sheet: Sheet1!(0,0) -> Sheet1!(0,1) [weight: 1.00]\n",
      "  same_sheet: Sheet1!(0,0) -> Sheet1!(1,0) [weight: 1.00]\n",
      "  same_sheet: Sheet1!(0,0) -> Sheet1!(1,1) [weight: 1.00]\n",
      "  same_sheet: Sheet1!(0,1) -> Sheet1!(1,0) [weight: 1.00]\n",
      "  same_sheet: Sheet1!(0,1) -> Sheet1!(1,1) [weight: 1.00]\n",
      "\n",
      "Exemples de références cross-sheet:\n"
     ]
    }
   ],
   "source": [
    "class EdgeType(Enum):\n",
    "    \"\"\"Types d'arêtes dans le graphe Excel\"\"\"\n",
    "    # Relations spatiales\n",
    "    SAME_ROW = \"same_row\"\n",
    "    SAME_COL = \"same_col\"\n",
    "    ADJACENT_RIGHT = \"adjacent_right\"\n",
    "    ADJACENT_DOWN = \"adjacent_down\"\n",
    "    ADJACENT_DIAG = \"adjacent_diag\"\n",
    "    \n",
    "    # Relations de distance\n",
    "    NEAR_2 = \"near_2\"      # Distance 2\n",
    "    NEAR_3 = \"near_3\"      # Distance 3\n",
    "    NEAR_5 = \"near_5\"      # Distance 5\n",
    "    FAR = \"far\"            # Distance > 5\n",
    "    \n",
    "    # Relations de dépendance\n",
    "    FORMULA_REF = \"formula_ref\"           # A1 référence B1 dans une formule\n",
    "    FORMULA_RANGE = \"formula_range\"       # Formule utilise une plage (A1:B5)\n",
    "    FORMULA_INDIRECT = \"formula_indirect\" # Référence indirecte (INDIRECT, etc.)\n",
    "    CROSS_SHEET_REF = \"cross_sheet_ref\"   # Référence entre feuilles (Sheet2!A1)\n",
    "    \n",
    "    # Relations structurelles\n",
    "    MERGED_CELL = \"merged_cell\"      # Cellules fusionnées\n",
    "    SAME_STYLE = \"same_style\"        # Même style appliqué\n",
    "    SAME_VALUE_TYPE = \"same_value_type\"  # Même type de valeur\n",
    "    \n",
    "    # Relations de feuille\n",
    "    SAME_SHEET = \"same_sheet\"        # Appartiennent à la même feuille\n",
    "    CROSS_SHEET = \"cross_sheet\"      # Appartiennent à des feuilles différentes\n",
    "    \n",
    "    # Relations de plage\n",
    "    RANGE_START = \"range_start\"      # Début de plage\n",
    "    RANGE_END = \"range_end\"          # Fin de plage\n",
    "    RANGE_MEMBER = \"range_member\"    # Membre d'une plage\n",
    "\n",
    "@dataclass\n",
    "class GraphEdge:\n",
    "    \"\"\"Représente une arête dans le graphe Excel\"\"\"\n",
    "    source_idx: int           # Index de la cellule source\n",
    "    target_idx: int           # Index de la cellule cible\n",
    "    edge_type: EdgeType       # Type de relation\n",
    "    weight: float = 1.0       # Poids de l'arête\n",
    "    metadata: Dict[str, Any] = None  # Métadonnées additionnelles\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.metadata is None:\n",
    "            self.metadata = {}\n",
    "\n",
    "@dataclass\n",
    "class ExcelGraph:\n",
    "    \"\"\"Représente le graphe Excel avec cellules et arêtes\"\"\"\n",
    "    cell_embeddings: torch.Tensor      # [num_cells, embedding_dim]\n",
    "    edge_embeddings: torch.Tensor      # [num_edges, edge_embedding_dim]\n",
    "    edge_indices: torch.Tensor         # [2, num_edges] - format PyG\n",
    "    edge_types: List[EdgeType]         # Type de chaque arête\n",
    "    edge_weights: torch.Tensor         # [num_edges] - poids des arêtes\n",
    "    cell_positions: List[Tuple[int, int]]  # [(row, col)] positions originales\n",
    "    \n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        return self.cell_embeddings.size(0)\n",
    "    \n",
    "    @property\n",
    "    def num_edges(self) -> int:\n",
    "        return self.edge_embeddings.size(0)\n",
    "\n",
    "class ExcelGraphBuilder:\n",
    "    \"\"\"Construit le graphe de relations entre cellules Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 max_distance: int = 5,\n",
    "                 include_spatial: bool = True,\n",
    "                 include_formula_deps: bool = True,\n",
    "                 include_structural: bool = True,\n",
    "                 include_sheet_relations: bool = True,\n",
    "                 same_style_threshold: float = 0.8,\n",
    "                 cross_sheet_weight: float = 0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_distance: Distance maximale pour les arêtes spatiales\n",
    "            include_spatial: Inclure les relations spatiales\n",
    "            include_formula_deps: Inclure les dépendances de formules\n",
    "            include_structural: Inclure les relations structurelles\n",
    "            include_sheet_relations: Inclure les relations de feuille\n",
    "            same_style_threshold: Seuil pour considérer des styles similaires\n",
    "            cross_sheet_weight: Poids pour les relations inter-feuilles\n",
    "        \"\"\"\n",
    "        self.max_distance = max_distance\n",
    "        self.include_spatial = include_spatial\n",
    "        self.include_formula_deps = include_formula_deps\n",
    "        self.include_structural = include_structural\n",
    "        self.include_sheet_relations = include_sheet_relations\n",
    "        self.same_style_threshold = same_style_threshold\n",
    "        self.cross_sheet_weight = cross_sheet_weight\n",
    "    \n",
    "    def build_graph(self, cells: List['FullCellInfo']) -> Tuple[List[GraphEdge], Dict[Tuple[str, int, int], int]]:\n",
    "        \"\"\"\n",
    "        Construit le graphe de relations entre cellules\n",
    "        \n",
    "        Args:\n",
    "            cells: Liste des cellules Excel\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[edges, position_to_index_map] - position inclut maintenant sheet_name\n",
    "        \"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        # Créer un mapping (sheet, row, col) -> index\n",
    "        pos_to_idx = {(cell.sheet_name, cell.row, cell.col): i for i, cell in enumerate(cells)}\n",
    "        \n",
    "        # 1. Relations de feuille (en premier pour établir le contexte)\n",
    "        if self.include_sheet_relations:\n",
    "            edges.extend(self._build_sheet_relation_edges(cells, pos_to_idx))\n",
    "        \n",
    "        # 2. Relations spatiales (seulement dans la même feuille)\n",
    "        if self.include_spatial:\n",
    "            edges.extend(self._build_spatial_edges(cells, pos_to_idx))\n",
    "        \n",
    "        # 3. Relations de dépendance (formules - incluant cross-sheet)\n",
    "        if self.include_formula_deps:\n",
    "            edges.extend(self._build_formula_dependency_edges(cells, pos_to_idx))\n",
    "        \n",
    "        # 4. Relations structurelles\n",
    "        if self.include_structural:\n",
    "            edges.extend(self._build_structural_edges(cells, pos_to_idx))\n",
    "        \n",
    "        return edges, pos_to_idx\n",
    "    \n",
    "    def _build_sheet_relation_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur l'appartenance aux feuilles\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        # Grouper les cellules par feuille\n",
    "        sheets = {}\n",
    "        for i, cell in enumerate(cells):\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append(i)\n",
    "        \n",
    "        # Relations intra-feuille (SAME_SHEET)\n",
    "        for sheet_name, cell_indices in sheets.items():\n",
    "            for i in range(len(cell_indices)):\n",
    "                for j in range(i + 1, len(cell_indices)):\n",
    "                    idx_i, idx_j = cell_indices[i], cell_indices[j]\n",
    "                    edges.append(GraphEdge(\n",
    "                        idx_i, idx_j, \n",
    "                        EdgeType.SAME_SHEET, \n",
    "                        weight=1.0,\n",
    "                        metadata={'sheet_name': sheet_name}\n",
    "                    ))\n",
    "        \n",
    "        # Relations inter-feuilles (CROSS_SHEET)\n",
    "        sheet_names = list(sheets.keys())\n",
    "        for i in range(len(sheet_names)):\n",
    "            for j in range(i + 1, len(sheet_names)):\n",
    "                sheet_i, sheet_j = sheet_names[i], sheet_names[j]\n",
    "                cells_i, cells_j = sheets[sheet_i], sheets[sheet_j]\n",
    "                \n",
    "                # Connecter toutes les cellules entre feuilles différentes\n",
    "                # (peut être coûteux - limiter si nécessaire)\n",
    "                for cell_idx_i in cells_i[:10]:  # Limiter à 10 cellules par feuille\n",
    "                    for cell_idx_j in cells_j[:10]:\n",
    "                        edges.append(GraphEdge(\n",
    "                            cell_idx_i, cell_idx_j,\n",
    "                            EdgeType.CROSS_SHEET,\n",
    "                            weight=self.cross_sheet_weight,\n",
    "                            metadata={\n",
    "                                'sheet_i': sheet_i,\n",
    "                                'sheet_j': sheet_j\n",
    "                            }\n",
    "                        ))\n",
    "        \n",
    "        return edges\n",
    "    \n",
    "    def _build_spatial_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur les relations spatiales (dans la même feuille uniquement)\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        # Grouper par feuille pour éviter les relations spatiales inter-feuilles\n",
    "        sheets = {}\n",
    "        for i, cell in enumerate(cells):\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append((i, cell))\n",
    "        \n",
    "        # Construire les relations spatiales pour chaque feuille séparément\n",
    "        for sheet_name, sheet_cells in sheets.items():\n",
    "            for i, (idx_i, cell_i) in enumerate(sheet_cells):\n",
    "                for j, (idx_j, cell_j) in enumerate(sheet_cells):\n",
    "                    if i >= j:  # Éviter les doublons\n",
    "                        continue\n",
    "                    \n",
    "                    row_i, col_i = cell_i.row, cell_i.col\n",
    "                    row_j, col_j = cell_j.row, cell_j.col\n",
    "                    \n",
    "                    # Distance Manhattan\n",
    "                    distance = abs(row_i - row_j) + abs(col_i - col_j)\n",
    "                    \n",
    "                    if distance > self.max_distance:\n",
    "                        # Relation \"far\" (même feuille)\n",
    "                        edges.append(GraphEdge(\n",
    "                            idx_i, idx_j, EdgeType.FAR, \n",
    "                            weight=1.0/distance,\n",
    "                            metadata={'sheet_name': sheet_name}\n",
    "                        ))\n",
    "                        continue\n",
    "                    \n",
    "                    # Relations spécifiques\n",
    "                    if row_i == row_j and col_i != col_j:\n",
    "                        # Même ligne\n",
    "                        edges.append(GraphEdge(\n",
    "                            idx_i, idx_j, EdgeType.SAME_ROW, \n",
    "                            weight=1.0,\n",
    "                            metadata={'sheet_name': sheet_name, 'row': row_i}\n",
    "                        ))\n",
    "                        \n",
    "                        # Adjacent horizontal\n",
    "                        if abs(col_i - col_j) == 1:\n",
    "                            edges.append(GraphEdge(idx_i, idx_j, EdgeType.ADJACENT_RIGHT, weight=1.0))\n",
    "                    \n",
    "                    elif col_i == col_j and row_i != row_j:\n",
    "                        # Même colonne\n",
    "                        edges.append(GraphEdge(\n",
    "                            idx_i, idx_j, EdgeType.SAME_COL, \n",
    "                            weight=1.0,\n",
    "                            metadata={'sheet_name': sheet_name, 'col': col_i}\n",
    "                        ))\n",
    "                        \n",
    "                        # Adjacent vertical\n",
    "                        if abs(row_i - row_j) == 1:\n",
    "                            edges.append(GraphEdge(idx_i, idx_j, EdgeType.ADJACENT_DOWN, weight=1.0))\n",
    "                    \n",
    "                    elif distance == 2 and abs(row_i - row_j) == 1 and abs(col_i - col_j) == 1:\n",
    "                        # Adjacent diagonal\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.ADJACENT_DIAG, weight=0.7))\n",
    "                    \n",
    "                    # Relations de distance\n",
    "                    elif distance == 2:\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.NEAR_2, weight=0.5))\n",
    "                    elif distance == 3:\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.NEAR_3, weight=0.3))\n",
    "                    elif distance <= 5:\n",
    "                        edges.append(GraphEdge(idx_i, idx_j, EdgeType.NEAR_5, weight=0.1))\n",
    "        \n",
    "        return edges\n",
    "    \n",
    "    def _build_formula_dependency_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur les dépendances de formules (incluant cross-sheet)\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            if not cell.formula:\n",
    "                continue\n",
    "            \n",
    "            # Parser les références dans la formule\n",
    "            references = self._parse_formula_references(cell.formula, cell.sheet_name)\n",
    "            \n",
    "            for ref in references:\n",
    "                if ref['type'] == 'cell':\n",
    "                    # Référence à une cellule (même feuille ou autre)\n",
    "                    target_pos = (ref['sheet'], ref['row'], ref['col'])\n",
    "                    if target_pos in pos_to_idx:\n",
    "                        j = pos_to_idx[target_pos]\n",
    "                        edge_type = EdgeType.CROSS_SHEET_REF if ref['sheet'] != cell.sheet_name else EdgeType.FORMULA_REF\n",
    "                        weight = 0.8 if ref['sheet'] != cell.sheet_name else 1.0\n",
    "                        \n",
    "                        edges.append(GraphEdge(\n",
    "                            i, j, edge_type, \n",
    "                            weight=weight,\n",
    "                            metadata={\n",
    "                                'formula_ref': ref['text'],\n",
    "                                'source_sheet': cell.sheet_name,\n",
    "                                'target_sheet': ref['sheet']\n",
    "                            }\n",
    "                        ))\n",
    "                \n",
    "                elif ref['type'] == 'range':\n",
    "                    # Référence à une plage\n",
    "                    start_row, start_col = ref['start_row'], ref['start_col']\n",
    "                    end_row, end_col = ref['end_row'], ref['end_col']\n",
    "                    \n",
    "                    for row in range(start_row, end_row + 1):\n",
    "                        for col in range(start_col, end_col + 1):\n",
    "                            target_pos = (ref['sheet'], row, col)\n",
    "                            if target_pos in pos_to_idx:\n",
    "                                j = pos_to_idx[target_pos]\n",
    "                                edge_type = EdgeType.CROSS_SHEET_REF if ref['sheet'] != cell.sheet_name else EdgeType.FORMULA_RANGE\n",
    "                                weight = 0.4 if ref['sheet'] != cell.sheet_name else 0.5\n",
    "                                \n",
    "                                edges.append(GraphEdge(\n",
    "                                    i, j, edge_type,\n",
    "                                    weight=weight,\n",
    "                                    metadata={\n",
    "                                        'formula_range': ref['text'],\n",
    "                                        'source_sheet': cell.sheet_name,\n",
    "                                        'target_sheet': ref['sheet']\n",
    "                                    }\n",
    "                                ))\n",
    "                \n",
    "                elif ref['type'] == 'indirect':\n",
    "                    # Référence indirecte (plus complexe à analyser)\n",
    "                    edges.append(GraphEdge(\n",
    "                        i, i, EdgeType.FORMULA_INDIRECT, \n",
    "                        weight=0.3,\n",
    "                        metadata={'indirect_ref': ref['text']}\n",
    "                    ))\n",
    "        \n",
    "        return edges\n",
    "    \n",
    "    def _parse_formula_references(self, formula: str, current_sheet: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Parse les références dans une formule Excel (incluant cross-sheet)\"\"\"\n",
    "        references = []\n",
    "        \n",
    "        # Pattern pour les références cross-sheet (Sheet1!A1, 'Sheet Name'!A1)\n",
    "        cross_sheet_pattern = r\"(?:'([^']+)'|([^!\\s]+))!(\\$?[A-Z]+\\$?\\d+)\"\n",
    "        cross_sheet_matches = re.finditer(cross_sheet_pattern, formula.upper())\n",
    "        \n",
    "        for match in cross_sheet_matches:\n",
    "            sheet_name_quoted, sheet_name_simple, cell_ref = match.groups()\n",
    "            sheet_name = sheet_name_quoted or sheet_name_simple\n",
    "            \n",
    "            # Parser la référence de cellule\n",
    "            cell_match = re.match(r'\\$?([A-Z]+)\\$?(\\d+)', cell_ref)\n",
    "            if cell_match:\n",
    "                col_str, row_str = cell_match.groups()\n",
    "                col = self._col_str_to_num(col_str)\n",
    "                row = int(row_str) - 1\n",
    "                \n",
    "                references.append({\n",
    "                    'type': 'cell',\n",
    "                    'sheet': sheet_name,\n",
    "                    'row': row,\n",
    "                    'col': col,\n",
    "                    'text': match.group(0)\n",
    "                })\n",
    "        \n",
    "        # Pattern pour les plages cross-sheet (Sheet1!A1:B5)\n",
    "        cross_sheet_range_pattern = r\"(?:'([^']+)'|([^!\\s]+))!(\\$?[A-Z]+\\$?\\d+:\\$?[A-Z]+\\$?\\d+)\"\n",
    "        cross_sheet_range_matches = re.finditer(cross_sheet_range_pattern, formula.upper())\n",
    "        \n",
    "        for match in cross_sheet_range_matches:\n",
    "            sheet_name_quoted, sheet_name_simple, range_ref = match.groups()\n",
    "            sheet_name = sheet_name_quoted or sheet_name_simple\n",
    "            \n",
    "            # Parser la plage\n",
    "            range_match = re.match(r'\\$?([A-Z]+)\\$?(\\d+):\\$?([A-Z]+)\\$?(\\d+)', range_ref)\n",
    "            if range_match:\n",
    "                start_col_str, start_row_str, end_col_str, end_row_str = range_match.groups()\n",
    "                start_col = self._col_str_to_num(start_col_str)\n",
    "                start_row = int(start_row_str) - 1\n",
    "                end_col = self._col_str_to_num(end_col_str)\n",
    "                end_row = int(end_row_str) - 1\n",
    "                \n",
    "                references.append({\n",
    "                    'type': 'range',\n",
    "                    'sheet': sheet_name,\n",
    "                    'start_row': start_row,\n",
    "                    'start_col': start_col,\n",
    "                    'end_row': end_row,\n",
    "                    'end_col': end_col,\n",
    "                    'text': match.group(0)\n",
    "                })\n",
    "        \n",
    "        # Pattern pour les références locales (A1, A1:B5 sans nom de feuille)\n",
    "        # Retirer d'abord les références cross-sheet pour éviter les doublons\n",
    "        formula_local = formula.upper()\n",
    "        for match in re.finditer(cross_sheet_pattern, formula_local):\n",
    "            formula_local = formula_local.replace(match.group(0), \"\")\n",
    "        for match in re.finditer(cross_sheet_range_pattern, formula_local):\n",
    "            formula_local = formula_local.replace(match.group(0), \"\")\n",
    "        \n",
    "        # Références de cellules locales\n",
    "        cell_pattern = r'\\$?([A-Z]+)\\$?(\\d+)'\n",
    "        cell_matches = re.finditer(cell_pattern, formula_local)\n",
    "        \n",
    "        for match in cell_matches:\n",
    "            col_str, row_str = match.groups()\n",
    "            col = self._col_str_to_num(col_str)\n",
    "            row = int(row_str) - 1\n",
    "            references.append({\n",
    "                'type': 'cell',\n",
    "                'sheet': current_sheet,\n",
    "                'row': row,\n",
    "                'col': col,\n",
    "                'text': match.group(0)\n",
    "            })\n",
    "        \n",
    "        # Plages locales\n",
    "        range_pattern = r'\\$?([A-Z]+)\\$?(\\d+):\\$?([A-Z]+)\\$?(\\d+)'\n",
    "        range_matches = re.finditer(range_pattern, formula_local)\n",
    "        \n",
    "        for match in range_matches:\n",
    "            start_col_str, start_row_str, end_col_str, end_row_str = match.groups()\n",
    "            start_col = self._col_str_to_num(start_col_str)\n",
    "            start_row = int(start_row_str) - 1\n",
    "            end_col = self._col_str_to_num(end_col_str)\n",
    "            end_row = int(end_row_str) - 1\n",
    "            \n",
    "            references.append({\n",
    "                'type': 'range',\n",
    "                'sheet': current_sheet,\n",
    "                'start_row': start_row,\n",
    "                'start_col': start_col,\n",
    "                'end_row': end_row,\n",
    "                'end_col': end_col,\n",
    "                'text': match.group(0)\n",
    "            })\n",
    "        \n",
    "        # Fonctions indirectes\n",
    "        indirect_pattern = r'INDIRECT\\s*\\([^)]+\\)'\n",
    "        indirect_matches = re.finditer(indirect_pattern, formula.upper())\n",
    "        \n",
    "        for match in indirect_matches:\n",
    "            references.append({\n",
    "                'type': 'indirect',\n",
    "                'text': match.group(0)\n",
    "            })\n",
    "        \n",
    "        return references\n",
    "    \n",
    "    def _col_str_to_num(self, col_str: str) -> int:\n",
    "        \"\"\"Convertit une colonne string (A, B, ..., AA, AB) en nombre\"\"\"\n",
    "        result = 0\n",
    "        for char in col_str:\n",
    "            result = result * 26 + (ord(char) - ord('A') + 1)\n",
    "        return result - 1  # Convert to 0-based\n",
    "    \n",
    "    def _build_structural_edges(self, cells: List['FullCellInfo'], pos_to_idx: Dict) -> List[GraphEdge]:\n",
    "        \"\"\"Construit les arêtes basées sur les relations structurelles\"\"\"\n",
    "        edges = []\n",
    "        \n",
    "        for i, cell_i in enumerate(cells):\n",
    "            for j, cell_j in enumerate(cells):\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                \n",
    "                # Cellules fusionnées\n",
    "                if cell_i.is_merged and cell_j.is_merged:\n",
    "                    if cell_i.merge_range == cell_j.merge_range:\n",
    "                        edges.append(GraphEdge(i, j, EdgeType.MERGED_CELL, weight=1.0))\n",
    "                \n",
    "                # Même style (simplifié - comparer style_id)\n",
    "                if cell_i.style_id and cell_j.style_id and cell_i.style_id == cell_j.style_id:\n",
    "                    edges.append(GraphEdge(i, j, EdgeType.SAME_STYLE, weight=0.8))\n",
    "                \n",
    "                # Même type de valeur\n",
    "                if cell_i.cell_type == cell_j.cell_type and cell_i.cell_type != 0:  # Pas vide\n",
    "                    edges.append(GraphEdge(i, j, EdgeType.SAME_VALUE_TYPE, weight=0.4))\n",
    "        \n",
    "        return edges\n",
    "\n",
    "class EdgeEmbedder(nn.Module):\n",
    "    \"\"\"Embedder pour les arêtes du graphe\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Embedding par type d'arête\n",
    "        num_edge_types = len(EdgeType)\n",
    "        self.edge_type_embedding = nn.Embedding(num_edge_types, embedding_dim)\n",
    "        \n",
    "        # Embedding pour les poids (discrétisés)\n",
    "        self.weight_bins = 20\n",
    "        self.weight_embedding = nn.Embedding(self.weight_bins, embedding_dim // 4)\n",
    "        \n",
    "        # Projection finale\n",
    "        self.projection = nn.Linear(embedding_dim + embedding_dim // 4, embedding_dim)\n",
    "        \n",
    "        # Mapping des types vers des IDs\n",
    "        self.edge_type_to_id = {edge_type: i for i, edge_type in enumerate(EdgeType)}\n",
    "    \n",
    "    def forward(self, edge_types: List[EdgeType], edge_weights: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Embed les arêtes\n",
    "        \n",
    "        Args:\n",
    "            edge_types: Liste des types d'arêtes\n",
    "            edge_weights: Poids des arêtes [num_edges]\n",
    "            \n",
    "        Returns:\n",
    "            Embeddings des arêtes [num_edges, embedding_dim]\n",
    "        \"\"\"\n",
    "        # Convertir types en IDs\n",
    "        type_ids = torch.tensor([self.edge_type_to_id[et] for et in edge_types])\n",
    "        type_embeddings = self.edge_type_embedding(type_ids)\n",
    "        \n",
    "        # Discrétiser les poids\n",
    "        weight_bins = torch.clamp(\n",
    "            (edge_weights * self.weight_bins).long(), \n",
    "            0, self.weight_bins - 1\n",
    "        )\n",
    "        weight_embeddings = self.weight_embedding(weight_bins)\n",
    "        \n",
    "        # Combiner\n",
    "        combined = torch.cat([type_embeddings, weight_embeddings], dim=1)\n",
    "        return self.projection(combined)\n",
    "\n",
    "class ExcelGraphEmbedder(nn.Module):\n",
    "    \"\"\"Embedder complet pour les graphes Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, cell_embedder: ExcelCellEmbedder, edge_embedding_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.cell_embedder = cell_embedder\n",
    "        self.edge_embedder = EdgeEmbedder(edge_embedding_dim)\n",
    "        self.graph_builder = ExcelGraphBuilder()\n",
    "        \n",
    "    def forward(self, cells: List['FullCellInfo']) -> ExcelGraph:\n",
    "        \"\"\"\n",
    "        Convertit une liste de cellules en graphe embedé\n",
    "        \n",
    "        Args:\n",
    "            cells: Liste des cellules Excel\n",
    "            \n",
    "        Returns:\n",
    "            ExcelGraph avec embeddings\n",
    "        \"\"\"\n",
    "        # 1. Embed les cellules\n",
    "        cell_embeddings = self.cell_embedder(cells)\n",
    "        \n",
    "        # 2. Construire le graphe\n",
    "        edges, pos_to_idx = self.graph_builder.build_graph(cells)\n",
    "        \n",
    "        if not edges:\n",
    "            # Graphe vide\n",
    "            return ExcelGraph(\n",
    "                cell_embeddings=cell_embeddings,\n",
    "                edge_embeddings=torch.empty(0, self.edge_embedder.embedding_dim),\n",
    "                edge_indices=torch.empty(2, 0, dtype=torch.long),\n",
    "                edge_types=[],\n",
    "                edge_weights=torch.empty(0),\n",
    "                cell_positions=[(cell.row, cell.col) for cell in cells]\n",
    "            )\n",
    "        \n",
    "        # 3. Préparer les données d'arêtes\n",
    "        edge_indices = torch.tensor([[e.source_idx, e.target_idx] for e in edges]).T\n",
    "        edge_types = [e.edge_type for e in edges]\n",
    "        edge_weights = torch.tensor([e.weight for e in edges])\n",
    "        \n",
    "        # 4. Embed les arêtes\n",
    "        edge_embeddings = self.edge_embedder(edge_types, edge_weights)\n",
    "        \n",
    "        # 5. Créer le graphe final\n",
    "        return ExcelGraph(\n",
    "            cell_embeddings=cell_embeddings,\n",
    "            edge_embeddings=edge_embeddings,\n",
    "            edge_indices=edge_indices,\n",
    "            edge_types=edge_types,\n",
    "            edge_weights=edge_weights,\n",
    "            cell_positions=[(cell.row, cell.col) for cell in cells]\n",
    "        )\n",
    "    \n",
    "    def get_edge_statistics(self, graph: ExcelGraph) -> Dict[str, int]:\n",
    "        \"\"\"Retourne des statistiques sur les types d'arêtes\"\"\"\n",
    "        stats = {}\n",
    "        for edge_type in graph.edge_types:\n",
    "            stats[edge_type.value] = stats.get(edge_type.value, 0) + 1\n",
    "        return stats\n",
    "\n",
    "# Exemple d'utilisation et tests\n",
    "if __name__ == \"__main__\":\n",
    "    # Simuler des cellules pour tester\n",
    "    from dataclasses import dataclass\n",
    "    from typing import Tuple\n",
    "    \n",
    "    @dataclass\n",
    "    class MockFullCellInfo:\n",
    "        raw_value: str = \"\"\n",
    "        cell_type: int = 0\n",
    "        formula: str = \"\"\n",
    "        row: int = 0\n",
    "        col: int = 0\n",
    "        sheet_name: str = \"Sheet1\"\n",
    "        style_id: str = \"\"\n",
    "        is_merged: bool = False\n",
    "        merge_range: Tuple[int, int, int, int] = (0, 0, 0, 0)\n",
    "        # Autres attributs...\n",
    "        bold: bool = False\n",
    "        italic: bool = False\n",
    "        underline: bool = False\n",
    "        strike: bool = False\n",
    "        font_size: float = 11.0\n",
    "        font_family: str = \"Calibri\"\n",
    "        text_color: str = \"#000000\"\n",
    "        background_color: str = \"#FFFFFF\"\n",
    "        horizontal_align: int = 0\n",
    "        vertical_align: int = 0\n",
    "        text_wrap: bool = False\n",
    "        text_rotation: int = 0\n",
    "        border_top: int = 0\n",
    "        border_bottom: int = 0\n",
    "        border_left: int = 0\n",
    "        border_right: int = 0\n",
    "    \n",
    "    # Créer des cellules de test avec multiple feuilles\n",
    "    cells = [\n",
    "        # Feuille 1\n",
    "        MockFullCellInfo(raw_value=\"A1\", row=0, col=0, cell_type=1, sheet_name=\"Sheet1\"),\n",
    "        MockFullCellInfo(raw_value=\"10\", row=0, col=1, cell_type=2, sheet_name=\"Sheet1\"),\n",
    "        MockFullCellInfo(raw_value=\"B1\", row=1, col=0, cell_type=1, sheet_name=\"Sheet1\"),\n",
    "        MockFullCellInfo(formula=\"=A1+B1\", row=1, col=1, cell_type=3, sheet_name=\"Sheet1\"),\n",
    "        \n",
    "        # Feuille 2\n",
    "        MockFullCellInfo(raw_value=\"Data\", row=0, col=0, cell_type=1, sheet_name=\"Sheet2\"),\n",
    "        MockFullCellInfo(raw_value=\"100\", row=0, col=1, cell_type=2, sheet_name=\"Sheet2\"),\n",
    "        MockFullCellInfo(formula=\"=Sheet1!A1*2\", row=1, col=0, cell_type=3, sheet_name=\"Sheet2\"),\n",
    "        \n",
    "        # Feuille 3 \n",
    "        MockFullCellInfo(formula=\"=SUM(Sheet1!A1:B2)\", row=0, col=0, cell_type=3, sheet_name=\"Sheet3\"),\n",
    "    ]\n",
    "    \n",
    "    # Créer le graph builder et tester\n",
    "    builder = ExcelGraphBuilder(include_sheet_relations=True)\n",
    "    edges, pos_to_idx = builder.build_graph(cells)\n",
    "    \n",
    "    print(f\"Nombre de cellules: {len(cells)}\")\n",
    "    print(f\"Nombre d'arêtes: {len(edges)}\")\n",
    "    print(f\"Nombre de feuilles: {len(set(cell.sheet_name for cell in cells))}\")\n",
    "    \n",
    "    print(f\"\\nPosition mapping (sheet, row, col) -> index:\")\n",
    "    for pos, idx in list(pos_to_idx.items())[:5]:\n",
    "        print(f\"  {pos} -> {idx}\")\n",
    "    \n",
    "    print(\"\\nArêtes par type:\")\n",
    "    edge_type_counts = {}\n",
    "    for edge in edges:\n",
    "        edge_type_counts[edge.edge_type.value] = edge_type_counts.get(edge.edge_type.value, 0) + 1\n",
    "    \n",
    "    for edge_type, count in sorted(edge_type_counts.items()):\n",
    "        print(f\"  {edge_type}: {count}\")\n",
    "    \n",
    "    print(\"\\nExemples d'arêtes de feuille:\")\n",
    "    sheet_edges = [e for e in edges if e.edge_type in [EdgeType.SAME_SHEET, EdgeType.CROSS_SHEET]]\n",
    "    for edge in sheet_edges[:5]:\n",
    "        source_cell = cells[edge.source_idx]\n",
    "        target_cell = cells[edge.target_idx]\n",
    "        print(f\"  {edge.edge_type.value}: \"\n",
    "              f\"{source_cell.sheet_name}!({source_cell.row},{source_cell.col}) -> \"\n",
    "              f\"{target_cell.sheet_name}!({target_cell.row},{target_cell.col}) \"\n",
    "              f\"[weight: {edge.weight:.2f}]\")\n",
    "    \n",
    "    print(\"\\nExemples de références cross-sheet:\")\n",
    "    cross_ref_edges = [e for e in edges if e.edge_type == EdgeType.CROSS_SHEET_REF]\n",
    "    for edge in cross_ref_edges:\n",
    "        source_cell = cells[edge.source_idx]\n",
    "        target_cell = cells[edge.target_idx]\n",
    "        metadata = edge.metadata or {}\n",
    "        print(f\"  {edge.edge_type.value}: \"\n",
    "              f\"{source_cell.sheet_name}!({source_cell.row},{source_cell.col}) -> \"\n",
    "              f\"{target_cell.sheet_name}!({target_cell.row},{target_cell.col}) \"\n",
    "              f\"[formula: {metadata.get('formula_ref', 'N/A')}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e0749-d488-44df-84d6-f2564967dfc7",
   "metadata": {},
   "source": [
    "Fonction pour transformer un/des json en GraphEmbedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f48e8db-f591-413d-95f7-d005879625b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dimension avant projection: 616\n",
      "Statistiques du graphe:\n",
      "  Nombre de nœuds: 6\n",
      "  Nombre d'arêtes: 43\n",
      "  Degré moyen: 14.33\n",
      "  Nombre de feuilles: 2\n",
      "  Feuilles: [0, 1]\n",
      "  Types d'arêtes:\n",
      "    same_sheet: 7\n",
      "    cross_sheet: 8\n",
      "    same_col: 2\n",
      "    adjacent_down: 2\n",
      "    same_row: 3\n",
      "    adjacent_right: 3\n",
      "    adjacent_diag: 2\n",
      "    formula_ref: 2\n",
      "    same_style: 10\n",
      "    same_value_type: 4\n",
      "\n",
      "Dimensions des embeddings:\n",
      "  Cellules: torch.Size([6, 256])\n",
      "  Arêtes: torch.Size([43, 64])\n",
      "  Indices d'arêtes: torch.Size([2, 43])\n",
      "\n",
      "Batch transformé: 2 graphes\n",
      "Total dimension avant projection: 616\n",
      "\n",
      "Graphe rapide: 6 nœuds, 43 arêtes\n"
     ]
    }
   ],
   "source": [
    "class JSONToGraphTransformer:\n",
    "    \"\"\"Transforme un JSON Excel en GraphEmbedded\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embedding_config: Optional['EmbeddingConfig'] = None,\n",
    "                 max_cells_per_sheet: int = 1000,\n",
    "                 include_empty_cells: bool = False,\n",
    "                 graph_config: Optional[Dict[str, Any]] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_config: Configuration pour l'embedder\n",
    "            max_cells_per_sheet: Limite de cellules par feuille\n",
    "            include_empty_cells: Inclure les cellules vides\n",
    "            graph_config: Configuration pour le graph builder\n",
    "        \"\"\"\n",
    "        # Configuration par défaut\n",
    "        if embedding_config is None:\n",
    "            embedding_config = EmbeddingConfig(\n",
    "                embedding_dim=256,\n",
    "                position_embedding_dim=32,\n",
    "                max_position=10000,\n",
    "                color_vocab_size=1000\n",
    "            )\n",
    "        \n",
    "        if graph_config is None:\n",
    "            graph_config = {\n",
    "                'max_distance': 5,\n",
    "                'include_spatial': True,\n",
    "                'include_formula_deps': True,\n",
    "                'include_structural': True,\n",
    "                'include_sheet_relations': True,\n",
    "                'cross_sheet_weight': 0.3\n",
    "            }\n",
    "        \n",
    "        self.embedding_config = embedding_config\n",
    "        self.max_cells_per_sheet = max_cells_per_sheet\n",
    "        self.include_empty_cells = include_empty_cells\n",
    "        self.graph_config = graph_config\n",
    "        \n",
    "        # Initialiser les composants\n",
    "        self.cell_embedder = ExcelCellEmbedder(embedding_config)\n",
    "        self.graph_embedder = ExcelGraphEmbedder(\n",
    "            self.cell_embedder, \n",
    "            edge_embedding_dim=64\n",
    "        )\n",
    "        \n",
    "        # Configurer le graph builder\n",
    "        self.graph_embedder.graph_builder = ExcelGraphBuilder(**graph_config)\n",
    "    \n",
    "    def transform(self, \n",
    "                  json_data: Union[str, Dict[str, Any]], \n",
    "                  filter_sheets: Optional[List[str]] = None,\n",
    "                  max_total_cells: Optional[int] = None) -> 'ExcelGraph':\n",
    "        \"\"\"\n",
    "        Transforme un JSON Excel en ExcelGraph\n",
    "        \n",
    "        Args:\n",
    "            json_data: JSON string ou dict contenant les données Excel\n",
    "            filter_sheets: Liste des noms de feuilles à inclure (None = toutes)\n",
    "            max_total_cells: Limite totale de cellules (None = pas de limite)\n",
    "            \n",
    "        Returns:\n",
    "            ExcelGraph avec embeddings\n",
    "        \"\"\"\n",
    "        # 1. Parser le JSON\n",
    "        if isinstance(json_data, str):\n",
    "            excel_data = json.loads(json_data)\n",
    "        else:\n",
    "            excel_data = json_data\n",
    "        \n",
    "        # 2. Extraire les cellules\n",
    "        all_cells = self._extract_cells_from_json(excel_data, filter_sheets)\n",
    "        \n",
    "        # 3. Filtrer et limiter les cellules\n",
    "        filtered_cells = self._filter_cells(all_cells, max_total_cells)\n",
    "        \n",
    "        # 4. Transformer en graphe embedé\n",
    "        excel_graph = self.graph_embedder(filtered_cells)\n",
    "        \n",
    "        return excel_graph\n",
    "    \n",
    "    def _extract_cells_from_json(self, \n",
    "                                 excel_data: Dict[str, Any], \n",
    "                                 filter_sheets: Optional[List[str]] = None) -> List['FullCellInfo']:\n",
    "        \"\"\"Extrait les cellules du JSON Excel\"\"\"\n",
    "        try:\n",
    "            # Utiliser le parser existant\n",
    "            all_cells = ExcelParser.parse_excel_json(excel_data)\n",
    "            \n",
    "            # S'assurer qu'on a une liste\n",
    "            if not isinstance(all_cells, list):\n",
    "                if all_cells is None:\n",
    "                    return []\n",
    "                # Si c'est un seul objet FullCellInfo, le mettre dans une liste\n",
    "                return [all_cells]\n",
    "            \n",
    "            # Filtrer par feuilles si spécifié\n",
    "            if filter_sheets:\n",
    "                all_cells = [cell for cell in all_cells if cell.sheet_name in filter_sheets]\n",
    "            \n",
    "            return all_cells\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du parsing JSON: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _filter_cells(self, \n",
    "                      cells: List['FullCellInfo'], \n",
    "                      max_total_cells: Optional[int] = None) -> List['FullCellInfo']:\n",
    "        \"\"\"Filtre et limite les cellules selon les critères\"\"\"\n",
    "        # Vérifier que cells est bien une liste\n",
    "        if not isinstance(cells, list):\n",
    "            if cells is None:\n",
    "                return []\n",
    "            return [cells]  # Convertir un seul objet en liste\n",
    "        \n",
    "        if not cells:  # Liste vide\n",
    "            return []\n",
    "        \n",
    "        filtered_cells = []\n",
    "        \n",
    "        # Grouper par feuille\n",
    "        sheets = {}\n",
    "        for cell in cells:\n",
    "            if cell.sheet_name not in sheets:\n",
    "                sheets[cell.sheet_name] = []\n",
    "            sheets[cell.sheet_name].append(cell)\n",
    "        \n",
    "        # Filtrer par feuille\n",
    "        for sheet_name, sheet_cells in sheets.items():\n",
    "            # Filtrer les cellules vides si nécessaire\n",
    "            if not self.include_empty_cells:\n",
    "                sheet_cells = [\n",
    "                    cell for cell in sheet_cells \n",
    "                    if cell.raw_value or cell.formula or cell.style_id or cell.is_merged\n",
    "                ]\n",
    "            \n",
    "            # Trier par priorité (formules > valeurs > style > vides)\n",
    "            sheet_cells.sort(key=self._cell_priority, reverse=True)\n",
    "            \n",
    "            # Limiter par feuille\n",
    "            if len(sheet_cells) > self.max_cells_per_sheet:\n",
    "                sheet_cells = sheet_cells[:self.max_cells_per_sheet]\n",
    "            \n",
    "            filtered_cells.extend(sheet_cells)\n",
    "        \n",
    "        # Limiter le total si spécifié\n",
    "        if max_total_cells and len(filtered_cells) > max_total_cells:\n",
    "            # Trier par priorité globale et prendre les plus importantes\n",
    "            filtered_cells.sort(key=self._cell_priority, reverse=True)\n",
    "            filtered_cells = filtered_cells[:max_total_cells]\n",
    "        \n",
    "        return filtered_cells\n",
    "    \n",
    "    def _cell_priority(self, cell: 'FullCellInfo') -> int:\n",
    "        \"\"\"Calcule la priorité d'une cellule pour le filtrage\"\"\"\n",
    "        priority = 0\n",
    "        \n",
    "        # Formules ont la plus haute priorité\n",
    "        if cell.formula:\n",
    "            priority += 1000\n",
    "        \n",
    "        # Cellules avec valeurs\n",
    "        if cell.raw_value:\n",
    "            priority += 500\n",
    "            \n",
    "            # Bonus selon le type\n",
    "            if cell.cell_type == 2:  # Nombre\n",
    "                priority += 100\n",
    "            elif cell.cell_type == 1:  # Texte\n",
    "                priority += 50\n",
    "        \n",
    "        # Cellules avec style\n",
    "        if cell.style_id and cell.style_id != \"s0\":\n",
    "            priority += 200\n",
    "        \n",
    "        # Cellules fusionnées\n",
    "        if cell.is_merged:\n",
    "            priority += 150\n",
    "        \n",
    "        # Proximité du coin supérieur gauche (cellules importantes souvent en haut à gauche)\n",
    "        distance_from_origin = cell.row + cell.col\n",
    "        priority += max(0, 100 - distance_from_origin)\n",
    "        \n",
    "        return priority\n",
    "    \n",
    "    def transform_batch(self, \n",
    "                        json_files: List[Union[str, Dict[str, Any]]],\n",
    "                        batch_size: int = 32) -> List['ExcelGraph']:\n",
    "        \"\"\"\n",
    "        Transforme plusieurs JSON en batch\n",
    "        \n",
    "        Args:\n",
    "            json_files: Liste de JSON (strings ou dicts)\n",
    "            batch_size: Taille des batches pour l'embedding\n",
    "            \n",
    "        Returns:\n",
    "            Liste d'ExcelGraph\n",
    "        \"\"\"\n",
    "        graphs = []\n",
    "        \n",
    "        for i in range(0, len(json_files), batch_size):\n",
    "            batch = json_files[i:i + batch_size]\n",
    "            batch_graphs = []\n",
    "            \n",
    "            for json_data in batch:\n",
    "                try:\n",
    "                    graph = self.transform(json_data)\n",
    "                    batch_graphs.append(graph)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de la transformation: {e}\")\n",
    "                    # Créer un graphe vide en cas d'erreur\n",
    "                    empty_graph = self._create_empty_graph()\n",
    "                    batch_graphs.append(empty_graph)\n",
    "            \n",
    "            graphs.extend(batch_graphs)\n",
    "        \n",
    "        return graphs\n",
    "    \n",
    "    def _create_empty_graph(self) -> 'ExcelGraph':\n",
    "        \"\"\"Crée un graphe vide en cas d'erreur\"\"\"\n",
    "        return ExcelGraph(\n",
    "            cell_embeddings=torch.empty(0, self.embedding_config.embedding_dim),\n",
    "            edge_embeddings=torch.empty(0, 64),\n",
    "            edge_indices=torch.empty(2, 0, dtype=torch.long),\n",
    "            edge_types=[],\n",
    "            edge_weights=torch.empty(0),\n",
    "            cell_positions=[]\n",
    "        )\n",
    "    \n",
    "    def get_graph_statistics(self, graph: 'ExcelGraph') -> Dict[str, Any]:\n",
    "        \"\"\"Retourne des statistiques détaillées sur le graphe\"\"\"\n",
    "        if graph.num_nodes == 0:\n",
    "            return {'empty_graph': True}\n",
    "        \n",
    "        # Statistiques de base\n",
    "        stats = {\n",
    "            'num_nodes': graph.num_nodes,\n",
    "            'num_edges': graph.num_edges,\n",
    "            'avg_degree': graph.num_edges * 2 / graph.num_nodes if graph.num_nodes > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # Statistiques par type d'arête\n",
    "        edge_type_counts = {}\n",
    "        for edge_type in graph.edge_types:\n",
    "            edge_type_counts[edge_type.value] = edge_type_counts.get(edge_type.value, 0) + 1\n",
    "        stats['edge_types'] = edge_type_counts\n",
    "        \n",
    "        # Statistiques des feuilles\n",
    "        sheets = set(pos[0] if isinstance(pos, tuple) and len(pos) >= 1 else \"unknown\" \n",
    "                    for pos in graph.cell_positions)\n",
    "        stats['num_sheets'] = len(sheets)\n",
    "        stats['sheet_names'] = list(sheets)\n",
    "        \n",
    "        # Statistiques des positions\n",
    "        if graph.cell_positions:\n",
    "            positions = [(pos[1], pos[2]) if isinstance(pos, tuple) and len(pos) >= 3 \n",
    "                        else pos for pos in graph.cell_positions]\n",
    "            if positions and all(isinstance(p, tuple) and len(p) == 2 for p in positions):\n",
    "                rows = [p[0] for p in positions]\n",
    "                cols = [p[1] for p in positions]\n",
    "                stats['position_range'] = {\n",
    "                    'min_row': min(rows),\n",
    "                    'max_row': max(rows),\n",
    "                    'min_col': min(cols),\n",
    "                    'max_col': max(cols)\n",
    "                }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def save_graph(self, graph: 'ExcelGraph', filepath: str):\n",
    "        \"\"\"Sauvegarde un graphe au format PyTorch\"\"\"\n",
    "        torch.save({\n",
    "            'cell_embeddings': graph.cell_embeddings,\n",
    "            'edge_embeddings': graph.edge_embeddings,\n",
    "            'edge_indices': graph.edge_indices,\n",
    "            'edge_types': [et.value for et in graph.edge_types],\n",
    "            'edge_weights': graph.edge_weights,\n",
    "            'cell_positions': graph.cell_positions,\n",
    "            'config': self.embedding_config,\n",
    "            'graph_config': self.graph_config\n",
    "        }, filepath)\n",
    "    \n",
    "    def load_graph(self, filepath: str) -> 'ExcelGraph':\n",
    "        \"\"\"Charge un graphe depuis un fichier\"\"\"\n",
    "        data = torch.load(filepath)\n",
    "        \n",
    "        # Reconstituer les edge_types\n",
    "        edge_types = [EdgeType(et) for et in data['edge_types']]\n",
    "        \n",
    "        return ExcelGraph(\n",
    "            cell_embeddings=data['cell_embeddings'],\n",
    "            edge_embeddings=data['edge_embeddings'],\n",
    "            edge_indices=data['edge_indices'],\n",
    "            edge_types=edge_types,\n",
    "            edge_weights=data['edge_weights'],\n",
    "            cell_positions=data['cell_positions']\n",
    "        )\n",
    "\n",
    "# Fonction utilitaire standalone\n",
    "def json_to_excel_graph(json_data: Union[str, Dict[str, Any]], \n",
    "                        **kwargs) -> 'ExcelGraph':\n",
    "    \"\"\"\n",
    "    Fonction utilitaire pour transformer rapidement un JSON en ExcelGraph\n",
    "    \n",
    "    Args:\n",
    "        json_data: JSON Excel (string ou dict)\n",
    "        **kwargs: Arguments pour JSONToGraphTransformer\n",
    "        \n",
    "    Returns:\n",
    "        ExcelGraph\n",
    "    \"\"\"\n",
    "    transformer = JSONToGraphTransformer(**kwargs)\n",
    "    return transformer.transform(json_data)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # JSON d'exemple (format Univer)\n",
    "    example_json = {\n",
    "        \"styles\": {\n",
    "            \"s0\": {\"fs\": 12.0},\n",
    "            \"s1\": {\"fs\": 16.0, \"bl\": 1, \"cl\": {\"rgb\": \"#FFFFFF\"}, \"bg\": {\"rgb\": \"#4470C4\"}}\n",
    "        },\n",
    "        \"sheets\": {\n",
    "            \"sheet1\": {\n",
    "                \"id\": \"sheet1\",\n",
    "                \"name\": \"Sheet1\",\n",
    "                \"hidden\": 0,\n",
    "                \"rowCount\": 10,\n",
    "                \"columnCount\": 10,\n",
    "                \"mergeData\": [],\n",
    "                \"cellData\": {\n",
    "                    \"0\": {\n",
    "                        \"0\": {\"v\": \"Hello\", \"t\": 1, \"s\": \"s0\"},\n",
    "                        \"1\": {\"v\": \"World\", \"t\": 1, \"s\": \"s1\"}\n",
    "                    },\n",
    "                    \"1\": {\n",
    "                        \"0\": {\"v\": 42, \"t\": 2, \"s\": \"s0\"},\n",
    "                        \"1\": {\"f\": \"=A1&B1\", \"t\": 3, \"s\": \"s0\"}\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"sheet2\": {\n",
    "                \"id\": \"sheet2\", \n",
    "                \"name\": \"Sheet2\",\n",
    "                \"hidden\": 0,\n",
    "                \"rowCount\": 5,\n",
    "                \"columnCount\": 5,\n",
    "                \"mergeData\": [],\n",
    "                \"cellData\": {\n",
    "                    \"0\": {\n",
    "                        \"0\": {\"v\": \"Data\", \"t\": 1, \"s\": \"s0\"},\n",
    "                        \"1\": {\"f\": \"=Sheet1!A1\", \"t\": 3, \"s\": \"s0\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Créer le transformer\n",
    "    transformer = JSONToGraphTransformer(\n",
    "        max_cells_per_sheet=100,\n",
    "        include_empty_cells=False\n",
    "    )\n",
    "    \n",
    "    # Transformer le JSON\n",
    "    excel_graph = transformer.transform(example_json)\n",
    "    \n",
    "    # Afficher les statistiques\n",
    "    stats = transformer.get_graph_statistics(excel_graph)\n",
    "    print(\"Statistiques du graphe:\")\n",
    "    print(f\"  Nombre de nœuds: {stats['num_nodes']}\")\n",
    "    print(f\"  Nombre d'arêtes: {stats['num_edges']}\")\n",
    "    print(f\"  Degré moyen: {stats['avg_degree']:.2f}\")\n",
    "    print(f\"  Nombre de feuilles: {stats['num_sheets']}\")\n",
    "    print(f\"  Feuilles: {stats['sheet_names']}\")\n",
    "    \n",
    "    if 'edge_types' in stats:\n",
    "        print(\"  Types d'arêtes:\")\n",
    "        for edge_type, count in stats['edge_types'].items():\n",
    "            print(f\"    {edge_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nDimensions des embeddings:\")\n",
    "    print(f\"  Cellules: {excel_graph.cell_embeddings.shape}\")\n",
    "    print(f\"  Arêtes: {excel_graph.edge_embeddings.shape}\")\n",
    "    print(f\"  Indices d'arêtes: {excel_graph.edge_indices.shape}\")\n",
    "    \n",
    "    # Test avec une liste de JSON\n",
    "    json_list = [example_json, example_json]\n",
    "    graphs = transformer.transform_batch(json_list)\n",
    "    print(f\"\\nBatch transformé: {len(graphs)} graphes\")\n",
    "    \n",
    "    # Sauvegarde (optionnel)\n",
    "    # transformer.save_graph(excel_graph, \"example_graph.pt\")\n",
    "    \n",
    "    # Test de la fonction utilitaire\n",
    "    quick_graph = json_to_excel_graph(example_json, max_cells_per_sheet=50)\n",
    "    print(f\"\\nGraphe rapide: {quick_graph.num_nodes} nœuds, {quick_graph.num_edges} arêtes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5abb5e0a-c538-4d1a-a942-ed9c213e8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformerLayer(nn.Module):\n",
    "    \"Couche Transformer adaptée aux graphes Excel\"\n",
    "    \n",
    "    def __init__(self, d_model: int, n_heads: int, d_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        # Multi-head attention spatiale\n",
    "        self.spatial_attention = nn.MultiheadAttention(\n",
    "            d_model, n_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Multi-head attention sur les arêtes\n",
    "        self.edge_attention = nn.MultiheadAttention(\n",
    "            d_model, n_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Feed forward\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Gate pour combiner spatial et edge attention\n",
    "        self.gate = nn.Linear(d_model * 2, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, \n",
    "                node_features: torch.Tensor,\n",
    "                edge_indices: torch.Tensor,\n",
    "                edge_features: torch.Tensor,\n",
    "                attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            node_features: [batch_size, num_nodes, d_model]\n",
    "            edge_indices: [2, num_edges] \n",
    "            edge_features: [num_edges, d_model]\n",
    "            attention_mask: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        batch_size, num_nodes, d_model = node_features.shape\n",
    "        \n",
    "        # 1. Attention spatiale globale (toutes les cellules)\n",
    "        spatial_out, spatial_weights = self.spatial_attention(\n",
    "            node_features, node_features, node_features,\n",
    "            attn_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # 2. Attention basée sur les arêtes du graphe\n",
    "        if edge_indices.size(1) > 0:\n",
    "            # Construire les features pour l'attention sur arêtes\n",
    "            edge_source_features = node_features[:, edge_indices[0]]  # [batch, num_edges, d_model]\n",
    "            edge_target_features = node_features[:, edge_indices[1]]  # [batch, num_edges, d_model]\n",
    "            \n",
    "            # Combiner avec les features d'arêtes\n",
    "            edge_combined = edge_source_features + edge_features.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            \n",
    "            # Attention sur les arêtes\n",
    "            edge_out, edge_weights = self.edge_attention(\n",
    "                edge_combined, edge_combined, edge_target_features\n",
    "            )\n",
    "            \n",
    "            # Agréger vers les nœuds (scatter_add simulation)\n",
    "            edge_aggregated = torch.zeros_like(node_features)\n",
    "            for i in range(edge_indices.size(1)):\n",
    "                target_idx = edge_indices[1, i]\n",
    "                edge_aggregated[:, target_idx] += edge_out[:, i]\n",
    "        else:\n",
    "            edge_aggregated = torch.zeros_like(node_features)\n",
    "        \n",
    "        # 3. Combiner spatial et edge attention avec gating\n",
    "        combined_attention = torch.cat([spatial_out, edge_aggregated], dim=-1)\n",
    "        gated_attention = torch.sigmoid(self.gate(combined_attention))\n",
    "        attended = gated_attention * spatial_out + (1 - gated_attention) * edge_aggregated\n",
    "        \n",
    "        # 4. Résiduelle + LayerNorm\n",
    "        x = self.norm1(node_features + self.dropout(attended))\n",
    "        \n",
    "        # 5. Feed Forward\n",
    "        ff_out = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ExcelGraphTransformer(nn.Module):\n",
    "    \"\"\"Transformer principal pour les graphes Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config: EmbeddingConfig,\n",
    "                 num_layers: int = 6,\n",
    "                 n_heads: int = 8,\n",
    "                 d_ff: int = 1024,\n",
    "                 dropout: float = 0.1,\n",
    "                 max_nodes: int = 512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.d_model = config.embedding_dim\n",
    "        self.max_nodes = max_nodes\n",
    "        \n",
    "        # Embedder de cellules optimisé\n",
    "        self.cell_embedder = self._create_cell_embedder(config)\n",
    "        \n",
    "        # Embedder d'arêtes\n",
    "        self.edge_embedder = EdgeEmbedder(config.embedding_dim)\n",
    "        \n",
    "        # Encodage positionnel 2D (row, col)\n",
    "        self.pos_encoding_2d = PositionalEncoding2D(config.embedding_dim)\n",
    "        \n",
    "        # Couches Transformer\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            GraphTransformerLayer(self.d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Projection finale\n",
    "        self.output_projection = nn.Linear(self.d_model, self.d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def _create_cell_embedder(self, config):\n",
    "        \"\"\"Crée un embedder de cellules optimisé\"\"\"\n",
    "        # Version simplifiée avec les dimensions optimisées\n",
    "        class CellEmbedder(nn.Module):\n",
    "            def __init__(self, config):\n",
    "                super().__init__()\n",
    "                self.config = config\n",
    "                \n",
    "                # Position\n",
    "                self.row_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "                self.col_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "                \n",
    "                # Type et contenu\n",
    "                self.type_embedding = nn.Embedding(4, config.type_embedding_dim)\n",
    "                self.value_encoder = ValueEncoder(config)\n",
    "                \n",
    "                # Style simplifié\n",
    "                self.bool_embedding = nn.Embedding(2, 8)\n",
    "                self.font_size_embedding = nn.Embedding(73, 16)\n",
    "                self.color_embedding = nn.Embedding(config.color_vocab_size, 24)\n",
    "                \n",
    "                # Projection finale optimisée\n",
    "                total_dim = (\n",
    "                    2 * config.position_embedding_dim +  # row, col\n",
    "                    config.type_embedding_dim +          # type\n",
    "                    self.value_encoder.output_dim +      # value (256D)\n",
    "                    4 * 8 +                              # bools\n",
    "                    16 + 24 + 48                         # font, colors, etc.\n",
    "                )\n",
    "                \n",
    "                self.projection = nn.Linear(total_dim, config.embedding_dim)\n",
    "                self.layer_norm = nn.LayerNorm(config.embedding_dim)\n",
    "                \n",
    "            def forward(self, cells, mask_indices=None):\n",
    "                if not isinstance(cells, list):\n",
    "                    cells = [cells]\n",
    "                \n",
    "                embeddings = []\n",
    "                for i, cell in enumerate(cells):\n",
    "                    # Position\n",
    "                    row_emb = self.row_embedding(torch.clamp(torch.tensor(cell.row), 0, self.config.max_position - 1))\n",
    "                    col_emb = self.col_embedding(torch.clamp(torch.tensor(cell.col), 0, self.config.max_position - 1))\n",
    "                    \n",
    "                    # Type\n",
    "                    type_emb = self.type_embedding(torch.tensor(cell.cell_type))\n",
    "                    \n",
    "                    # Contenu (avec masking possible)\n",
    "                    mask_content = mask_indices is not None and i in mask_indices\n",
    "                    value_emb = self.value_encoder(cell, mask_content=mask_content)\n",
    "                    \n",
    "                    # Style simplifié\n",
    "                    bold_emb = self.bool_embedding(torch.tensor(int(cell.bold)))\n",
    "                    italic_emb = self.bool_embedding(torch.tensor(int(cell.italic)))\n",
    "                    underline_emb = self.bool_embedding(torch.tensor(int(cell.underline)))\n",
    "                    strike_emb = self.bool_embedding(torch.tensor(int(cell.strike)))\n",
    "                    \n",
    "                    font_size = min(int(cell.font_size), 72)\n",
    "                    font_size_emb = self.font_size_embedding(torch.tensor(font_size))\n",
    "                    \n",
    "                    # Couleurs simplifiées\n",
    "                    text_color_id = self._color_to_id(cell.text_color)\n",
    "                    bg_color_id = self._color_to_id(cell.background_color)\n",
    "                    text_color_emb = self.color_embedding(torch.tensor(text_color_id))\n",
    "                    bg_color_emb = self.color_embedding(torch.tensor(bg_color_id))\n",
    "                    \n",
    "                    # Concaténer\n",
    "                    cell_embedding = torch.cat([\n",
    "                        row_emb, col_emb, type_emb, value_emb,\n",
    "                        bold_emb, italic_emb, underline_emb, strike_emb,\n",
    "                        font_size_emb, text_color_emb, bg_color_emb\n",
    "                    ], dim=0)\n",
    "                    \n",
    "                    embeddings.append(cell_embedding)\n",
    "                \n",
    "                # Stack et projeter\n",
    "                batch_embeddings = torch.stack(embeddings)\n",
    "                projected = self.projection(batch_embeddings)\n",
    "                normalized = self.layer_norm(projected)\n",
    "                \n",
    "                return normalized.squeeze(0) if len(cells) == 1 else normalized\n",
    "            \n",
    "            def _color_to_id(self, color: str) -> int:\n",
    "                if not color or color == \"#FFFFFF\":\n",
    "                    return 0\n",
    "                try:\n",
    "                    hex_val = int(color.replace(\"#\", \"\"), 16)\n",
    "                    return (hex_val % (self.config.color_vocab_size - 1)) + 1\n",
    "                except:\n",
    "                    return 0\n",
    "        \n",
    "        return CellEmbedder(config)\n",
    "    \n",
    "    def forward(self, \n",
    "                excel_graph: 'ExcelGraph',\n",
    "                mask_indices: Optional[List[int]] = None) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass du transformer\n",
    "        \n",
    "        Args:\n",
    "            excel_graph: Graphe Excel avec embeddings\n",
    "            mask_indices: Indices des cellules à masquer\n",
    "            \n",
    "        Returns:\n",
    "            Dict avec les embeddings et logits\n",
    "        \"\"\"\n",
    "        # Récupérer les features\n",
    "        node_features = excel_graph.cell_embeddings.unsqueeze(0)  # [1, num_nodes, d_model]\n",
    "        edge_indices = excel_graph.edge_indices\n",
    "        edge_features = excel_graph.edge_embeddings\n",
    "        \n",
    "        # Ajouter l'encodage positionnel 2D\n",
    "        positions = [(pos[0], pos[1]) for pos in excel_graph.cell_positions]\n",
    "        pos_encoding = self.pos_encoding_2d(positions, node_features.device)\n",
    "        node_features = node_features + pos_encoding.unsqueeze(0)\n",
    "        \n",
    "        # Appliquer les couches Transformer\n",
    "        x = node_features\n",
    "        attention_weights = []\n",
    "        \n",
    "        for layer in self.transformer_layers:\n",
    "            x = layer(x, edge_indices, edge_features)\n",
    "        \n",
    "        # Projection finale\n",
    "        output_embeddings = self.output_projection(x)\n",
    "        \n",
    "        return {\n",
    "            'embeddings': output_embeddings,\n",
    "            'hidden_states': x,\n",
    "            'masked_indices': mask_indices\n",
    "        }\n",
    "\n",
    "class PositionalEncoding2D(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # S'assurer que d_model est divisible par 4 pour row/col encoding\n",
    "        if d_model % 4 != 0:\n",
    "            d_model_adj = ((d_model // 4) + 1) * 4\n",
    "            self.projection = nn.Linear(d_model_adj, d_model)\n",
    "        else:\n",
    "            d_model_adj = d_model\n",
    "            self.projection = None\n",
    "        \n",
    "        # Créer un tensor pour stocker les encodages\n",
    "        pe = torch.zeros(max_len, max_len, d_model_adj)\n",
    "        dim_per_component = d_model_adj // 2\n",
    "        \n",
    "        # Position encoding pour les lignes (première moitié des dimensions)\n",
    "        for row in range(max_len):\n",
    "            for pos_dim in range(0, dim_per_component, 2):\n",
    "                div_term = 10000.0 ** (pos_dim / dim_per_component)\n",
    "                pe[row, :, pos_dim] = torch.sin(row / div_term)\n",
    "                if pos_dim + 1 < dim_per_component:\n",
    "                    pe[row, :, pos_dim + 1] = torch.cos(row / div_term)\n",
    "        \n",
    "        # Position encoding pour les colonnes (deuxième moitié des dimensions)\n",
    "        for col in range(max_len):\n",
    "            for pos_dim in range(dim_per_component, d_model_adj, 2):\n",
    "                rel_dim = pos_dim - dim_per_component\n",
    "                div_term = 10000.0 ** (rel_dim / dim_per_component)\n",
    "                pe[:, col, pos_dim] = torch.sin(col / div_term)\n",
    "                if pos_dim + 1 < d_model_adj:\n",
    "                    pe[:, col, pos_dim + 1] = torch.cos(col / div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, positions: List[Tuple[int, int]], device: torch.device) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            positions: Liste de (row, col)\n",
    "            device: Device PyTorch\n",
    "        \"\"\"\n",
    "        batch_pos = []\n",
    "        for row, col in positions:\n",
    "            row = min(row, self.pe.size(0) - 1)\n",
    "            col = min(col, self.pe.size(1) - 1)\n",
    "            pos_encoding = self.pe[row, col]\n",
    "            \n",
    "            # Projeter si nécessaire\n",
    "            if self.projection is not None:\n",
    "                pos_encoding = self.projection(pos_encoding)\n",
    "            \n",
    "            batch_pos.append(pos_encoding)\n",
    "        \n",
    "        return torch.stack(batch_pos).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf3f1a3-44bf-4430-a354-5fa8f4f464b7",
   "metadata": {},
   "source": [
    "Tache d'apprentissage : Masked Cell Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "814eb582-77a4-4d3e-b47b-a1589e5112fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes manquantes pour l'entraînement\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "class ExcelMaskedDataset(Dataset):\n",
    "    \"\"\"Dataset pour l'entraînement avec masquage de cellules\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 json_files: List[Dict[str, Any]],\n",
    "                 transformer_builder: 'JSONToGraphTransformer',\n",
    "                 mask_ratio: float = 0.15,\n",
    "                 num_candidates: int = 10):\n",
    "        self.json_files = json_files\n",
    "        self.transformer_builder = transformer_builder\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.num_candidates = num_candidates\n",
    "        \n",
    "        # Pré-traiter les données\n",
    "        self.samples = []\n",
    "        self._prepare_samples()\n",
    "    \n",
    "    def _prepare_samples(self):\n",
    "        \"\"\"Prépare les échantillons d'entraînement\"\"\"\n",
    "        for i, json_data in enumerate(self.json_files):\n",
    "            try:\n",
    "                # Extraire les cellules\n",
    "                cells = self.transformer_builder._extract_cells_from_json(json_data)\n",
    "                cells = self.transformer_builder._filter_cells(cells, max_total_cells=200)\n",
    "                \n",
    "                if len(cells) < 3:  # Besoin d'au moins 3 cellules\n",
    "                    continue\n",
    "                \n",
    "                # Créer le graphe\n",
    "                graph = self.transformer_builder.graph_embedder(cells)\n",
    "                \n",
    "                # Choisir les cellules à masquer\n",
    "                mask_indices = ExcelMaskingStrategy.random_masking(cells, self.mask_ratio)\n",
    "                if not mask_indices:\n",
    "                    continue\n",
    "                \n",
    "                # Générer les candidats\n",
    "                candidates = []\n",
    "                labels = []  # Position du bon candidat\n",
    "                \n",
    "                for mask_idx in mask_indices:\n",
    "                    cell = cells[mask_idx]\n",
    "                    cell_candidates = generate_candidates(cell, self.num_candidates)\n",
    "                    \n",
    "                    # S'assurer que la vraie valeur est dans les candidats\n",
    "                    true_value = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"\"\n",
    "                    \n",
    "                    if true_value and true_value not in cell_candidates:\n",
    "                        # Remplacer un candidat aléatoire par la vraie valeur\n",
    "                        random_idx = random.randint(0, len(cell_candidates) - 1)\n",
    "                        cell_candidates[random_idx] = true_value\n",
    "                    \n",
    "                    # Trouver la position de la vraie valeur\n",
    "                    try:\n",
    "                        label = cell_candidates.index(true_value)\n",
    "                    except ValueError:\n",
    "                        label = 0  # Par défaut\n",
    "                    \n",
    "                    candidates.append(cell_candidates)\n",
    "                    labels.append(label)\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'graph': graph,\n",
    "                    'mask_indices': mask_indices,\n",
    "                    'candidates': candidates,\n",
    "                    'labels': labels,\n",
    "                    'file_id': i\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erreur échantillon {i}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "class MaskedPredictionTrainer:\n",
    "    \"\"\"Entraîneur pour la tâche de masked prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: 'MaskedCellPredictor',\n",
    "                 learning_rate: float = 1e-4,\n",
    "                 weight_decay: float = 1e-5):\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=learning_rate, \n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=100, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        # Métriques d'entraînement\n",
    "        self.training_history = []\n",
    "    \n",
    "    def train_epoch(self, dataloader: DataLoader, epoch: int) -> Dict[str, float]:\n",
    "        \"\"\"Entraîne le modèle sur une époque\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_predictions = 0\n",
    "        top3_correct = 0\n",
    "        top5_correct = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            try:\n",
    "                # Forward pass\n",
    "                graph = batch['graph']\n",
    "                mask_indices = batch['mask_indices']\n",
    "                candidates = batch['candidates']\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                # Prédiction\n",
    "                output = self.model(graph, mask_indices, candidates)\n",
    "                logits = output['logits']  # [num_masked, num_candidates]\n",
    "                \n",
    "                # Loss (Cross-entropy)\n",
    "                # Flatten pour le calcul de loss\n",
    "                labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "                loss = F.cross_entropy(logits, labels_tensor)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Métriques\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Accuracy\n",
    "                probabilities = F.softmax(logits, dim=-1)\n",
    "                predictions = torch.argmax(probabilities, dim=-1)\n",
    "                \n",
    "                correct = (predictions == labels_tensor).sum().item()\n",
    "                total_correct += correct\n",
    "                total_predictions += len(labels)\n",
    "                \n",
    "                # Top-k accuracy\n",
    "                _, top_k = torch.topk(probabilities, k=5, dim=-1)\n",
    "                labels_expanded = labels_tensor.unsqueeze(1).expand_as(top_k)\n",
    "                \n",
    "                top3_correct += (labels_expanded[:, :3] == top_k[:, :3]).any(dim=1).sum().item()\n",
    "                top5_correct += (labels_expanded == top_k).any(dim=1).sum().item()\n",
    "                \n",
    "                # Logging\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(f\"  Batch {batch_idx}: Loss {loss.item():.4f}, Acc {correct/len(labels):.1%}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erreur batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Scheduler step\n",
    "        self.scheduler.step()\n",
    "        \n",
    "        # Métriques d'époque\n",
    "        epoch_metrics = {\n",
    "            'loss': total_loss / len(dataloader) if len(dataloader) > 0 else 0,\n",
    "            'accuracy': total_correct / total_predictions if total_predictions > 0 else 0,\n",
    "            'top3_accuracy': top3_correct / total_predictions if total_predictions > 0 else 0,\n",
    "            'top5_accuracy': top5_correct / total_predictions if total_predictions > 0 else 0,\n",
    "            'total_predictions': total_predictions,\n",
    "            'epoch_time': time.time() - start_time,\n",
    "            'learning_rate': self.optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "        \n",
    "        self.training_history.append(epoch_metrics)\n",
    "        return epoch_metrics\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Fonction de collation pour le DataLoader\"\"\"\n",
    "    # Pour l'instant, on ne supporte que batch_size=1\n",
    "    if len(batch) == 1:\n",
    "        return batch[0]\n",
    "    else:\n",
    "        # Pour les batches plus grands, il faudrait implémenter\n",
    "        # le padding/batching des graphes\n",
    "        raise NotImplementedError(\"Batch size > 1 pas encore supporté\")\n",
    "\n",
    "def load_json_files(data_folder: str) -> tuple:\n",
    "    \"\"\"Charge tous les fichiers JSON du dossier\"\"\"\n",
    "    json_files = []\n",
    "    file_paths = []\n",
    "    \n",
    "    patterns = [\n",
    "        os.path.join(data_folder, \"*.json\"),\n",
    "        os.path.join(data_folder, \"**\", \"*.json\")\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        found_files = glob.glob(pattern, recursive=True)\n",
    "        for file_path in found_files:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                json_files.append(data)\n",
    "                file_paths.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur chargement {file_path}: {e}\")\n",
    "    \n",
    "    return json_files, file_paths\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "def run_full_training_on_your_data():\n",
    "    \"\"\"Lance l'entraînement complet sur vos données\"\"\"\n",
    "    \n",
    "    print(\"🚀 ENTRAÎNEMENT COMPLET SUR VOS DONNÉES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Configuration adaptée\n",
    "    config = EmbeddingConfig(\n",
    "        embedding_dim=256,  # Divisible par 4\n",
    "        position_embedding_dim=32,\n",
    "        max_position=2000,\n",
    "        color_vocab_size=300\n",
    "    )\n",
    "    \n",
    "    # Transformer builder\n",
    "    transformer_builder = JSONToGraphTransformer(\n",
    "        embedding_config=config,\n",
    "        max_cells_per_sheet=500,\n",
    "        include_empty_cells=False\n",
    "    )\n",
    "    \n",
    "    # Modèle plus robuste\n",
    "    excel_transformer = ExcelGraphTransformer(\n",
    "        config, \n",
    "        num_layers=6,\n",
    "        n_heads=8, \n",
    "        d_ff=1024\n",
    "    )\n",
    "    \n",
    "    predictor = MaskedCellPredictor(excel_transformer, num_candidates=10)\n",
    "    \n",
    "    # Charger vos données\n",
    "    json_files, file_paths = load_json_files(\"data\")\n",
    "    print(f\"Fichiers chargés: {len(json_files)}\")\n",
    "    \n",
    "    # Limiter pour le test\n",
    "    if len(json_files) > 10:\n",
    "        json_files = json_files[:10]\n",
    "    \n",
    "    # Dataset\n",
    "    dataset = ExcelMaskedDataset(\n",
    "        json_files,\n",
    "        transformer_builder,\n",
    "        mask_ratio=0.15,\n",
    "        num_candidates=10\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset créé: {len(dataset)} échantillons\")\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"❌ Dataset vide!\")\n",
    "        return None, None\n",
    "    \n",
    "    # DataLoader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Entraîneur\n",
    "    trainer = MaskedPredictionTrainer(predictor)\n",
    "    \n",
    "    # Entraînement\n",
    "    num_epochs = 10\n",
    "    print(f\"Entraînement sur {num_epochs} époques...\")\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nÉpoque {epoch + 1}/{num_epochs}:\")\n",
    "        \n",
    "        epoch_metrics = trainer.train_epoch(dataloader, epoch)\n",
    "        \n",
    "        print(f\"  Loss: {epoch_metrics['loss']:.4f}\")\n",
    "        print(f\"  Accuracy: {epoch_metrics['accuracy']:.1%}\")\n",
    "        print(f\"  Top-3: {epoch_metrics['top3_accuracy']:.1%}\")\n",
    "        print(f\"  Top-5: {epoch_metrics['top5_accuracy']:.1%}\")\n",
    "        \n",
    "        if epoch_metrics['accuracy'] > best_accuracy:\n",
    "            best_accuracy = epoch_metrics['accuracy']\n",
    "            torch.save(predictor.state_dict(), \"best_model.pt\")\n",
    "            print(f\"  ⭐ Nouveau record: {best_accuracy:.1%}\")\n",
    "    \n",
    "    return predictor, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c752602-3d44-4aca-9533-b21be1010286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCellPredictor(nn.Module):\n",
    "    \"\"\"Modèle pour prédire les cellules masquées\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 transformer: ExcelGraphTransformer,\n",
    "                 num_candidates: int = 10):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "        self.num_candidates = num_candidates\n",
    "        \n",
    "        # Tête de classification pour choisir parmi les candidats\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(transformer.d_model, transformer.d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(transformer.d_model // 2, num_candidates)\n",
    "        )\n",
    "        \n",
    "    def forward(self, \n",
    "                excel_graph: 'ExcelGraph',\n",
    "                mask_indices: List[int],\n",
    "                candidates: List[List[str]]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            excel_graph: Graphe Excel\n",
    "            mask_indices: Indices des cellules masquées\n",
    "            candidates: Liste de candidats pour chaque cellule masquée\n",
    "            \n",
    "        Returns:\n",
    "            Dict avec logits et probabilités\n",
    "        \"\"\"\n",
    "        # Forward pass du transformer\n",
    "        transformer_output = self.transformer(excel_graph, mask_indices)\n",
    "        embeddings = transformer_output['embeddings']  # [1, num_nodes, d_model]\n",
    "        \n",
    "        # Extraire les embeddings des cellules masquées\n",
    "        masked_embeddings = embeddings[0, mask_indices]  # [num_masked, d_model]\n",
    "        \n",
    "        # Prédiction pour chaque cellule masquée\n",
    "        logits = self.classification_head(masked_embeddings)  # [num_masked, num_candidates]\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        return {\n",
    "            'logits': logits,\n",
    "            'probabilities': probabilities,\n",
    "            'masked_embeddings': masked_embeddings,\n",
    "            'candidates': candidates\n",
    "        }\n",
    "    \n",
    "    def predict_top_candidates(self, \n",
    "                              excel_graph: 'ExcelGraph',\n",
    "                              mask_indices: List[int],\n",
    "                              candidates: List[List[str]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Prédit et retourne les candidats ordonnés par probabilité\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(excel_graph, mask_indices, candidates)\n",
    "            probabilities = output['probabilities']\n",
    "            \n",
    "            predictions = []\n",
    "            for i, (mask_idx, cell_candidates) in enumerate(zip(mask_indices, candidates)):\n",
    "                probs = probabilities[i].cpu().numpy()\n",
    "                \n",
    "                # Ordonner par probabilité décroissante\n",
    "                sorted_indices = np.argsort(probs)[::-1]\n",
    "                \n",
    "                prediction = {\n",
    "                    'cell_index': mask_idx,\n",
    "                    'candidates_ranked': [\n",
    "                        {\n",
    "                            'value': cell_candidates[idx] if idx < len(cell_candidates) else f\"candidate_{idx}\",\n",
    "                            'probability': float(probs[idx]),\n",
    "                            'rank': rank + 1\n",
    "                        }\n",
    "                        for rank, idx in enumerate(sorted_indices)\n",
    "                    ]\n",
    "                }\n",
    "                predictions.append(prediction)\n",
    "            \n",
    "            return predictions\n",
    "\n",
    "# Utilitaires pour l'entraînement\n",
    "class ExcelMaskingStrategy:\n",
    "    \"\"\"Stratégies pour masquer les cellules\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_masking(cells: List['FullCellInfo'], \n",
    "                      mask_ratio: float = 0.15) -> List[int]:\n",
    "        \"\"\"Masquage aléatoire\"\"\"\n",
    "        num_cells = len(cells)\n",
    "        num_mask = int(num_cells * mask_ratio)\n",
    "        \n",
    "        # Privilégier les cellules avec contenu\n",
    "        content_indices = [i for i, cell in enumerate(cells) \n",
    "                          if cell.raw_value or cell.formula]\n",
    "        \n",
    "        if len(content_indices) >= num_mask:\n",
    "            return random.sample(content_indices, num_mask)\n",
    "        else:\n",
    "            # Compléter avec des cellules aléatoires\n",
    "            remaining = num_mask - len(content_indices)\n",
    "            other_indices = [i for i in range(num_cells) if i not in content_indices]\n",
    "            additional = random.sample(other_indices, min(remaining, len(other_indices)))\n",
    "            return content_indices + additional\n",
    "    \n",
    "    @staticmethod\n",
    "    def strategic_masking(cells: List['FullCellInfo']) -> List[int]:\n",
    "        \"\"\"Masquage stratégique (formules, valeurs importantes)\"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        for i, cell in enumerate(cells):\n",
    "            priority = 0\n",
    "            \n",
    "            # Formules = haute priorité\n",
    "            if cell.formula:\n",
    "                priority += 100\n",
    "            \n",
    "            # Valeurs numériques = moyenne priorité\n",
    "            elif cell.cell_type == 2:\n",
    "                priority += 50\n",
    "            \n",
    "            # Texte = basse priorité\n",
    "            elif cell.cell_type == 1:\n",
    "                priority += 25\n",
    "            \n",
    "            if priority > 0:\n",
    "                candidates.append((i, priority))\n",
    "        \n",
    "        # Prendre les plus prioritaires\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        num_mask = min(3, len(candidates))  # Masquer au plus 3 cellules\n",
    "        \n",
    "        return [idx for idx, _ in candidates[:num_mask]]\n",
    "\n",
    "def generate_candidates(cell: 'FullCellInfo', num_candidates: int = 10) -> List[str]:\n",
    "    \"\"\"Génère des candidats pour une cellule masquée\"\"\"\n",
    "    candidates = []\n",
    "    \n",
    "    if cell.cell_type == 2:  # Nombre\n",
    "        # Candidats numériques\n",
    "        try:\n",
    "            original = float(cell.raw_value) if cell.raw_value else 0\n",
    "            candidates = [\n",
    "                str(original),  # Valeur originale\n",
    "                str(original * 2),\n",
    "                str(original + 1),\n",
    "                str(original - 1),\n",
    "                str(int(original * 1.1)),\n",
    "                \"0\", \"1\", \"100\", \"42\", \"999\"\n",
    "            ]\n",
    "        except:\n",
    "            candidates = [\"0\", \"1\", \"10\", \"100\", \"42\", \"999\", \"1.5\", \"2.0\", \"3.14\", \"50\"]\n",
    "    \n",
    "    elif cell.cell_type == 1:  # Texte\n",
    "        original = str(cell.raw_value) if cell.raw_value else \"\"\n",
    "        candidates = [\n",
    "            original,  # Valeur originale\n",
    "            original.upper(),\n",
    "            original.lower(),\n",
    "            original + \"_copy\",\n",
    "            \"Text\", \"Data\", \"Value\", \"Item\", \"Total\", \"Summary\"\n",
    "        ]\n",
    "    \n",
    "    elif cell.cell_type == 3:  # Formule\n",
    "        candidates = [\n",
    "            cell.formula,  # Formule originale\n",
    "            \"=SUM(A1:A10)\",\n",
    "            \"=AVERAGE(B1:B5)\",\n",
    "            \"=COUNT(C1:C20)\",\n",
    "            \"=MAX(D1:D10)\",\n",
    "            \"=MIN(E1:E10)\",\n",
    "            \"=IF(F1>0,\\\"Yes\\\",\\\"No\\\")\",\n",
    "            \"=VLOOKUP(G1,A:B,2,FALSE)\",\n",
    "            \"=TODAY()\",\n",
    "            \"=CONCATENATE(H1,I1)\"\n",
    "        ]\n",
    "    \n",
    "    else:  # Vide\n",
    "        candidates = [\n",
    "            \"\", \"0\", \"1\", \"Text\", \"Data\", \"=SUM(A1:A5)\", \n",
    "            \"Total\", \"N/A\", \"TBD\", \"...\"\n",
    "        ]\n",
    "    \n",
    "    # S'assurer qu'on a exactement num_candidates\n",
    "    while len(candidates) < num_candidates:\n",
    "        candidates.append(f\"option_{len(candidates)}\")\n",
    "    \n",
    "    return candidates[:num_candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c593a8-b89b-4a7f-afda-1a3f92109d8d",
   "metadata": {},
   "source": [
    "Pipe pour application sur le dossier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a14793a-c0ff-4fa8-a015-2296552c0a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 INSTRUCTIONS D'UTILISATION DANS LE NOTEBOOK:\n",
      "\n",
      "1. Placez vos fichiers *.json dans le dossier 'data/'\n",
      "\n",
      "2. Exécutez cette cellule pour charger les fonctions\n",
      "\n",
      "3. Lancez l'analyse avec:\n",
      "   result = analyze_my_data(\"data\")\n",
      "\n",
      "4. Pour limiter à quelques fichiers:\n",
      "   result = analyze_my_data(\"data\", max_files=5)\n",
      "\n",
      "5. Les résultats seront affichés et un rapport HTML sera créé.\n",
      "\n",
      "📊 Cette version analyse vos données et évalue la faisabilité\n",
      "   d'un entraînement complet sans lancer le transformer lourd.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Version compatible avec Jupyter Notebook\n",
    "# À exécuter directement dans une cellule de notebook\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration pour éviter les conflits dans Jupyter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_pipeline_notebook(data_folder=\"data\", max_files=None, quick_mode=True):\n",
    "    \"\"\"\n",
    "    Version simplifiée de la pipeline pour notebook Jupyter\n",
    "    \n",
    "    Args:\n",
    "        data_folder: Dossier contenant les fichiers JSON\n",
    "        max_files: Nombre maximum de fichiers à traiter (None = tous)\n",
    "        quick_mode: Mode rapide avec moins d'époques\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🚀 PIPELINE EXCEL TRANSFORMER - VERSION NOTEBOOK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Vérification de l'environnement\n",
    "    print(\"\\n1️⃣ VÉRIFICATION DE L'ENVIRONNEMENT\")\n",
    "    \n",
    "    try:\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        print(f\"✅ PyTorch: {torch.__version__}\")\n",
    "        print(f\"✅ NumPy: {np.__version__}\")\n",
    "        print(f\"✅ Pandas: {pd.__version__}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Module manquant: {e}\")\n",
    "        return {\"error\": f\"Missing module: {e}\"}\n",
    "    \n",
    "    # 2. Recherche des fichiers JSON\n",
    "    print(f\"\\n2️⃣ RECHERCHE DES FICHIERS JSON DANS '{data_folder}'\")\n",
    "    \n",
    "    if not os.path.exists(data_folder):\n",
    "        print(f\"❌ Le dossier '{data_folder}' n'existe pas!\")\n",
    "        print(\"💡 Créez le dossier et placez-y vos fichiers *.json\")\n",
    "        return {\"error\": f\"Folder {data_folder} not found\"}\n",
    "    \n",
    "    # Patterns de recherche\n",
    "    json_files = []\n",
    "    patterns = [\n",
    "        os.path.join(data_folder, \"*.json\"),\n",
    "        os.path.join(data_folder, \"**\", \"*.json\")\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        found_files = glob.glob(pattern, recursive=True)\n",
    "        json_files.extend(found_files)\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"❌ Aucun fichier *.json trouvé dans '{data_folder}'\")\n",
    "        return {\"error\": \"No JSON files found\"}\n",
    "    \n",
    "    print(f\"📁 Trouvé {len(json_files)} fichiers JSON\")\n",
    "    \n",
    "    # Limiter si nécessaire\n",
    "    if max_files and len(json_files) > max_files:\n",
    "        json_files = json_files[:max_files]\n",
    "        print(f\"🔄 Limitation à {max_files} fichiers\")\n",
    "    \n",
    "    # 3. Analyse des fichiers\n",
    "    print(f\"\\n3️⃣ ANALYSE DES FICHIERS\")\n",
    "    \n",
    "    valid_files = []\n",
    "    analysis_summary = {\n",
    "        'total_files': len(json_files),\n",
    "        'valid_files': 0,\n",
    "        'total_cells': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    for i, file_path in enumerate(json_files):\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Validation structure Excel\n",
    "            cell_count = 0\n",
    "            is_valid = False\n",
    "            \n",
    "            if 'sheets' in data:\n",
    "                for sheet_data in data['sheets'].values():\n",
    "                    if 'cellData' in sheet_data:\n",
    "                        for row_data in sheet_data['cellData'].values():\n",
    "                            cell_count += len(row_data)\n",
    "                        is_valid = True\n",
    "            \n",
    "            if is_valid and cell_count > 0:\n",
    "                valid_files.append(data)\n",
    "                analysis_summary['valid_files'] += 1\n",
    "                analysis_summary['total_cells'] += cell_count\n",
    "                print(f\"  ✅ {filename}: {cell_count} cellules\")\n",
    "            else:\n",
    "                print(f\"  ⚠️  {filename}: Structure non-Excel ou vide\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"{filename}: {str(e)[:50]}...\"\n",
    "            analysis_summary['errors'].append(error_msg)\n",
    "            print(f\"  ❌ {error_msg}\")\n",
    "    \n",
    "    print(f\"\\n📊 RÉSUMÉ DE L'ANALYSE:\")\n",
    "    print(f\"   Fichiers analysés: {analysis_summary['total_files']}\")\n",
    "    print(f\"   Fichiers valides: {analysis_summary['valid_files']}\")\n",
    "    print(f\"   Total cellules: {analysis_summary['total_cells']}\")\n",
    "    print(f\"   Erreurs: {len(analysis_summary['errors'])}\")\n",
    "    \n",
    "    if analysis_summary['valid_files'] == 0:\n",
    "        print(\"❌ Aucun fichier Excel valide trouvé!\")\n",
    "        return {\"error\": \"No valid Excel files\", \"analysis\": analysis_summary}\n",
    "    \n",
    "    # 4. Test de base sur les données (sans transformer complet)\n",
    "    print(f\"\\n4️⃣ TEST DE BASE SUR LES DONNÉES\")\n",
    "    \n",
    "    # Prendre les premiers fichiers pour test\n",
    "    test_files = valid_files[:min(3, len(valid_files))]\n",
    "    \n",
    "    cells_extracted = 0\n",
    "    sheets_found = 0\n",
    "    formulas_found = 0\n",
    "    \n",
    "    for file_data in test_files:\n",
    "        for sheet_data in file_data.get('sheets', {}).values():\n",
    "            sheets_found += 1\n",
    "            cell_data = sheet_data.get('cellData', {})\n",
    "            \n",
    "            for row_data in cell_data.values():\n",
    "                for cell_info in row_data.values():\n",
    "                    cells_extracted += 1\n",
    "                    if cell_info.get('f'):  # Formule\n",
    "                        formulas_found += 1\n",
    "    \n",
    "    print(f\"✅ Test réussi:\")\n",
    "    print(f\"   Cellules extraites: {cells_extracted}\")\n",
    "    print(f\"   Feuilles trouvées: {sheets_found}\")\n",
    "    print(f\"   Formules trouvées: {formulas_found}\")\n",
    "    \n",
    "    # 5. Simulation d'entraînement simple\n",
    "    print(f\"\\n5️⃣ SIMULATION D'ENTRAÎNEMENT\")\n",
    "    \n",
    "    # Statistiques des types de cellules\n",
    "    cell_types = {'empty': 0, 'text': 0, 'number': 0, 'formula': 0}\n",
    "    \n",
    "    for file_data in test_files:\n",
    "        for sheet_data in file_data.get('sheets', {}).values():\n",
    "            cell_data = sheet_data.get('cellData', {})\n",
    "            for row_data in cell_data.values():\n",
    "                for cell_info in row_data.values():\n",
    "                    cell_type = cell_info.get('t', 0)\n",
    "                    if cell_type == 0:\n",
    "                        cell_types['empty'] += 1\n",
    "                    elif cell_type == 1:\n",
    "                        cell_types['text'] += 1\n",
    "                    elif cell_type == 2:\n",
    "                        cell_types['number'] += 1\n",
    "                    elif cell_type == 3:\n",
    "                        cell_types['formula'] += 1\n",
    "    \n",
    "    print(\"📊 Types de cellules détectés:\")\n",
    "    total_cells = sum(cell_types.values())\n",
    "    for cell_type, count in cell_types.items():\n",
    "        percentage = (count / total_cells * 100) if total_cells > 0 else 0\n",
    "        print(f\"   {cell_type}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 6. Simulation de prédictions\n",
    "    print(f\"\\n6️⃣ SIMULATION DE PRÉDICTIONS\")\n",
    "    \n",
    "    # Générer des candidats pour quelques cellules d'exemple\n",
    "    sample_predictions = []\n",
    "    \n",
    "    # Prendre quelques cellules d'exemple\n",
    "    for file_data in test_files[:2]:\n",
    "        for sheet_data in file_data.get('sheets', {}).values():\n",
    "            cell_data = sheet_data.get('cellData', {})\n",
    "            count = 0\n",
    "            for row_key, row_data in cell_data.items():\n",
    "                for col_key, cell_info in row_data.items():\n",
    "                    if count >= 3:  # Limiter à 3 exemples par fichier\n",
    "                        break\n",
    "                    \n",
    "                    value = cell_info.get('v', '')\n",
    "                    cell_type = cell_info.get('t', 0)\n",
    "                    formula = cell_info.get('f', '')\n",
    "                    \n",
    "                    # Générer des candidats selon le type\n",
    "                    candidates = []\n",
    "                    if cell_type == 1:  # Texte\n",
    "                        candidates = [str(value), f\"{value}_copy\", \"Text\", \"Data\", \"Item\"]\n",
    "                    elif cell_type == 2:  # Nombre\n",
    "                        try:\n",
    "                            num_val = float(value) if value else 0\n",
    "                            candidates = [str(value), str(num_val + 1), str(num_val * 2), \"0\", \"100\"]\n",
    "                        except:\n",
    "                            candidates = [\"0\", \"1\", \"10\", \"100\", str(value)]\n",
    "                    elif cell_type == 3:  # Formule\n",
    "                        candidates = [formula, \"=SUM(A1:A10)\", \"=AVERAGE(B1:B5)\", \"=COUNT(C1:C10)\", \"=MAX(D1:D5)\"]\n",
    "                    else:\n",
    "                        candidates = [\"\", \"0\", \"Text\", \"Data\", \"N/A\"]\n",
    "                    \n",
    "                    # Simuler une prédiction (le vrai modèle assignerait des probabilités)\n",
    "                    predicted_probs = np.random.dirichlet([2, 1, 1, 1, 1])  # Favoriser le premier candidat\n",
    "                    \n",
    "                    sample_predictions.append({\n",
    "                        'position': f\"({row_key},{col_key})\",\n",
    "                        'true_value': str(value) if value else str(formula),\n",
    "                        'cell_type': ['Empty', 'Text', 'Number', 'Formula'][cell_type],\n",
    "                        'candidates': candidates[:5],\n",
    "                        'probabilities': predicted_probs[:5].tolist()\n",
    "                    })\n",
    "                    \n",
    "                    count += 1\n",
    "                if count >= 3:\n",
    "                    break\n",
    "    \n",
    "    print(\"🔮 Exemples de prédictions simulées:\")\n",
    "    for i, pred in enumerate(sample_predictions[:5]):\n",
    "        print(f\"\\n   Exemple {i+1} - Position {pred['position']} ({pred['cell_type']}):\")\n",
    "        print(f\"      Vraie valeur: '{pred['true_value']}'\")\n",
    "        print(\"      Top 3 prédictions:\")\n",
    "        \n",
    "        # Trier par probabilité\n",
    "        sorted_preds = sorted(zip(pred['candidates'], pred['probabilities']), \n",
    "                            key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for rank, (candidate, prob) in enumerate(sorted_preds[:3]):\n",
    "            marker = \"🎯\" if candidate == pred['true_value'] else f\"{rank+1}.\"\n",
    "            print(f\"         {marker} {candidate[:20]:20s} ({prob:.1%})\")\n",
    "    \n",
    "    # 7. Rapport de faisabilité\n",
    "    print(f\"\\n7️⃣ RAPPORT DE FAISABILITÉ\")\n",
    "    \n",
    "    feasibility_score = 0\n",
    "    recommendations = []\n",
    "    \n",
    "    # Évaluer la faisabilité\n",
    "    if analysis_summary['valid_files'] >= 5:\n",
    "        feasibility_score += 30\n",
    "        recommendations.append(\"✅ Nombre suffisant de fichiers pour l'entraînement\")\n",
    "    else:\n",
    "        recommendations.append(\"⚠️ Peu de fichiers - entraînement limité possible\")\n",
    "    \n",
    "    if analysis_summary['total_cells'] >= 1000:\n",
    "        feasibility_score += 40\n",
    "        recommendations.append(\"✅ Nombre suffisant de cellules pour l'entraînement\")\n",
    "    elif analysis_summary['total_cells'] >= 100:\n",
    "        feasibility_score += 20\n",
    "        recommendations.append(\"⚠️ Nombre modéré de cellules - entraînement possible mais limité\")\n",
    "    else:\n",
    "        recommendations.append(\"❌ Trop peu de cellules pour un entraînement efficace\")\n",
    "    \n",
    "    if formulas_found >= 10:\n",
    "        feasibility_score += 20\n",
    "        recommendations.append(\"✅ Formules détectées - apprentissage des relations possible\")\n",
    "    elif formulas_found > 0:\n",
    "        feasibility_score += 10\n",
    "        recommendations.append(\"⚠️ Quelques formules - apprentissage partiel possible\")\n",
    "    else:\n",
    "        recommendations.append(\"⚠️ Aucune formule - apprentissage limité aux valeurs\")\n",
    "    \n",
    "    if len(analysis_summary['errors']) == 0:\n",
    "        feasibility_score += 10\n",
    "        recommendations.append(\"✅ Aucune erreur de format\")\n",
    "    else:\n",
    "        recommendations.append(f\"⚠️ {len(analysis_summary['errors'])} fichiers avec erreurs\")\n",
    "    \n",
    "    print(f\"📊 Score de faisabilité: {feasibility_score}/100\")\n",
    "    \n",
    "    if feasibility_score >= 70:\n",
    "        print(\"🟢 FAISABILITÉ ÉLEVÉE - Entraînement recommandé\")\n",
    "    elif feasibility_score >= 40:\n",
    "        print(\"🟡 FAISABILITÉ MODÉRÉE - Entraînement possible avec limitations\")\n",
    "    else:\n",
    "        print(\"🔴 FAISABILITÉ FAIBLE - Améliorer les données avant entraînement\")\n",
    "    \n",
    "    print(\"\\n💡 RECOMMANDATIONS:\")\n",
    "    for rec in recommendations:\n",
    "        print(f\"   {rec}\")\n",
    "    \n",
    "    # 8. Prochaines étapes\n",
    "    print(f\"\\n8️⃣ PROCHAINES ÉTAPES\")\n",
    "    \n",
    "    if feasibility_score >= 40:\n",
    "        print(\"Pour lancer l'entraînement complet:\")\n",
    "        print(\"1. 🚀 Utilisez la pipeline complète avec vos données\")\n",
    "        print(\"2. 📊 Ajustez les hyperparamètres selon la taille de vos données\")\n",
    "        print(\"3. 🔄 Itérez sur différentes stratégies de masquage\")\n",
    "        print(\"4. 📈 Évaluez les performances sur un ensemble de test\")\n",
    "    else:\n",
    "        print(\"Pour améliorer vos données:\")\n",
    "        print(\"1. 📁 Ajoutez plus de fichiers Excel au format JSON\")\n",
    "        print(\"2. 🔧 Vérifiez la structure de vos fichiers JSON\")\n",
    "        print(\"3. 📊 Assurez-vous d'avoir des formules et des valeurs variées\")\n",
    "        print(\"4. 🧹 Nettoyez les fichiers corrompus\")\n",
    "    \n",
    "    # Résumé final\n",
    "    result = {\n",
    "        'success': True,\n",
    "        'analysis': analysis_summary,\n",
    "        'feasibility_score': feasibility_score,\n",
    "        'recommendations': recommendations,\n",
    "        'sample_predictions': sample_predictions,\n",
    "        'cell_types': cell_types,\n",
    "        'next_steps': 'full_training' if feasibility_score >= 40 else 'improve_data'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🎉 ANALYSE TERMINÉE!\")\n",
    "    print(f\"📋 Résultat stocké dans la variable 'result'\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_data_report_notebook(result, output_file=\"data_report_notebook.html\"):\n",
    "    \"\"\"Crée un rapport HTML depuis les résultats d'analyse\"\"\"\n",
    "    \n",
    "    if not result.get('success'):\n",
    "        return None\n",
    "    \n",
    "    analysis = result['analysis']\n",
    "    feasibility = result['feasibility_score']\n",
    "    recommendations = result['recommendations']\n",
    "    \n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Rapport d'Analyse Excel - Notebook</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}\n",
    "            .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                       color: white; padding: 30px; border-radius: 10px; text-align: center; }}\n",
    "            .section {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; \n",
    "                       border-radius: 8px; background: #f9f9f9; }}\n",
    "            .metric {{ display: inline-block; margin: 10px; padding: 15px; \n",
    "                      background: white; border-radius: 8px; border-left: 4px solid #3498db; }}\n",
    "            .score {{ font-size: 2em; font-weight: bold; color: #2c3e50; }}\n",
    "            .good {{ border-left-color: #27ae60; }}\n",
    "            .warning {{ border-left-color: #f39c12; }}\n",
    "            .error {{ border-left-color: #e74c3c; }}\n",
    "            ul {{ list-style-type: none; padding: 0; }}\n",
    "            li {{ margin: 10px 0; padding: 10px; background: white; border-radius: 5px; }}\n",
    "            .emoji {{ font-size: 1.2em; margin-right: 10px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h1>📊 Analyse de Faisabilité Excel Transformer</h1>\n",
    "            <p>Rapport généré le {datetime.now().strftime('%d/%m/%Y à %H:%M')}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>📈 Résumé Exécutif</h2>\n",
    "            <div class=\"metric good\">\n",
    "                <strong>Fichiers analysés</strong><br>\n",
    "                <span class=\"score\">{analysis['total_files']}</span>\n",
    "            </div>\n",
    "            <div class=\"metric good\">\n",
    "                <strong>Fichiers valides</strong><br>\n",
    "                <span class=\"score\">{analysis['valid_files']}</span>\n",
    "            </div>\n",
    "            <div class=\"metric good\">\n",
    "                <strong>Total cellules</strong><br>\n",
    "                <span class=\"score\">{analysis['total_cells']:,}</span>\n",
    "            </div>\n",
    "            <div class=\"metric {'good' if feasibility >= 70 else 'warning' if feasibility >= 40 else 'error'}\">\n",
    "                <strong>Score de faisabilité</strong><br>\n",
    "                <span class=\"score\">{feasibility}/100</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>🎯 Évaluation de Faisabilité</h2>\n",
    "    \"\"\"\n",
    "    \n",
    "    if feasibility >= 70:\n",
    "        html_content += '<div style=\"background: #d4edda; padding: 15px; border-radius: 5px; border-left: 4px solid #28a745;\">'\n",
    "        html_content += '<h3 style=\"color: #155724; margin: 0;\">🟢 FAISABILITÉ ÉLEVÉE</h3>'\n",
    "        html_content += '<p style=\"margin: 10px 0 0 0;\">Vos données sont excellentes pour l\\'entraînement du transformer Excel!</p>'\n",
    "        html_content += '</div>'\n",
    "    elif feasibility >= 40:\n",
    "        html_content += '<div style=\"background: #fff3cd; padding: 15px; border-radius: 5px; border-left: 4px solid #ffc107;\">'\n",
    "        html_content += '<h3 style=\"color: #856404; margin: 0;\">🟡 FAISABILITÉ MODÉRÉE</h3>'\n",
    "        html_content += '<p style=\"margin: 10px 0 0 0;\">L\\'entraînement est possible mais avec des limitations.</p>'\n",
    "        html_content += '</div>'\n",
    "    else:\n",
    "        html_content += '<div style=\"background: #f8d7da; padding: 15px; border-radius: 5px; border-left: 4px solid #dc3545;\">'\n",
    "        html_content += '<h3 style=\"color: #721c24; margin: 0;\">🔴 FAISABILITÉ FAIBLE</h3>'\n",
    "        html_content += '<p style=\"margin: 10px 0 0 0;\">Améliorez vos données avant de lancer l\\'entraînement.</p>'\n",
    "        html_content += '</div>'\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>💡 Recommandations</h2>\n",
    "            <ul>\n",
    "    \"\"\"\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        html_content += f'<li><span class=\"emoji\">{rec[:2]}</span>{rec[2:]}</li>'\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>🚀 Prochaines Étapes</h2>\n",
    "    \"\"\"\n",
    "    \n",
    "    if result['next_steps'] == 'full_training':\n",
    "        html_content += \"\"\"\n",
    "            <ol>\n",
    "                <li>✅ Lancez la pipeline complète d'entraînement</li>\n",
    "                <li>📊 Surveillez les métriques d'accuracy pendant l'entraînement</li>\n",
    "                <li>🔄 Expérimentez avec différentes stratégies de masquage</li>\n",
    "                <li>📈 Évaluez les performances sur un ensemble de validation</li>\n",
    "            </ol>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        html_content += \"\"\"\n",
    "            <ol>\n",
    "                <li>📁 Collectez plus de fichiers Excel au format JSON</li>\n",
    "                <li>🔧 Vérifiez et corrigez la structure de vos données</li>\n",
    "                <li>📊 Assurez-vous d'avoir une variété de types de cellules</li>\n",
    "                <li>🧹 Nettoyez les fichiers avec des erreurs</li>\n",
    "            </ol>\n",
    "        \"\"\"\n",
    "    \n",
    "    html_content += f\"\"\"\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"section\">\n",
    "            <h2>📋 Détails Techniques</h2>\n",
    "            <p><strong>Fichiers avec erreurs:</strong> {len(analysis['errors'])}</p>\n",
    "            <p><strong>Taux de réussite:</strong> {(analysis['valid_files']/analysis['total_files']*100):.1f}%</p>\n",
    "            <p><strong>Cellules par fichier (moyenne):</strong> {(analysis['total_cells']/analysis['valid_files']):.0f}</p>\n",
    "        </div>\n",
    "        \n",
    "        <footer style=\"text-align: center; margin-top: 40px; color: #666;\">\n",
    "            <p>Rapport généré par Excel Graph Transformer Pipeline</p>\n",
    "        </footer>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"📄 Rapport HTML sauvegardé: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "# Fonction principale pour notebook\n",
    "def analyze_my_data(data_folder=\"data\", max_files=None, create_report=True):\n",
    "    \"\"\"\n",
    "    Fonction principale à appeler dans le notebook\n",
    "    \n",
    "    Usage:\n",
    "        result = analyze_my_data(\"data\", max_files=5)\n",
    "    \"\"\"\n",
    "    result = run_pipeline_notebook(data_folder, max_files, quick_mode=True)\n",
    "    \n",
    "    if result.get('success') and create_report:\n",
    "        create_data_report_notebook(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Instructions d'utilisation\n",
    "print(\"\"\"\n",
    "🎯 INSTRUCTIONS D'UTILISATION DANS LE NOTEBOOK:\n",
    "\n",
    "1. Placez vos fichiers *.json dans le dossier 'data/'\n",
    "\n",
    "2. Exécutez cette cellule pour charger les fonctions\n",
    "\n",
    "3. Lancez l'analyse avec:\n",
    "   result = analyze_my_data(\"data\")\n",
    "\n",
    "4. Pour limiter à quelques fichiers:\n",
    "   result = analyze_my_data(\"data\", max_files=5)\n",
    "\n",
    "5. Les résultats seront affichés et un rapport HTML sera créé.\n",
    "\n",
    "📊 Cette version analyse vos données et évalue la faisabilité\n",
    "   d'un entraînement complet sans lancer le transformer lourd.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fd4b94d8-163c-4709-a5b3-e3109507a17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 PIPELINE EXCEL TRANSFORMER - VERSION NOTEBOOK\n",
      "============================================================\n",
      "\n",
      "1️⃣ VÉRIFICATION DE L'ENVIRONNEMENT\n",
      "✅ PyTorch: 2.7.1+cpu\n",
      "✅ NumPy: 2.3.1\n",
      "✅ Pandas: 2.3.0\n",
      "\n",
      "2️⃣ RECHERCHE DES FICHIERS JSON DANS 'embedding/data'\n",
      "📁 Trouvé 22 fichiers JSON\n",
      "\n",
      "3️⃣ ANALYSE DES FICHIERS\n",
      "  ✅ 001c766dd64f5fdad3768694b0d382b6d988d94ba248c21fb0e7930b27dacf28.json: 3372 cellules\n",
      "  ✅ 0017285f44fbc2ca3e36d830e95a0cb049eb474cf1e17ff400f8074b6c2cea1f.json: 22176 cellules\n",
      "  ✅ 002640c96a51ecb5b9d6ce18816fd01edc27c079c7667156dfa67fc706a703d7.json: 5195 cellules\n",
      "  ✅ 0024d5eb932a3ac70e343098d6a0379394997851df9d83e0850669e23320075e.json: 601 cellules\n",
      "  ✅ 00350d054fe0d85c109eb3607d8aa1dfbef4be0ecbe8e670b7cc8f2f8b236972.json: 657 cellules\n",
      "  ✅ 00013ad39833fc129f5b79553f6d6389dad9b192130ebd754f64fc47c01cef82.json: 33 cellules\n",
      "  ✅ 0014b1c74f12b7f42dc7c267c6b56e3c90dac181ab147e71441d5f6b78c99ac8.json: 392 cellules\n",
      "  ✅ 000b7dd83566a50f96006b5948980639f3382f65b3a34d6bf757ddd3d01bf003.json: 72528 cellules\n",
      "  ✅ 0022c921e3505c0980a6f3b19c9334cc889d4715bf58783beccf68c5feb7b161.json: 2032 cellules\n",
      "  ✅ 0003d90ad249104a7ba0fb6bab08e8b9e70746e0cd2c3b30a006935b55f2a07b.json: 1556 cellules\n",
      "  ✅ 003593d1064dcd41f60b311efc7d7d0fca9c433d5f244481a3e4db279a5083ef.json: 43969 cellules\n",
      "  ✅ 001c766dd64f5fdad3768694b0d382b6d988d94ba248c21fb0e7930b27dacf28.json: 3372 cellules\n",
      "  ✅ 0017285f44fbc2ca3e36d830e95a0cb049eb474cf1e17ff400f8074b6c2cea1f.json: 22176 cellules\n",
      "  ✅ 002640c96a51ecb5b9d6ce18816fd01edc27c079c7667156dfa67fc706a703d7.json: 5195 cellules\n",
      "  ✅ 0024d5eb932a3ac70e343098d6a0379394997851df9d83e0850669e23320075e.json: 601 cellules\n",
      "  ✅ 00350d054fe0d85c109eb3607d8aa1dfbef4be0ecbe8e670b7cc8f2f8b236972.json: 657 cellules\n",
      "  ✅ 00013ad39833fc129f5b79553f6d6389dad9b192130ebd754f64fc47c01cef82.json: 33 cellules\n",
      "  ✅ 0014b1c74f12b7f42dc7c267c6b56e3c90dac181ab147e71441d5f6b78c99ac8.json: 392 cellules\n",
      "  ✅ 000b7dd83566a50f96006b5948980639f3382f65b3a34d6bf757ddd3d01bf003.json: 72528 cellules\n",
      "  ✅ 0022c921e3505c0980a6f3b19c9334cc889d4715bf58783beccf68c5feb7b161.json: 2032 cellules\n",
      "  ✅ 0003d90ad249104a7ba0fb6bab08e8b9e70746e0cd2c3b30a006935b55f2a07b.json: 1556 cellules\n",
      "  ✅ 003593d1064dcd41f60b311efc7d7d0fca9c433d5f244481a3e4db279a5083ef.json: 43969 cellules\n",
      "\n",
      "📊 RÉSUMÉ DE L'ANALYSE:\n",
      "   Fichiers analysés: 22\n",
      "   Fichiers valides: 22\n",
      "   Total cellules: 305022\n",
      "   Erreurs: 0\n",
      "\n",
      "4️⃣ TEST DE BASE SUR LES DONNÉES\n",
      "✅ Test réussi:\n",
      "   Cellules extraites: 30743\n",
      "   Feuilles trouvées: 24\n",
      "   Formules trouvées: 0\n",
      "\n",
      "5️⃣ SIMULATION D'ENTRAÎNEMENT\n",
      "📊 Types de cellules détectés:\n",
      "   empty: 23748 (77.2%)\n",
      "   text: 3606 (11.7%)\n",
      "   number: 3389 (11.0%)\n",
      "   formula: 0 (0.0%)\n",
      "\n",
      "6️⃣ SIMULATION DE PRÉDICTIONS\n",
      "🔮 Exemples de prédictions simulées:\n",
      "\n",
      "   Exemple 1 - Position (1,1) (Text):\n",
      "      Vraie valeur: 'Перечень предприятий, предоставляющих форму 2-услуги (квартальная) за 4 квартал 2024 года.                                                                                                                   Срок  предоставления до 27 января  2025 года. '\n",
      "      Top 3 prédictions:\n",
      "         🎯 Перечень предприятий (60.8%)\n",
      "         2. Перечень предприятий (25.5%)\n",
      "         3. Data                 (10.8%)\n",
      "\n",
      "   Exemple 2 - Position (3,1) (Text):\n",
      "      Vraie valeur: 'КАТО'\n",
      "      Top 3 prédictions:\n",
      "         🎯 КАТО                 (52.2%)\n",
      "         2. Text                 (31.7%)\n",
      "         3. Data                 (9.7%)\n",
      "\n",
      "   Exemple 3 - Position (3,2) (Text):\n",
      "      Vraie valeur: 'БИН/ИИН'\n",
      "      Top 3 prédictions:\n",
      "         🎯 БИН/ИИН              (46.7%)\n",
      "         2. Data                 (31.3%)\n",
      "         3. БИН/ИИН_copy         (12.1%)\n",
      "\n",
      "   Exemple 4 - Position (0,0) (Text):\n",
      "      Vraie valeur: 'Item No. (BOLD is a module)'\n",
      "      Top 3 prédictions:\n",
      "         🎯 Item No. (BOLD is a  (33.2%)\n",
      "         2. Text                 (26.9%)\n",
      "         3. Data                 (20.2%)\n",
      "\n",
      "   Exemple 5 - Position (0,1) (Empty):\n",
      "      Vraie valeur: ''\n",
      "      Top 3 prédictions:\n",
      "         1. Data                 (26.6%)\n",
      "         2. N/A                  (25.2%)\n",
      "         3. 0                    (21.8%)\n",
      "\n",
      "7️⃣ RAPPORT DE FAISABILITÉ\n",
      "📊 Score de faisabilité: 80/100\n",
      "🟢 FAISABILITÉ ÉLEVÉE - Entraînement recommandé\n",
      "\n",
      "💡 RECOMMANDATIONS:\n",
      "   ✅ Nombre suffisant de fichiers pour l'entraînement\n",
      "   ✅ Nombre suffisant de cellules pour l'entraînement\n",
      "   ⚠️ Aucune formule - apprentissage limité aux valeurs\n",
      "   ✅ Aucune erreur de format\n",
      "\n",
      "8️⃣ PROCHAINES ÉTAPES\n",
      "Pour lancer l'entraînement complet:\n",
      "1. 🚀 Utilisez la pipeline complète avec vos données\n",
      "2. 📊 Ajustez les hyperparamètres selon la taille de vos données\n",
      "3. 🔄 Itérez sur différentes stratégies de masquage\n",
      "4. 📈 Évaluez les performances sur un ensemble de test\n",
      "\n",
      "🎉 ANALYSE TERMINÉE!\n",
      "📋 Résultat stocké dans la variable 'result'\n",
      "📄 Rapport HTML sauvegardé: data_report_notebook.html\n"
     ]
    }
   ],
   "source": [
    "# Analyser tous vos fichiers JSON\n",
    "result = analyze_my_data(\"embedding/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1141516f-0963-406a-b360-352e753ae389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 ENTRAÎNEMENT OPTIMISÉ SUR VOS DONNÉES\n",
      "============================================================\n",
      "\n",
      "1️⃣ CONFIGURATION DU MODÈLE\n",
      "   Embedding dimension: 256\n",
      "   Position max: 2000\n",
      "   Vocabulaire couleurs: 300\n",
      "\n",
      "2️⃣ CRÉATION DU TRANSFORMER BUILDER\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'max_value_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 238\u001b[39m\n\u001b[32m    235\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m💡 Lancez d\u001b[39m\u001b[33m'\u001b[39m\u001b[33mabord l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mentraînement avec run_optimized_training()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# Lancer l'entraînement\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m model, trainer = \u001b[43mrun_optimized_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mrun_optimized_training\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 2. Création du transformer builder\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m2️⃣ CRÉATION DU TRANSFORMER BUILDER\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m transformer_builder = \u001b[43mJSONToGraphTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_cells_per_sheet\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_empty_cells\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     52\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# 3. Modèle avec encodage positionnel corrigé\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m3️⃣ INITIALISATION DU MODÈLE\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mJSONToGraphTransformer.__init__\u001b[39m\u001b[34m(self, embedding_config, max_cells_per_sheet, include_empty_cells, graph_config)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.graph_config = graph_config\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Initialiser les composants\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28mself\u001b[39m.cell_embedder = \u001b[43mExcelCellEmbedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mself\u001b[39m.graph_embedder = ExcelGraphEmbedder(\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mself\u001b[39m.cell_embedder, \n\u001b[32m     44\u001b[39m     edge_embedding_dim=\u001b[32m64\u001b[39m\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Configurer le graph builder\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mExcelCellEmbedder.__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.type_embedding = nn.Embedding(\u001b[32m4\u001b[39m, config.type_embedding_dim)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Contenu (valeur/formule)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28mself\u001b[39m.value_encoder = \u001b[43mValueEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Formatage booléen\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.bool_embedding = nn.Embedding(\u001b[32m2\u001b[39m, \u001b[32m8\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 216\u001b[39m, in \u001b[36mValueEncoder.__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.config = config\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28mself\u001b[39m.max_tokens = \u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_value_tokens\u001b[49m  \u001b[38;5;66;03m# FIXÉ\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.token_dim = config.value_token_dim    \u001b[38;5;66;03m# FIXÉ\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[38;5;28mself\u001b[39m.output_dim = \u001b[38;5;28mself\u001b[39m.max_tokens * \u001b[38;5;28mself\u001b[39m.token_dim  \u001b[38;5;66;03m# 8 * 32 = 256D\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Config' object has no attribute 'max_value_tokens'"
     ]
    }
   ],
   "source": [
    "# Lancer la pipeline complète sur vos données\n",
    "# Cette fonction utilisera vos 22 fichiers pour un vrai entraînement\n",
    "\n",
    "# Configuration optimisée pour vos données\n",
    "class YourDataConfig:\n",
    "    \"\"\"Configuration spécialement adaptée à vos données\"\"\"\n",
    "    embedding_dim = 256\n",
    "    position_embedding_dim = 48\n",
    "    type_embedding_dim = 16\n",
    "    max_position = 2000  # Pour vos gros fichiers\n",
    "    color_vocab_size = 300\n",
    "    align_vocab_size = 5\n",
    "    border_vocab_size = 10\n",
    "    font_vocab_size = 30\n",
    "    max_font_size = 72\n",
    "\n",
    "def run_optimized_training():\n",
    "    \"\"\"Lance l'entraînement optimisé sur vos données avec corrections\"\"\"\n",
    "    \n",
    "    print(\"🚀 ENTRAÎNEMENT OPTIMISÉ SUR VOS DONNÉES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Configuration\n",
    "    print(\"\\n1️⃣ CONFIGURATION DU MODÈLE\")\n",
    "    \n",
    "    # Configuration corrigée (en tant qu'objet, pas classe)\n",
    "    class Config:\n",
    "        def __init__(self):\n",
    "            self.embedding_dim = 256  # Divisible par 4\n",
    "            self.position_embedding_dim = 32\n",
    "            self.type_embedding_dim = 16\n",
    "            self.max_position = 2000\n",
    "            self.color_vocab_size = 300\n",
    "            self.align_vocab_size = 5\n",
    "            self.border_vocab_size = 10\n",
    "            self.font_vocab_size = 30\n",
    "            self.max_font_size = 72\n",
    "    \n",
    "    config = Config()\n",
    "    \n",
    "    print(f\"   Embedding dimension: {config.embedding_dim}\")\n",
    "    print(f\"   Position max: {config.max_position}\")\n",
    "    print(f\"   Vocabulaire couleurs: {config.color_vocab_size}\")\n",
    "    \n",
    "    # 2. Création du transformer builder\n",
    "    print(\"\\n2️⃣ CRÉATION DU TRANSFORMER BUILDER\")\n",
    "    \n",
    "    transformer_builder = JSONToGraphTransformer(\n",
    "        embedding_config=config,\n",
    "        max_cells_per_sheet=300,\n",
    "        include_empty_cells=False\n",
    "    )\n",
    "    \n",
    "    # 3. Modèle avec encodage positionnel corrigé\n",
    "    print(\"\\n3️⃣ INITIALISATION DU MODÈLE\")\n",
    "    \n",
    "    # Utiliser le modèle existant mais corriger le problème d'encodage positionnel\n",
    "    excel_transformer = ExcelGraphTransformer(\n",
    "        config, \n",
    "        num_layers=4,  # Réduit pour commencer\n",
    "        n_heads=8, \n",
    "        d_ff=768\n",
    "    )\n",
    "    \n",
    "    # CORRECTION : Remplacer l'encodage positionnel problématique\n",
    "    excel_transformer.pos_encoding_2d = PositionalEncoding2D(config.embedding_dim)\n",
    "    \n",
    "    predictor = MaskedCellPredictor(excel_transformer, num_candidates=10)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in predictor.parameters())\n",
    "    print(f\"✅ Modèle créé: {total_params:,} paramètres\")\n",
    "    \n",
    "    # 4. Préparation des données\n",
    "    print(\"\\n4️⃣ PRÉPARATION DES DONNÉES\")\n",
    "    \n",
    "    # Charger vos fichiers (adapter le chemin si nécessaire)\n",
    "    try:\n",
    "        json_files, file_paths = load_json_files(\"embedding/data\")  # Votre dossier\n",
    "    except:\n",
    "        try:\n",
    "            json_files, file_paths = load_json_files(\"data\")  # Dossier alternatif\n",
    "        except:\n",
    "            print(\"❌ Impossible de trouver le dossier de données\")\n",
    "            return None, None\n",
    "    \n",
    "    print(f\"   Fichiers chargés: {len(json_files)}\")\n",
    "    \n",
    "    # Limiter pour le test initial\n",
    "    if len(json_files) > 5:  # Encore plus conservateur\n",
    "        json_files = json_files[:5]\n",
    "        print(f\"   Limitation à {len(json_files)} fichiers pour le test\")\n",
    "    \n",
    "    # Créer le dataset\n",
    "    try:\n",
    "        dataset = ExcelMaskedDataset(\n",
    "            json_files,\n",
    "            transformer_builder,\n",
    "            mask_ratio=0.1,  # Masquer seulement 10%\n",
    "            num_candidates=10\n",
    "        )\n",
    "        print(f\"✅ Dataset créé: {len(dataset)} échantillons\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur dataset: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"❌ Dataset vide après filtrage!\")\n",
    "        return None, None\n",
    "    \n",
    "    # 5. Entraînement\n",
    "    print(\"\\n5️⃣ LANCEMENT DE L'ENTRAÎNEMENT\")\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    trainer = MaskedPredictionTrainer(predictor)\n",
    "    \n",
    "    # Entraînement sur 3 époques d'abord pour tester\n",
    "    num_epochs = 3\n",
    "    print(f\"   Entraînement sur {num_epochs} époques de test...\")\n",
    "    \n",
    "    training_results = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\n📚 Époque {epoch + 1}/{num_epochs}:\")\n",
    "            \n",
    "            epoch_metrics = trainer.train_epoch(dataloader, epoch)\n",
    "            training_results.append(epoch_metrics)\n",
    "            \n",
    "            # Affichage des métriques\n",
    "            print(f\"   Loss: {epoch_metrics['loss']:.4f}\")\n",
    "            print(f\"   Accuracy: {epoch_metrics['accuracy']:.1%}\")\n",
    "            print(f\"   Top-3: {epoch_metrics['top3_accuracy']:.1%}\")\n",
    "            print(f\"   Top-5: {epoch_metrics['top5_accuracy']:.1%}\")\n",
    "            print(f\"   Prédictions: {epoch_metrics['total_predictions']}\")\n",
    "            \n",
    "            if epoch_metrics['accuracy'] > best_accuracy:\n",
    "                best_accuracy = epoch_metrics['accuracy']\n",
    "                print(f\"   ⭐ Nouveau record: {best_accuracy:.1%}\")\n",
    "                \n",
    "                # Sauvegarder le meilleur modèle\n",
    "                torch.save(predictor.state_dict(), \"best_model_your_data.pt\")\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\n⏱️ Entraînement terminé en {training_time:.1f}s\")\n",
    "        print(f\"🏆 Meilleure accuracy: {best_accuracy:.1%}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur pendant l'entraînement: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "    \n",
    "    # 6. Test rapide\n",
    "    print(\"\\n6️⃣ TEST RAPIDE DU MODÈLE ENTRAÎNÉ\")\n",
    "    \n",
    "    if len(dataset) > 0:\n",
    "        try:\n",
    "            # Prendre un échantillon\n",
    "            sample = dataset[0]\n",
    "            if sample is not None:\n",
    "                graph = sample['graph']\n",
    "                mask_indices = sample['mask_indices']\n",
    "                candidates = sample['candidates']\n",
    "                \n",
    "                # Prédiction\n",
    "                predictions = predictor.predict_top_candidates(graph, mask_indices, candidates)\n",
    "                \n",
    "                print(\"🔮 Exemple de prédiction après entraînement:\")\n",
    "                for i, pred in enumerate(predictions[:2]):  # 2 premiers\n",
    "                    print(f\"\\n   Cellule {pred['cell_index']}:\")\n",
    "                    for rank, cand in enumerate(pred['candidates_ranked'][:3]):\n",
    "                        print(f\"     {rank+1}. {cand['value'][:30]:30s} ({cand['probability']:.1%})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erreur test: {e}\")\n",
    "    \n",
    "    # 7. Résumé final\n",
    "    print(f\"\\n7️⃣ RÉSUMÉ FINAL\")\n",
    "    print(f\"   Fichiers traités: {len(json_files)}\")\n",
    "    print(f\"   Échantillons d'entraînement: {len(dataset)}\")\n",
    "    print(f\"   Époques complétées: {len(training_results)}\")\n",
    "    print(f\"   Meilleure accuracy: {best_accuracy:.1%}\")\n",
    "    print(f\"   Modèle sauvegardé: best_model_your_data.pt\")\n",
    "    \n",
    "    return predictor, training_results\n",
    "\n",
    "def quick_test_trained_model():\n",
    "    \"\"\"Test rapide du modèle entraîné\"\"\"\n",
    "    \n",
    "    print(\"\\n🧪 TEST DU MODÈLE ENTRAÎNÉ\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Charger le modèle sauvegardé\n",
    "        config = YourDataConfig()\n",
    "        \n",
    "        # Recréer l'architecture\n",
    "        excel_transformer = ExcelGraphTransformer(config, num_layers=4, n_heads=8)\n",
    "        predictor = MaskedCellPredictor(excel_transformer, num_candidates=10)\n",
    "        \n",
    "        # Charger les poids\n",
    "        predictor.load_state_dict(torch.load(\"best_model_your_data.pt\"))\n",
    "        predictor.eval()\n",
    "        \n",
    "        print(\"✅ Modèle chargé avec succès\")\n",
    "        \n",
    "        # Test sur un fichier de vos données\n",
    "        json_files, file_paths = load_json_files(\"data\")\n",
    "        if json_files:\n",
    "            test_file = json_files[0]\n",
    "            filename = os.path.basename(file_paths[0])\n",
    "            \n",
    "            print(f\"🔍 Test sur: {filename}\")\n",
    "            \n",
    "            # Créer l'évaluateur\n",
    "            transformer_builder = JSONToGraphTransformer(embedding_config=config)\n",
    "            evaluator = ExcelMaskedEvaluator(predictor, transformer_builder)\n",
    "            \n",
    "            # Test interactif\n",
    "            evaluator.interactive_test(test_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur: {e}\")\n",
    "        print(\"💡 Lancez d'abord l'entraînement avec run_optimized_training()\")\n",
    "\n",
    "# Lancer l'entraînement\n",
    "model, trainer = run_optimized_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c582ab24-cef2-463b-8240-2ebe948b3101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 LANCEMENT DU TEST COMPLET\n",
      "\n",
      "🔍 TEST AVEC VOS DONNÉES RÉELLES\n",
      "==================================================\n",
      "🚀 ENTRAÎNEMENT CORRIGÉ - Version Complète\n",
      "============================================================\n",
      "\n",
      "1️⃣ CONFIGURATION\n",
      "✅ Configuration créée: embedding_dim=256\n",
      "\n",
      "2️⃣ CONSTRUCTION ET TEST DU MODÈLE\n",
      "   Dimensions avant projection: 176\n",
      "✅ Modèle créé:\n",
      "   Paramètres totaux: 1,969,482\n",
      "\n",
      "3️⃣ TEST AVEC DES DONNÉES FACTICES\n",
      "✅ Embeddings générés: torch.Size([4, 256])\n",
      "✅ Transformer output: torch.Size([1, 4, 256])\n",
      "✅ Prédiction logits: torch.Size([2, 10])\n",
      "✅ Prédictions formatées: 2 cellules\n",
      "\n",
      "   📍 Cellule 0 (vraie valeur: 'Hello'):\n",
      "     1. Hey        (16.4%)\n",
      "     2. Bonjour    (13.9%)\n",
      "     3. Text       (11.0%)\n",
      "\n",
      "   📍 Cellule 2 (vraie valeur: '42'):\n",
      "     1. 33         (13.6%)\n",
      "     2. 1          (13.5%)\n",
      "     3. 999        (11.2%)\n",
      "\n",
      "🎉 SUCCÈS! Le modèle fonctionne correctement.\n",
      "📋 Toutes les dimensions sont compatibles.\n",
      "📁 Trouvé 11 fichiers dans embedding/data\n",
      "📄 Test avec: 001c766dd64f5fdad3768694b0d382b6d988d94ba248c21fb0e7930b27dacf28.json\n",
      "📊 Cellules extraites: 3372\n",
      "✅ Embedding de vos données: torch.Size([5, 256])\n",
      "✅ Prédiction sur vos données réussie!\n",
      "   Cellule testée: 'Перечень предприятий, предоставляющих форму 2-услуги (квартальная) за 4 квартал 2024 года.                                                                                                                   Срок  предоставления до 27 января  2025 года. ' (type 1)\n",
      "   Top 3 prédictions:\n",
      "     - candidate_6 (13.3%)\n",
      "     - candidate_9 (11.5%)\n",
      "     - data (11.1%)\n",
      "\n",
      "🎉 SUCCÈS! Votre modèle est compatible avec vos données JSON!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def run_corrected_training():\n",
    "    \"\"\"Version corrigée de l'entraînement sans erreurs de dimensions ou d'imports\"\"\"\n",
    "    \n",
    "    print(\"🚀 ENTRAÎNEMENT CORRIGÉ - Version Complète\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Configuration simple et claire\n",
    "    print(\"\\n1️⃣ CONFIGURATION\")\n",
    "    \n",
    "    class SimpleConfig:\n",
    "        def __init__(self):\n",
    "            # Dimensions principales\n",
    "            self.embedding_dim = 256\n",
    "            self.position_embedding_dim = 32\n",
    "            self.type_embedding_dim = 16\n",
    "            \n",
    "            # Vocabulaires\n",
    "            self.max_position = 1000\n",
    "            self.max_font_size = 72\n",
    "            self.color_vocab_size = 100\n",
    "            self.value_vocab_size = 10000\n",
    "    \n",
    "    config = SimpleConfig()\n",
    "    print(f\"✅ Configuration créée: embedding_dim={config.embedding_dim}\")\n",
    "    \n",
    "    # 2. Cellule de test simple\n",
    "    class TestCell:\n",
    "        def __init__(self, row=0, col=0, value=\"test\", cell_type=1):\n",
    "            self.row = row\n",
    "            self.col = col\n",
    "            self.cell_type = cell_type\n",
    "            self.raw_value = value\n",
    "            self.formula = \"\"\n",
    "            self.style_id = \"\"\n",
    "            # Attributs de style avec valeurs par défaut\n",
    "            self.bold = False\n",
    "            self.italic = False\n",
    "            self.underline = False\n",
    "            self.strike = False\n",
    "            self.font_size = 11.0\n",
    "            self.font_family = \"Calibri\"\n",
    "            self.text_color = \"#000000\"\n",
    "            self.background_color = \"#FFFFFF\"\n",
    "            self.horizontal_align = 0\n",
    "            self.vertical_align = 0\n",
    "            self.text_wrap = False\n",
    "            self.text_rotation = 0\n",
    "            self.border_top = 0\n",
    "            self.border_bottom = 0\n",
    "            self.border_left = 0\n",
    "            self.border_right = 0\n",
    "            self.is_merged = False\n",
    "            self.merge_range = (0, 0, 0, 0)\n",
    "            self.sheet_name = \"Sheet1\"\n",
    "    \n",
    "    # 3. Embedder de cellules simplifié\n",
    "    class SimpleCellEmbedder(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "            \n",
    "            # Embeddings de base\n",
    "            self.row_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "            self.col_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "            self.type_embedding = nn.Embedding(4, config.type_embedding_dim)  # 0=empty, 1=text, 2=number, 3=formula\n",
    "            \n",
    "            # Valeur simplifiée (hash du contenu)\n",
    "            self.value_embedding = nn.Embedding(config.value_vocab_size, 64)\n",
    "            \n",
    "            # Style simplifié\n",
    "            self.style_embedding = nn.Embedding(100, 32)  # 100 styles possibles\n",
    "            \n",
    "            # Calcul des dimensions EXACT\n",
    "            total_dim = (\n",
    "                config.position_embedding_dim +  # row = 32\n",
    "                config.position_embedding_dim +  # col = 32  \n",
    "                config.type_embedding_dim +      # type = 16\n",
    "                64 +                             # value = 64\n",
    "                32                               # style = 32\n",
    "            )  # Total = 176\n",
    "            \n",
    "            print(f\"   Dimensions avant projection: {total_dim}\")\n",
    "            \n",
    "            # Projection vers la dimension finale\n",
    "            self.projection = nn.Linear(total_dim, config.embedding_dim)\n",
    "            self.layer_norm = nn.LayerNorm(config.embedding_dim)\n",
    "        \n",
    "        def forward(self, cells):\n",
    "            if not isinstance(cells, list):\n",
    "                cells = [cells]\n",
    "            \n",
    "            embeddings = []\n",
    "            \n",
    "            for cell in cells:\n",
    "                # Position (clampée pour éviter les erreurs)\n",
    "                row_idx = min(max(cell.row, 0), self.config.max_position - 1)\n",
    "                col_idx = min(max(cell.col, 0), self.config.max_position - 1)\n",
    "                \n",
    "                row_emb = self.row_embedding(torch.tensor(row_idx))\n",
    "                col_emb = self.col_embedding(torch.tensor(col_idx))\n",
    "                \n",
    "                # Type de cellule\n",
    "                type_emb = self.type_embedding(torch.tensor(cell.cell_type))\n",
    "                \n",
    "                # Valeur (hash du contenu)\n",
    "                content = str(cell.raw_value) + str(cell.formula)\n",
    "                value_hash = abs(hash(content)) % self.config.value_vocab_size\n",
    "                value_emb = self.value_embedding(torch.tensor(value_hash))\n",
    "                \n",
    "                # Style (hash du style_id)\n",
    "                style_hash = abs(hash(cell.style_id)) % 100 if cell.style_id else 0\n",
    "                style_emb = self.style_embedding(torch.tensor(style_hash))\n",
    "                \n",
    "                # Concaténer tous les embeddings\n",
    "                cell_embedding = torch.cat([\n",
    "                    row_emb,    # 32 dim\n",
    "                    col_emb,    # 32 dim\n",
    "                    type_emb,   # 16 dim\n",
    "                    value_emb,  # 64 dim\n",
    "                    style_emb   # 32 dim\n",
    "                ], dim=0)       # Total: 176 dim\n",
    "                \n",
    "                embeddings.append(cell_embedding)\n",
    "            \n",
    "            # Stack et projeter\n",
    "            batch_embeddings = torch.stack(embeddings)  # [batch_size, 176]\n",
    "            projected = self.projection(batch_embeddings)  # [batch_size, 256]\n",
    "            normalized = self.layer_norm(projected)\n",
    "            \n",
    "            return normalized.squeeze(0) if len(cells) == 1 else normalized\n",
    "    \n",
    "    # 4. Transformer simple\n",
    "    class SimpleTransformer(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.d_model = config.embedding_dim\n",
    "            self.cell_embedder = SimpleCellEmbedder(config)\n",
    "            \n",
    "            # Couche transformer simple\n",
    "            encoder_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=self.d_model,\n",
    "                nhead=8,\n",
    "                dim_feedforward=512,\n",
    "                dropout=0.1,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "            \n",
    "            # Encodage positionnel simple (paramètre apprenable)\n",
    "            self.pos_encoding = nn.Parameter(torch.randn(500, self.d_model) * 0.1)\n",
    "        \n",
    "        def forward(self, cells):\n",
    "            # Embedder les cellules\n",
    "            embeddings = self.cell_embedder(cells)  # [num_cells, d_model]\n",
    "            \n",
    "            # Ajouter dimension batch si nécessaire\n",
    "            if len(embeddings.shape) == 1:\n",
    "                embeddings = embeddings.unsqueeze(0)  # [1, d_model]\n",
    "            if len(embeddings.shape) == 2:\n",
    "                embeddings = embeddings.unsqueeze(0)  # [1, num_cells, d_model]\n",
    "            \n",
    "            batch_size, seq_len, d_model = embeddings.shape\n",
    "            \n",
    "            # Ajouter encodage positionnel\n",
    "            pos_emb = self.pos_encoding[:seq_len].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            embeddings = embeddings + pos_emb\n",
    "            \n",
    "            # Passer dans le transformer\n",
    "            output = self.transformer(embeddings)\n",
    "            \n",
    "            return output\n",
    "    \n",
    "    # 5. Modèle de prédiction\n",
    "    class SimplePredictor(nn.Module):\n",
    "        def __init__(self, transformer, num_candidates=10):\n",
    "            super().__init__()\n",
    "            self.transformer = transformer\n",
    "            self.num_candidates = num_candidates\n",
    "            \n",
    "            # Tête de classification\n",
    "            self.classification_head = nn.Sequential(\n",
    "                nn.Linear(transformer.d_model, transformer.d_model // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(transformer.d_model // 2, num_candidates)\n",
    "            )\n",
    "        \n",
    "        def forward(self, cells, mask_indices, candidates):\n",
    "            # Forward pass du transformer\n",
    "            transformer_output = self.transformer(cells)  # [1, num_cells, d_model]\n",
    "            \n",
    "            if len(mask_indices) == 0:\n",
    "                return {'logits': torch.empty(0, self.num_candidates)}\n",
    "            \n",
    "            # Extraire les embeddings des cellules masquées\n",
    "            masked_embeddings = transformer_output[0, mask_indices]  # [num_masked, d_model]\n",
    "            \n",
    "            # Classification\n",
    "            logits = self.classification_head(masked_embeddings)  # [num_masked, num_candidates]\n",
    "            \n",
    "            return {\n",
    "                'logits': logits,\n",
    "                'embeddings': masked_embeddings\n",
    "            }\n",
    "        \n",
    "        def predict_candidates(self, cells, mask_indices, candidates):\n",
    "            \"\"\"Version simplifiée de prédiction\"\"\"\n",
    "            with torch.no_grad():\n",
    "                output = self.forward(cells, mask_indices, candidates)\n",
    "                logits = output['logits']\n",
    "                probabilities = torch.softmax(logits, dim=-1)\n",
    "                \n",
    "                predictions = []\n",
    "                for i, (mask_idx, cell_candidates) in enumerate(zip(mask_indices, candidates)):\n",
    "                    probs = probabilities[i].cpu().numpy()\n",
    "                    \n",
    "                    # Ordonner par probabilité\n",
    "                    sorted_indices = torch.argsort(probabilities[i], descending=True)\n",
    "                    \n",
    "                    ranked_candidates = []\n",
    "                    for rank, idx in enumerate(sorted_indices[:5]):  # Top 5\n",
    "                        ranked_candidates.append({\n",
    "                            'value': cell_candidates[idx] if idx < len(cell_candidates) else f\"candidate_{idx}\",\n",
    "                            'probability': float(probabilities[i][idx]),\n",
    "                            'rank': rank + 1\n",
    "                        })\n",
    "                    \n",
    "                    predictions.append({\n",
    "                        'cell_index': mask_idx,\n",
    "                        'candidates_ranked': ranked_candidates\n",
    "                    })\n",
    "                \n",
    "                return predictions\n",
    "    \n",
    "    # 6. TEST DU MODÈLE\n",
    "    print(\"\\n2️⃣ CONSTRUCTION ET TEST DU MODÈLE\")\n",
    "    \n",
    "    try:\n",
    "        # Créer les modèles\n",
    "        transformer = SimpleTransformer(config)\n",
    "        predictor = SimplePredictor(transformer, num_candidates=10)\n",
    "        \n",
    "        print(f\"✅ Modèle créé:\")\n",
    "        total_params = sum(p.numel() for p in predictor.parameters())\n",
    "        print(f\"   Paramètres totaux: {total_params:,}\")\n",
    "        \n",
    "        # 7. TEST AVEC DES CELLULES FACTICES\n",
    "        print(\"\\n3️⃣ TEST AVEC DES DONNÉES FACTICES\")\n",
    "        \n",
    "        # Créer des cellules de test\n",
    "        test_cells = [\n",
    "            TestCell(row=0, col=0, value=\"Hello\", cell_type=1),\n",
    "            TestCell(row=0, col=1, value=\"World\", cell_type=1),\n",
    "            TestCell(row=1, col=0, value=\"42\", cell_type=2),\n",
    "            TestCell(row=1, col=1, value=\"\", cell_type=0)  # cellule vide\n",
    "        ]\n",
    "        \n",
    "        # Test d'embedding\n",
    "        with torch.no_grad():\n",
    "            embeddings = transformer.cell_embedder(test_cells)\n",
    "            print(f\"✅ Embeddings générés: {embeddings.shape}\")\n",
    "            \n",
    "            # Test du transformer\n",
    "            transformer_output = transformer(test_cells)\n",
    "            print(f\"✅ Transformer output: {transformer_output.shape}\")\n",
    "            \n",
    "            # Test de prédiction\n",
    "            mask_indices = [0, 2]  # Masquer les cellules 0 et 2\n",
    "            candidates = [\n",
    "                [\"Hello\", \"Hi\", \"Hey\", \"Bonjour\", \"Text\", \"Data\", \"Value\", \"Item\", \"Word\", \"Cell\"],\n",
    "                [\"42\", \"0\", \"100\", \"1\", \"999\", \"3.14\", \"50\", \"200\", \"75\", \"33\"]\n",
    "            ]\n",
    "            \n",
    "            prediction_output = predictor(test_cells, mask_indices, candidates)\n",
    "            print(f\"✅ Prédiction logits: {prediction_output['logits'].shape}\")\n",
    "            \n",
    "            # Test de prédiction avec candidats\n",
    "            predictions = predictor.predict_candidates(test_cells, mask_indices, candidates)\n",
    "            print(f\"✅ Prédictions formatées: {len(predictions)} cellules\")\n",
    "            \n",
    "            # Afficher les résultats\n",
    "            for i, pred in enumerate(predictions):\n",
    "                cell_idx = pred['cell_index']\n",
    "                test_cell = test_cells[cell_idx]\n",
    "                true_value = test_cell.raw_value\n",
    "                \n",
    "                print(f\"\\n   📍 Cellule {cell_idx} (vraie valeur: '{true_value}'):\")\n",
    "                for rank, candidate in enumerate(pred['candidates_ranked'][:3]):\n",
    "                    marker = \"🎯\" if candidate['value'] == true_value else f\"{rank+1}.\"\n",
    "                    print(f\"     {marker} {candidate['value']:10s} ({candidate['probability']:.1%})\")\n",
    "        \n",
    "        print(f\"\\n🎉 SUCCÈS! Le modèle fonctionne correctement.\")\n",
    "        print(f\"📋 Toutes les dimensions sont compatibles.\")\n",
    "        \n",
    "        return predictor, transformer, config\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de la construction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "# 8. FONCTION POUR TESTER AVEC VOS VRAIES DONNÉES\n",
    "def test_with_real_data():\n",
    "    \"\"\"Test avec vos fichiers JSON réels\"\"\"\n",
    "    print(\"\\n🔍 TEST AVEC VOS DONNÉES RÉELLES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    predictor, transformer, config = run_corrected_training()\n",
    "    \n",
    "    if predictor is None:\n",
    "        print(\"❌ Échec de la création du modèle\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Essayer de charger vos fichiers\n",
    "        data_folders = [\"embedding/data\", \"data\", \"./data\"]\n",
    "        json_files = []\n",
    "        \n",
    "        for folder in data_folders:\n",
    "            if os.path.exists(folder):\n",
    "                pattern = os.path.join(folder, \"*.json\")\n",
    "                found_files = glob.glob(pattern)\n",
    "                if found_files:\n",
    "                    print(f\"📁 Trouvé {len(found_files)} fichiers dans {folder}\")\n",
    "                    \n",
    "                    # Charger le premier fichier\n",
    "                    with open(found_files[0], 'r', encoding='utf-8') as f:\n",
    "                        sample_data = json.load(f)\n",
    "                    \n",
    "                    print(f\"📄 Test avec: {os.path.basename(found_files[0])}\")\n",
    "                    \n",
    "                    # Parser avec votre classe existante\n",
    "                    cells = ExcelParser.parse_excel_json(sample_data)\n",
    "                    print(f\"📊 Cellules extraites: {len(cells)}\")\n",
    "                    \n",
    "                    if cells and len(cells) > 0:\n",
    "                        # Prendre quelques cellules pour test\n",
    "                        test_cells = cells[:5]\n",
    "                        \n",
    "                        # Test d'embedding\n",
    "                        with torch.no_grad():\n",
    "                            embeddings = transformer.cell_embedder(test_cells)\n",
    "                            print(f\"✅ Embedding de vos données: {embeddings.shape}\")\n",
    "                            \n",
    "                            # Test de prédiction simple\n",
    "                            mask_indices = [0] if len(test_cells) > 0 else []\n",
    "                            candidates = [[\"test\", \"data\", \"value\", \"item\", \"text\"]]\n",
    "                            \n",
    "                            if mask_indices:\n",
    "                                predictions = predictor.predict_candidates(test_cells, mask_indices, candidates)\n",
    "                                print(f\"✅ Prédiction sur vos données réussie!\")\n",
    "                                \n",
    "                                # Afficher le résultat\n",
    "                                pred = predictions[0]\n",
    "                                real_cell = test_cells[pred['cell_index']]\n",
    "                                print(f\"   Cellule testée: '{real_cell.raw_value}' (type {real_cell.cell_type})\")\n",
    "                                print(f\"   Top 3 prédictions:\")\n",
    "                                for cand in pred['candidates_ranked'][:3]:\n",
    "                                    print(f\"     - {cand['value']} ({cand['probability']:.1%})\")\n",
    "                    \n",
    "                    print(f\"\\n🎉 SUCCÈS! Votre modèle est compatible avec vos données JSON!\")\n",
    "                    return predictor\n",
    "                    \n",
    "        print(\"❌ Aucun fichier JSON trouvé dans les dossiers standards\")\n",
    "        print(\"💡 Placez vos fichiers *.json dans un dossier 'data/' ou 'embedding/data/'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur avec vos données: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    return predictor\n",
    "\n",
    "# Lancer le test complet\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 LANCEMENT DU TEST COMPLET\")\n",
    "    model = test_with_real_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7a91513-234c-47a6-820a-ffe34c07366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Version corrigée de l'entraînement\n",
      "🚀 ENTRAÎNEMENT CORRIGÉ - Version Debug\n",
      "============================================================\n",
      "\n",
      "1️⃣ CHARGEMENT DES DONNÉES\n",
      "📁 Dossier trouvé: embedding/data (11 fichiers)\n",
      "✅ 11 fichiers chargés\n",
      "\n",
      "2️⃣ CRÉATION DU MODÈLE\n",
      "✅ Modèle créé: 6,920,906 paramètres\n",
      "\n",
      "3️⃣ CRÉATION ET DEBUG DU DATASET\n",
      "📚 Création du dataset avec 8 fichiers...\n",
      "✅ Dataset créé: 8 échantillons valides\n",
      "🔍 DEBUG DATASET\n",
      "==============================\n",
      "\n",
      "Échantillon 0:\n",
      "  Type: <class 'dict'>\n",
      "  - cells: <class 'list'>\n",
      "    Length: 20\n",
      "  - mask_indices: <class 'list'>\n",
      "    Value: [16, 12, 0]\n",
      "  - candidates: <class 'list'>\n",
      "  - labels: <class 'list'>\n",
      "    Value: [3, 3, 0]\n",
      "  - file_id: <class 'int'>\n",
      "\n",
      "Échantillon 1:\n",
      "  Type: <class 'dict'>\n",
      "  - cells: <class 'list'>\n",
      "    Length: 20\n",
      "  - mask_indices: <class 'list'>\n",
      "    Value: [11, 5, 14]\n",
      "  - candidates: <class 'list'>\n",
      "  - labels: <class 'list'>\n",
      "    Value: [0, 0, 0]\n",
      "  - file_id: <class 'int'>\n",
      "\n",
      "🧪 TEST D'UN ÉCHANTILLON\n",
      "✅ Échantillon récupéré: 20 cellules, 3 masquées\n",
      "✅ Forward pass réussi: torch.Size([3, 10])\n",
      "\n",
      "4️⃣ LANCEMENT DE L'ENTRAÎNEMENT CORRIGÉ\n",
      "🎯 Entraînement sur 5 époques\n",
      "📊 8 batches par époque\n",
      "\n",
      "📚 Époque 1/5\n",
      "----------------------------------------\n",
      "    Batch   0: Loss 2.5479, Acc 0.0% [3 prédictions]\n",
      "    Batch   5: Loss 2.0219, Acc 100.0% [3 prédictions]\n",
      "    💾 Nouveau record sauvegardé: 45.8%\n",
      "  📈 Train - Loss: 2.1824, Acc: 45.8%, Batches réussis: 8/8, Time: 2.3s\n",
      "\n",
      "📚 Époque 2/5\n",
      "----------------------------------------\n",
      "    Batch   0: Loss 1.8199, Acc 100.0% [3 prédictions]\n",
      "    Batch   5: Loss 1.3810, Acc 100.0% [3 prédictions]\n",
      "    💾 Nouveau record sauvegardé: 100.0%\n",
      "  📈 Train - Loss: 1.5230, Acc: 100.0%, Batches réussis: 8/8, Time: 1.8s\n",
      "\n",
      "📚 Époque 3/5\n",
      "----------------------------------------\n",
      "    Batch   0: Loss 1.1147, Acc 100.0% [3 prédictions]\n",
      "    Batch   5: Loss 0.7315, Acc 100.0% [3 prédictions]\n",
      "  📈 Train - Loss: 0.9977, Acc: 91.7%, Batches réussis: 8/8, Time: 1.2s\n",
      "\n",
      "📚 Époque 4/5\n",
      "----------------------------------------\n",
      "    Batch   0: Loss 1.2966, Acc 66.7% [3 prédictions]\n",
      "    Batch   5: Loss 1.0329, Acc 66.7% [3 prédictions]\n",
      "  📈 Train - Loss: 0.7261, Acc: 87.5%, Batches réussis: 8/8, Time: 1.2s\n",
      "\n",
      "📚 Époque 5/5\n",
      "----------------------------------------\n",
      "    Batch   0: Loss 1.1611, Acc 66.7% [3 prédictions]\n",
      "    Batch   5: Loss 0.0965, Acc 100.0% [3 prédictions]\n",
      "  📈 Train - Loss: 0.3953, Acc: 91.7%, Batches réussis: 8/8, Time: 1.5s\n",
      "\n",
      "5️⃣ RÉSULTATS\n",
      "🏆 Accuracy finale: 91.7%\n",
      "🏆 Meilleure accuracy: 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ExcelDataset(Dataset):\n",
    "    \"\"\"Dataset corrigé pour l'entraînement avec vos données Excel JSON\"\"\"\n",
    "    \n",
    "    def __init__(self, json_files, max_cells_per_file=50, mask_ratio=0.15, num_candidates=10):\n",
    "        self.max_cells_per_file = max_cells_per_file\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.num_candidates = num_candidates\n",
    "        self.samples = []\n",
    "        \n",
    "        print(f\"📚 Création du dataset avec {len(json_files)} fichiers...\")\n",
    "        \n",
    "        for i, json_data in enumerate(json_files):\n",
    "            try:\n",
    "                # Parser les cellules\n",
    "                cells = ExcelParser.parse_excel_json(json_data)\n",
    "                \n",
    "                # Filtrer et limiter\n",
    "                if len(cells) > self.max_cells_per_file:\n",
    "                    # Prendre les cellules les plus importantes\n",
    "                    cells_with_content = [c for c in cells if c.raw_value or c.formula]\n",
    "                    if len(cells_with_content) >= self.max_cells_per_file:\n",
    "                        cells = cells_with_content[:self.max_cells_per_file]\n",
    "                    else:\n",
    "                        # Compléter avec des cellules quelconques\n",
    "                        remaining = self.max_cells_per_file - len(cells_with_content)\n",
    "                        other_cells = [c for c in cells if c not in cells_with_content]\n",
    "                        cells = cells_with_content + other_cells[:remaining]\n",
    "                \n",
    "                if len(cells) >= 3:  # Minimum 3 cellules\n",
    "                    self.samples.append({\n",
    "                        'cells': cells,\n",
    "                        'file_id': i\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erreur fichier {i}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"✅ Dataset créé: {len(self.samples)} échantillons valides\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        cells = sample['cells']\n",
    "        \n",
    "        # Choisir les cellules à masquer\n",
    "        num_to_mask = max(1, int(len(cells) * self.mask_ratio))\n",
    "        \n",
    "        # Privilégier les cellules avec contenu\n",
    "        cells_with_content = [i for i, c in enumerate(cells) if c.raw_value or c.formula]\n",
    "        if len(cells_with_content) >= num_to_mask:\n",
    "            mask_indices = random.sample(cells_with_content, num_to_mask)\n",
    "        else:\n",
    "            # Compléter avec des cellules aléatoires\n",
    "            remaining = num_to_mask - len(cells_with_content)\n",
    "            other_indices = [i for i in range(len(cells)) if i not in cells_with_content]\n",
    "            if other_indices:\n",
    "                additional = random.sample(other_indices, min(remaining, len(other_indices)))\n",
    "                mask_indices = cells_with_content + additional\n",
    "            else:\n",
    "                mask_indices = cells_with_content if cells_with_content else [0]\n",
    "        \n",
    "        # Générer les candidats et labels\n",
    "        candidates = []\n",
    "        labels = []\n",
    "        \n",
    "        for mask_idx in mask_indices:\n",
    "            cell = cells[mask_idx]\n",
    "            \n",
    "            # Générer candidats basés sur le type de cellule\n",
    "            cell_candidates = self._generate_candidates(cell)\n",
    "            \n",
    "            # Trouver la vraie valeur\n",
    "            true_value = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"\"\n",
    "            \n",
    "            # S'assurer que la vraie valeur est dans les candidats\n",
    "            if true_value and true_value not in cell_candidates:\n",
    "                # Remplacer un candidat aléatoire\n",
    "                replace_idx = random.randint(0, len(cell_candidates) - 1)\n",
    "                cell_candidates[replace_idx] = true_value\n",
    "            \n",
    "            # Label = position de la vraie valeur\n",
    "            try:\n",
    "                label = cell_candidates.index(true_value) if true_value else 0\n",
    "            except ValueError:\n",
    "                label = 0\n",
    "            \n",
    "            candidates.append(cell_candidates)\n",
    "            labels.append(label)\n",
    "        \n",
    "        return {\n",
    "            'cells': cells,\n",
    "            'mask_indices': mask_indices,\n",
    "            'candidates': candidates,\n",
    "            'labels': labels,\n",
    "            'file_id': sample['file_id']\n",
    "        }\n",
    "    \n",
    "    def _generate_candidates(self, cell):\n",
    "        \"\"\"Génère des candidats réalistes selon le type de cellule\"\"\"\n",
    "        if cell.cell_type == 1:  # Texte\n",
    "            original = str(cell.raw_value) if cell.raw_value else \"\"\n",
    "            candidates = [\n",
    "                original,\n",
    "                original.upper() if original else \"TEXT\",\n",
    "                original.lower() if original else \"text\", \n",
    "                original + \"_copy\" if original else \"Data\",\n",
    "                \"Данные\", \"Информация\", \"Значение\", \"Элемент\", \"Запись\", \"Пункт\"\n",
    "            ]\n",
    "        elif cell.cell_type == 2:  # Nombre\n",
    "            try:\n",
    "                original = float(cell.raw_value) if cell.raw_value else 0\n",
    "                candidates = [\n",
    "                    str(original),\n",
    "                    str(original + 1),\n",
    "                    str(original * 2),\n",
    "                    str(int(original)),\n",
    "                    \"0\", \"1\", \"100\", \"1000\", \"0.5\", \"2.0\"\n",
    "                ]\n",
    "            except:\n",
    "                candidates = [\"0\", \"1\", \"10\", \"100\", \"1000\", \"0.5\", \"2.0\", \"50\", \"200\", \"999\"]\n",
    "        elif cell.cell_type == 3:  # Formule\n",
    "            candidates = [\n",
    "                cell.formula if cell.formula else \"=SUM(A1:A10)\",\n",
    "                \"=SUM(A1:A10)\",\n",
    "                \"=AVERAGE(B1:B10)\", \n",
    "                \"=COUNT(C1:C10)\",\n",
    "                \"=MAX(D1:D10)\",\n",
    "                \"=MIN(E1:E10)\",\n",
    "                \"=IF(A1>0,\\\"Да\\\",\\\"Нет\\\")\",\n",
    "                \"=CONCATENATE(A1,B1)\",\n",
    "                \"=VLOOKUP(A1,B:C,2,0)\",\n",
    "                \"=TODAY()\"\n",
    "            ]\n",
    "        else:  # Vide\n",
    "            candidates = [\"\", \"0\", \"1\", \"Данные\", \"Значение\", \"N/A\", \"TBD\", \"...\", \"-\", \"Пусто\"]\n",
    "        \n",
    "        # S'assurer qu'on a exactement num_candidates\n",
    "        while len(candidates) < self.num_candidates:\n",
    "            candidates.append(f\"option_{len(candidates)}\")\n",
    "        \n",
    "        return candidates[:self.num_candidates]\n",
    "\n",
    "class ExcelTrainer:\n",
    "    \"\"\"Entraîneur corrigé pour le modèle Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, model, learning_rate=1e-4, weight_decay=1e-5):\n",
    "        self.model = model\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), \n",
    "            lr=learning_rate, \n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=50, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        self.training_history = []\n",
    "        self.best_accuracy = 0.0\n",
    "    \n",
    "    def train_epoch(self, dataloader, epoch):\n",
    "        \"\"\"Entraîne le modèle sur une époque - VERSION CORRIGÉE\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_predictions = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            try:\n",
    "                # CORRECTION : Gestion correcte des batches\n",
    "                if isinstance(batch, list):\n",
    "                    batch = batch[0]  # Si c'est une liste, prendre le premier élément\n",
    "                \n",
    "                # Extraire les données\n",
    "                cells = batch['cells']\n",
    "                mask_indices = batch['mask_indices'] \n",
    "                candidates = batch['candidates']\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                # VÉRIFICATION : S'assurer que ce sont des listes\n",
    "                if not isinstance(mask_indices, list):\n",
    "                    print(f\"🔍 Debug - mask_indices type: {type(mask_indices)}, value: {mask_indices}\")\n",
    "                    continue\n",
    "                \n",
    "                if not isinstance(labels, list):\n",
    "                    print(f\"🔍 Debug - labels type: {type(labels)}, value: {labels}\")\n",
    "                    continue\n",
    "                \n",
    "                if len(mask_indices) == 0 or len(labels) == 0:\n",
    "                    print(f\"🔍 Debug - Empty mask_indices or labels\")\n",
    "                    continue\n",
    "                \n",
    "                # Convertir labels en tensor\n",
    "                labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "                \n",
    "                # Forward pass\n",
    "                output = self.model(cells, mask_indices, candidates)\n",
    "                logits = output['logits']\n",
    "                \n",
    "                # Vérifier les dimensions\n",
    "                if logits.size(0) != labels_tensor.size(0):\n",
    "                    print(f\"🔍 Debug - Dimension mismatch: logits {logits.shape}, labels {labels_tensor.shape}\")\n",
    "                    continue\n",
    "                \n",
    "                # Loss\n",
    "                loss = F.cross_entropy(logits, labels_tensor)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Métriques\n",
    "                total_loss += loss.item()\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                correct = (predictions == labels_tensor).sum().item()\n",
    "                total_correct += correct\n",
    "                total_predictions += len(labels)\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Log périodique\n",
    "                if batch_idx % 5 == 0:\n",
    "                    acc = correct / len(labels) if len(labels) > 0 else 0\n",
    "                    print(f\"    Batch {batch_idx:3d}: Loss {loss.item():.4f}, Acc {acc:.1%} [{len(labels)} prédictions]\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erreur batch {batch_idx}: {e}\")\n",
    "                # AJOUT : Debug détaillé\n",
    "                try:\n",
    "                    print(f\"   Debug batch type: {type(batch)}\")\n",
    "                    if isinstance(batch, dict):\n",
    "                        for key, value in batch.items():\n",
    "                            print(f\"   - {key}: {type(value)}\")\n",
    "                            if isinstance(value, list) and len(value) > 0:\n",
    "                                print(f\"     First element: {type(value[0])}\")\n",
    "                except:\n",
    "                    pass\n",
    "                continue\n",
    "        \n",
    "        # Scheduler step\n",
    "        self.scheduler.step()\n",
    "        \n",
    "        # Métriques d'époque\n",
    "        epoch_metrics = {\n",
    "            'loss': total_loss / max(batch_count, 1),\n",
    "            'accuracy': total_correct / max(total_predictions, 1),\n",
    "            'total_predictions': total_predictions,\n",
    "            'successful_batches': batch_count,\n",
    "            'epoch_time': time.time() - start_time,\n",
    "            'learning_rate': self.optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "        \n",
    "        self.training_history.append(epoch_metrics)\n",
    "        \n",
    "        # Sauvegarder le meilleur modèle\n",
    "        if epoch_metrics['accuracy'] > self.best_accuracy:\n",
    "            self.best_accuracy = epoch_metrics['accuracy']\n",
    "            torch.save(self.model.state_dict(), f\"best_excel_model_epoch_{epoch}.pt\")\n",
    "            print(f\"    💾 Nouveau record sauvegardé: {self.best_accuracy:.1%}\")\n",
    "        \n",
    "        return epoch_metrics\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Affiche l'historique d'entraînement\"\"\"\n",
    "        if not self.training_history:\n",
    "            return\n",
    "        \n",
    "        epochs = range(len(self.training_history))\n",
    "        losses = [h['loss'] for h in self.training_history]\n",
    "        accuracies = [h['accuracy'] for h in self.training_history]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        ax1.plot(epochs, losses, 'b-', label='Loss')\n",
    "        ax1.set_title('Loss d\\'entraînement')\n",
    "        ax1.set_xlabel('Époque')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        ax2.plot(epochs, accuracies, 'r-', label='Accuracy')\n",
    "        ax2.set_title('Accuracy d\\'entraînement')\n",
    "        ax2.set_xlabel('Époque')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.grid(True)\n",
    "        ax2.set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def collate_fn_fixed(batch):\n",
    "    \"\"\"Fonction de collation corrigée\"\"\"\n",
    "    # Retourner directement l'élément (batch size = 1)\n",
    "    return batch[0] if len(batch) == 1 else batch\n",
    "\n",
    "def debug_dataset(dataset, num_samples=3):\n",
    "    \"\"\"Debug le dataset pour comprendre le format\"\"\"\n",
    "    print(\"🔍 DEBUG DATASET\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        try:\n",
    "            sample = dataset[i]\n",
    "            print(f\"\\nÉchantillon {i}:\")\n",
    "            print(f\"  Type: {type(sample)}\")\n",
    "            \n",
    "            if isinstance(sample, dict):\n",
    "                for key, value in sample.items():\n",
    "                    print(f\"  - {key}: {type(value)}\")\n",
    "                    if key == 'mask_indices':\n",
    "                        print(f\"    Value: {value}\")\n",
    "                    elif key == 'labels':\n",
    "                        print(f\"    Value: {value}\")\n",
    "                    elif key == 'cells':\n",
    "                        print(f\"    Length: {len(value) if hasattr(value, '__len__') else 'N/A'}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Erreur échantillon {i}: {e}\")\n",
    "\n",
    "def run_fixed_training():\n",
    "    \"\"\"Version corrigée de l'entraînement complet\"\"\"\n",
    "    \n",
    "    print(\"🚀 ENTRAÎNEMENT CORRIGÉ - Version Debug\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Charger vos données\n",
    "    print(\"\\n1️⃣ CHARGEMENT DES DONNÉES\")\n",
    "    \n",
    "    data_folders = [\"embedding/data\", \"data\", \"./data\"]\n",
    "    json_files = []\n",
    "    \n",
    "    for folder in data_folders:\n",
    "        if os.path.exists(folder):\n",
    "            pattern = os.path.join(folder, \"*.json\")\n",
    "            found_files = glob.glob(pattern)\n",
    "            if found_files:\n",
    "                print(f\"📁 Dossier trouvé: {folder} ({len(found_files)} fichiers)\")\n",
    "                \n",
    "                for file_path in found_files:\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            json_data = json.load(f)\n",
    "                        json_files.append(json_data)\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Erreur {os.path.basename(file_path)}: {e}\")\n",
    "                break\n",
    "    \n",
    "    if not json_files:\n",
    "        print(\"❌ Aucun fichier JSON trouvé!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ {len(json_files)} fichiers chargés\")\n",
    "    \n",
    "    # 2. Créer le modèle (réutiliser la configuration qui marche)\n",
    "    print(\"\\n2️⃣ CRÉATION DU MODÈLE\")\n",
    "    \n",
    "    class TrainingConfig:\n",
    "        def __init__(self):\n",
    "            self.embedding_dim = 256\n",
    "            self.position_embedding_dim = 32\n",
    "            self.type_embedding_dim = 16\n",
    "            self.max_position = 2000\n",
    "            self.max_font_size = 72\n",
    "            self.color_vocab_size = 300\n",
    "            self.value_vocab_size = 50000\n",
    "    \n",
    "    config = TrainingConfig()\n",
    "    \n",
    "    # Réutiliser les classes qui fonctionnent du test précédent\n",
    "    class SimpleCellEmbedder(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "            \n",
    "            self.row_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "            self.col_embedding = nn.Embedding(config.max_position, config.position_embedding_dim)\n",
    "            self.type_embedding = nn.Embedding(4, config.type_embedding_dim)\n",
    "            self.value_embedding = nn.Embedding(config.value_vocab_size, 64)\n",
    "            self.style_embedding = nn.Embedding(1000, 32)\n",
    "            \n",
    "            total_dim = (config.position_embedding_dim * 2 + config.type_embedding_dim + 64 + 32)\n",
    "            self.projection = nn.Linear(total_dim, config.embedding_dim)\n",
    "            self.layer_norm = nn.LayerNorm(config.embedding_dim)\n",
    "        \n",
    "        def forward(self, cells):\n",
    "            if not isinstance(cells, list):\n",
    "                cells = [cells]\n",
    "            \n",
    "            embeddings = []\n",
    "            for cell in cells:\n",
    "                row_idx = min(max(cell.row, 0), self.config.max_position - 1)\n",
    "                col_idx = min(max(cell.col, 0), self.config.max_position - 1)\n",
    "                \n",
    "                row_emb = self.row_embedding(torch.tensor(row_idx))\n",
    "                col_emb = self.col_embedding(torch.tensor(col_idx))\n",
    "                type_emb = self.type_embedding(torch.tensor(cell.cell_type))\n",
    "                \n",
    "                content = str(cell.raw_value) + str(cell.formula)\n",
    "                value_hash = abs(hash(content)) % self.config.value_vocab_size\n",
    "                value_emb = self.value_embedding(torch.tensor(value_hash))\n",
    "                \n",
    "                style_hash = abs(hash(cell.style_id)) % 1000 if cell.style_id else 0\n",
    "                style_emb = self.style_embedding(torch.tensor(style_hash))\n",
    "                \n",
    "                cell_embedding = torch.cat([row_emb, col_emb, type_emb, value_emb, style_emb], dim=0)\n",
    "                embeddings.append(cell_embedding)\n",
    "            \n",
    "            batch_embeddings = torch.stack(embeddings)\n",
    "            projected = self.projection(batch_embeddings)\n",
    "            return self.layer_norm(projected).squeeze(0) if len(cells) == 1 else self.layer_norm(projected)\n",
    "    \n",
    "    class ExcelTransformer(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.d_model = config.embedding_dim\n",
    "            self.cell_embedder = SimpleCellEmbedder(config)\n",
    "            \n",
    "            encoder_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=self.d_model,\n",
    "                nhead=8,\n",
    "                dim_feedforward=1024,\n",
    "                dropout=0.1,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=4)\n",
    "            self.pos_encoding = nn.Parameter(torch.randn(1000, self.d_model) * 0.1)\n",
    "        \n",
    "        def forward(self, cells):\n",
    "            embeddings = self.cell_embedder(cells)\n",
    "            \n",
    "            if len(embeddings.shape) == 1:\n",
    "                embeddings = embeddings.unsqueeze(0)\n",
    "            if len(embeddings.shape) == 2:\n",
    "                embeddings = embeddings.unsqueeze(0)\n",
    "            \n",
    "            batch_size, seq_len, d_model = embeddings.shape\n",
    "            pos_emb = self.pos_encoding[:seq_len].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            embeddings = embeddings + pos_emb\n",
    "            \n",
    "            return self.transformer(embeddings)\n",
    "    \n",
    "    class ExcelPredictor(nn.Module):\n",
    "        def __init__(self, transformer, num_candidates=10):\n",
    "            super().__init__()\n",
    "            self.transformer = transformer\n",
    "            self.num_candidates = num_candidates\n",
    "            \n",
    "            self.classification_head = nn.Sequential(\n",
    "                nn.Linear(transformer.d_model, transformer.d_model),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(transformer.d_model, transformer.d_model // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(transformer.d_model // 2, num_candidates)\n",
    "            )\n",
    "        \n",
    "        def forward(self, cells, mask_indices, candidates):\n",
    "            transformer_output = self.transformer(cells)\n",
    "            \n",
    "            if len(mask_indices) == 0:\n",
    "                return {'logits': torch.empty(0, self.num_candidates)}\n",
    "            \n",
    "            masked_embeddings = transformer_output[0, mask_indices]\n",
    "            logits = self.classification_head(masked_embeddings)\n",
    "            \n",
    "            return {'logits': logits, 'embeddings': masked_embeddings}\n",
    "    \n",
    "    # Créer le modèle\n",
    "    transformer = ExcelTransformer(config)\n",
    "    model = ExcelPredictor(transformer, num_candidates=10)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"✅ Modèle créé: {total_params:,} paramètres\")\n",
    "    \n",
    "    # 3. Créer et débugger le dataset\n",
    "    print(\"\\n3️⃣ CRÉATION ET DEBUG DU DATASET\")\n",
    "    \n",
    "    # Diviser train/val\n",
    "    train_files = json_files[:max(1, int(0.8 * len(json_files)))]\n",
    "    val_files = json_files[int(0.8 * len(json_files)):] if len(json_files) > 1 else []\n",
    "    \n",
    "    train_dataset = ExcelDataset(train_files, max_cells_per_file=20, mask_ratio=0.15)\n",
    "    \n",
    "    # DEBUG du dataset\n",
    "    debug_dataset(train_dataset, num_samples=2)\n",
    "    \n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"❌ Dataset vide!\")\n",
    "        return None\n",
    "    \n",
    "    # Test d'un échantillon\n",
    "    print(\"\\n🧪 TEST D'UN ÉCHANTILLON\")\n",
    "    try:\n",
    "        sample = train_dataset[0]\n",
    "        print(f\"✅ Échantillon récupéré: {len(sample['cells'])} cellules, {len(sample['mask_indices'])} masquées\")\n",
    "        \n",
    "        # Test du modèle sur cet échantillon\n",
    "        with torch.no_grad():\n",
    "            output = model(sample['cells'], sample['mask_indices'], sample['candidates'])\n",
    "            print(f\"✅ Forward pass réussi: {output['logits'].shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur échantillon: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Créer le DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=1, \n",
    "        shuffle=True, \n",
    "        collate_fn=collate_fn_fixed\n",
    "    )\n",
    "    \n",
    "    # 5. Entraînement\n",
    "    print(\"\\n4️⃣ LANCEMENT DE L'ENTRAÎNEMENT CORRIGÉ\")\n",
    "    \n",
    "    trainer = ExcelTrainer(model, learning_rate=2e-4)\n",
    "    num_epochs = 5  # Commencer avec moins d'époques\n",
    "    \n",
    "    print(f\"🎯 Entraînement sur {num_epochs} époques\")\n",
    "    print(f\"📊 {len(train_loader)} batches par époque\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n📚 Époque {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Entraînement\n",
    "        train_metrics = trainer.train_epoch(train_loader, epoch)\n",
    "        \n",
    "        print(f\"  📈 Train - Loss: {train_metrics['loss']:.4f}, \"\n",
    "              f\"Acc: {train_metrics['accuracy']:.1%}, \"\n",
    "              f\"Batches réussis: {train_metrics['successful_batches']}/{len(train_loader)}, \"\n",
    "              f\"Time: {train_metrics['epoch_time']:.1f}s\")\n",
    "        \n",
    "        # Arrêter si aucun batch ne fonctionne\n",
    "        if train_metrics['successful_batches'] == 0:\n",
    "            print(\"❌ Aucun batch réussi - Arrêt de l'entraînement\")\n",
    "            break\n",
    "    \n",
    "    # 6. Résultats\n",
    "    print(f\"\\n5️⃣ RÉSULTATS\")\n",
    "    if trainer.training_history:\n",
    "        final_acc = trainer.training_history[-1]['accuracy']\n",
    "        print(f\"🏆 Accuracy finale: {final_acc:.1%}\")\n",
    "        print(f\"🏆 Meilleure accuracy: {trainer.best_accuracy:.1%}\")\n",
    "        \n",
    "        # Graphiques si on a des données\n",
    "        trainer.plot_training_history()\n",
    "    else:\n",
    "        print(\"❌ Aucune donnée d'entraînement\")\n",
    "    \n",
    "    return model, trainer\n",
    "\n",
    "# Lancer l'entraînement corrigé\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔧 Version corrigée de l'entraînement\")\n",
    "    model, trainer = run_fixed_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de2ce88b-8fc0-4b14-a3cf-b70bea6da26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 ENTRAÎNEMENT RÉUSSI! PROCHAINES ÉTAPES:\n",
      "==================================================\n",
      "🔍 ÉVALUATION DU MODÈLE ENTRAÎNÉ\n",
      "==================================================\n",
      "\n",
      "1️⃣ TEST SUR NOUVEAUX ÉCHANTILLONS\n",
      "📚 Création du dataset avec 2 fichiers...\n",
      "✅ Dataset créé: 2 échantillons valides\n",
      "\n",
      "📋 Test 1:\n",
      "   Cellules masquées: 3\n",
      "   ✅ Cellule (0,13): 'PB' → 'PB'\n",
      "   ✅ Cellule (0,5): 'Oddíl/stát' → 'Oddíl/stát'\n",
      "   ✅ Cellule (0,2): 'Závodník' → 'Závodník'\n",
      "\n",
      "📋 Test 2:\n",
      "   Cellules masquées: 3\n",
      "   ✅ Cellule (2,0): '（ARWU、THE、QS、U.S.News）' → '（ARWU、THE、QS、U.S.News）'\n",
      "   ✅ Cellule (0,0): '附件4' → '附件4'\n",
      "   ✅ Cellule (5,1): '学校名称' → '学校名称'\n",
      "\n",
      "📊 RÉSULTATS GLOBAUX:\n",
      "   Accuracy globale: 100.0% (6/6)\n",
      "\n",
      "📈 ACCURACY PAR TYPE:\n",
      "   Texte   : 100.0% (6/6)\n",
      "\n",
      "🏆 EXCELLENTE PERFORMANCE (100.0%)!\n",
      "   Votre modèle est prêt pour des tests avancés\n",
      "\n",
      "🎮 Pour tester interactivement:\n",
      "   interactive_prediction_demo(model)\n",
      "\n",
      "🚀 SUGGESTIONS D'AMÉLIORATION\n",
      "========================================\n",
      "1️⃣ DONNÉES\n",
      "   • Ajouter plus de fichiers Excel variés\n",
      "   • Inclure des formules plus complexes\n",
      "   • Augmenter la diversité des types de cellules\n",
      "\n",
      "2️⃣ ARCHITECTURE\n",
      "   • Augmenter à 6-8 couches transformer\n",
      "   • Essayer l'attention cross-sheet\n",
      "   • Ajouter un encodage positionnel 2D sophistiqué\n",
      "\n",
      "3️⃣ ENTRAÎNEMENT\n",
      "   • Passer à 20-50 époques\n",
      "   • Implémenter l'early stopping\n",
      "   • Utiliser data augmentation (rotation, masquage variable)\n",
      "\n",
      "4️⃣ ÉVALUATION\n",
      "   • Créer un dataset de test dédié\n",
      "   • Mesurer performance par type de contenu\n",
      "   • Tester sur des classeurs réels\n",
      "\n",
      "5️⃣ DÉPLOIEMENT\n",
      "   • Créer une API REST\n",
      "   • Interface web pour test interactif\n",
      "   • Plugin Excel/Google Sheets\n",
      "\n",
      "💾 Pour sauvegarder:\n",
      "   save_model_for_production(model, config)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExcelPredictor(\n",
       "  (transformer): ExcelTransformer(\n",
       "    (cell_embedder): SimpleCellEmbedder(\n",
       "      (row_embedding): Embedding(2000, 32)\n",
       "      (col_embedding): Embedding(2000, 32)\n",
       "      (type_embedding): Embedding(4, 16)\n",
       "      (value_embedding): Embedding(50000, 64)\n",
       "      (style_embedding): Embedding(1000, 32)\n",
       "      (projection): Linear(in_features=176, out_features=256, bias=True)\n",
       "      (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 🎯 PROCHAINES ÉTAPES POUR VOTRE MODÈLE EXCEL\n",
    "\n",
    "def evaluate_trained_model(model, json_files):\n",
    "    \"\"\"Évaluation complète du modèle entraîné\"\"\"\n",
    "    \n",
    "    print(\"🔍 ÉVALUATION DU MODÈLE ENTRAÎNÉ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Test sur de nouveaux échantillons\n",
    "    print(\"\\n1️⃣ TEST SUR NOUVEAUX ÉCHANTILLONS\")\n",
    "    \n",
    "    test_files = json_files[-2:]  # Prendre les 2 derniers fichiers comme test\n",
    "    test_dataset = ExcelDataset(test_files, max_cells_per_file=15, mask_ratio=0.2)\n",
    "    \n",
    "    if len(test_dataset) == 0:\n",
    "        print(\"❌ Pas de données de test\")\n",
    "        return\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "    predictions_by_type = {0: {'correct': 0, 'total': 0}, \n",
    "                          1: {'correct': 0, 'total': 0}, \n",
    "                          2: {'correct': 0, 'total': 0}, \n",
    "                          3: {'correct': 0, 'total': 0}}\n",
    "    \n",
    "    # Tester sur plusieurs échantillons\n",
    "    for i in range(min(len(test_dataset), 5)):\n",
    "        sample = test_dataset[i]\n",
    "        cells = sample['cells']\n",
    "        mask_indices = sample['mask_indices']\n",
    "        candidates = sample['candidates']\n",
    "        true_labels = sample['labels']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(cells, mask_indices, candidates)\n",
    "            logits = output['logits']\n",
    "            predicted_labels = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            \n",
    "            print(f\"\\n📋 Test {i+1}:\")\n",
    "            print(f\"   Cellules masquées: {len(mask_indices)}\")\n",
    "            \n",
    "            for j, (mask_idx, pred_label, true_label) in enumerate(zip(mask_indices, predicted_labels, true_labels)):\n",
    "                cell = cells[mask_idx]\n",
    "                true_value = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"\"\n",
    "                predicted_value = candidates[j][pred_label] if pred_label < len(candidates[j]) else \"N/A\"\n",
    "                \n",
    "                is_correct = pred_label == true_label\n",
    "                total_correct += is_correct\n",
    "                total_predictions += 1\n",
    "                \n",
    "                # Stats par type\n",
    "                cell_type = cell.cell_type\n",
    "                predictions_by_type[cell_type]['total'] += 1\n",
    "                if is_correct:\n",
    "                    predictions_by_type[cell_type]['correct'] += 1\n",
    "                \n",
    "                status = \"✅\" if is_correct else \"❌\"\n",
    "                print(f\"   {status} Cellule ({cell.row},{cell.col}): '{true_value}' → '{predicted_value}'\")\n",
    "    \n",
    "    # Résultats globaux\n",
    "    overall_accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
    "    print(f\"\\n📊 RÉSULTATS GLOBAUX:\")\n",
    "    print(f\"   Accuracy globale: {overall_accuracy:.1%} ({total_correct}/{total_predictions})\")\n",
    "    \n",
    "    type_names = {0: \"Vide\", 1: \"Texte\", 2: \"Nombre\", 3: \"Formule\"}\n",
    "    print(f\"\\n📈 ACCURACY PAR TYPE:\")\n",
    "    for cell_type, stats in predictions_by_type.items():\n",
    "        if stats['total'] > 0:\n",
    "            acc = stats['correct'] / stats['total']\n",
    "            print(f\"   {type_names[cell_type]:8s}: {acc:.1%} ({stats['correct']}/{stats['total']})\")\n",
    "    \n",
    "    return overall_accuracy\n",
    "\n",
    "def interactive_prediction_demo(model):\n",
    "    \"\"\"Demo interactif de prédiction\"\"\"\n",
    "    \n",
    "    print(\"\\n🎮 DEMO INTERACTIF\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Charger un fichier pour demo\n",
    "    data_folders = [\"embedding/data\", \"data\", \"./data\"]\n",
    "    for folder in data_folders:\n",
    "        if os.path.exists(folder):\n",
    "            json_files = glob.glob(os.path.join(folder, \"*.json\"))\n",
    "            if json_files:\n",
    "                with open(json_files[0], 'r', encoding='utf-8') as f:\n",
    "                    demo_data = json.load(f)\n",
    "                break\n",
    "    \n",
    "    # Parser et prendre quelques cellules\n",
    "    cells = ExcelParser.parse_excel_json(demo_data)\n",
    "    demo_cells = [c for c in cells if c.raw_value or c.formula][:10]\n",
    "    \n",
    "    if not demo_cells:\n",
    "        print(\"❌ Pas de cellules pour la demo\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📋 Cellules disponibles pour test:\")\n",
    "    for i, cell in enumerate(demo_cells):\n",
    "        content = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"[vide]\"\n",
    "        type_name = [\"Vide\", \"Texte\", \"Nombre\", \"Formule\"][cell.cell_type]\n",
    "        print(f\"   {i:2d}. ({cell.row:2d},{cell.col:2d}) {type_name:8s} | {content[:40]}\")\n",
    "    \n",
    "    # Test interactif\n",
    "    try:\n",
    "        choice = int(input(f\"\\nChoisissez une cellule à prédire (0-{len(demo_cells)-1}): \"))\n",
    "        if 0 <= choice < len(demo_cells):\n",
    "            test_cell = demo_cells[choice]\n",
    "            \n",
    "            # Créer candidats\n",
    "            dataset = ExcelDataset([demo_data], max_cells_per_file=20)\n",
    "            if len(dataset) > 0:\n",
    "                sample = dataset[0]\n",
    "                \n",
    "                # Forcer le masquage de la cellule choisie\n",
    "                mask_indices = [choice] if choice < len(sample['cells']) else [0]\n",
    "                candidates = [dataset._generate_candidates(test_cell)]\n",
    "                \n",
    "                # Prédiction\n",
    "                with torch.no_grad():\n",
    "                    output = model(sample['cells'][:len(demo_cells)], mask_indices, candidates)\n",
    "                    logits = output['logits']\n",
    "                    probabilities = torch.softmax(logits, dim=-1)\n",
    "                    \n",
    "                    print(f\"\\n🔮 PRÉDICTION POUR LA CELLULE:\")\n",
    "                    print(f\"   Position: ({test_cell.row}, {test_cell.col})\")\n",
    "                    print(f\"   Vraie valeur: '{test_cell.raw_value}'\")\n",
    "                    print(f\"   Type: {['Vide', 'Texte', 'Nombre', 'Formule'][test_cell.cell_type]}\")\n",
    "                    print(f\"\\n   Top 5 prédictions:\")\n",
    "                    \n",
    "                    # Trier par probabilité\n",
    "                    sorted_indices = torch.argsort(probabilities[0], descending=True)\n",
    "                    \n",
    "                    for rank, idx in enumerate(sorted_indices[:5]):\n",
    "                        candidate = candidates[0][idx] if idx < len(candidates[0]) else f\"option_{idx}\"\n",
    "                        prob = probabilities[0][idx].item()\n",
    "                        marker = \"🎯\" if candidate == str(test_cell.raw_value) else f\"{rank+1}.\"\n",
    "                        \n",
    "                        # Barre de progression visuelle\n",
    "                        bar_length = int(prob * 20)\n",
    "                        bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
    "                        \n",
    "                        print(f\"     {marker:3s} {candidate[:25]:25s} │{bar}│ {prob:.1%}\")\n",
    "        \n",
    "    except (ValueError, KeyboardInterrupt):\n",
    "        print(\"Demo terminée\")\n",
    "\n",
    "def advanced_training_suggestions():\n",
    "    \"\"\"Suggestions pour améliorer encore le modèle\"\"\"\n",
    "    \n",
    "    print(\"\\n🚀 SUGGESTIONS D'AMÉLIORATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    suggestions = [\n",
    "        \"1️⃣ DONNÉES\",\n",
    "        \"   • Ajouter plus de fichiers Excel variés\",\n",
    "        \"   • Inclure des formules plus complexes\", \n",
    "        \"   • Augmenter la diversité des types de cellules\",\n",
    "        \"\",\n",
    "        \"2️⃣ ARCHITECTURE\",\n",
    "        \"   • Augmenter à 6-8 couches transformer\",\n",
    "        \"   • Essayer l'attention cross-sheet\",\n",
    "        \"   • Ajouter un encodage positionnel 2D sophistiqué\",\n",
    "        \"\",\n",
    "        \"3️⃣ ENTRAÎNEMENT\",\n",
    "        \"   • Passer à 20-50 époques\",\n",
    "        \"   • Implémenter l'early stopping\",\n",
    "        \"   • Utiliser data augmentation (rotation, masquage variable)\",\n",
    "        \"\",\n",
    "        \"4️⃣ ÉVALUATION\",\n",
    "        \"   • Créer un dataset de test dédié\",\n",
    "        \"   • Mesurer performance par type de contenu\",\n",
    "        \"   • Tester sur des classeurs réels\",\n",
    "        \"\",\n",
    "        \"5️⃣ DÉPLOIEMENT\",\n",
    "        \"   • Créer une API REST\",\n",
    "        \"   • Interface web pour test interactif\", \n",
    "        \"   • Plugin Excel/Google Sheets\"\n",
    "    ]\n",
    "    \n",
    "    for suggestion in suggestions:\n",
    "        print(suggestion)\n",
    "\n",
    "def save_model_for_production(model, config):\n",
    "    \"\"\"Sauvegarde le modèle pour utilisation en production\"\"\"\n",
    "    \n",
    "    print(\"\\n💾 SAUVEGARDE POUR PRODUCTION\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Sauvegarder le modèle complet\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': config.__dict__ if hasattr(config, '__dict__') else vars(config),\n",
    "        'model_architecture': {\n",
    "            'embedding_dim': 256,\n",
    "            'num_layers': 4,\n",
    "            'num_heads': 8,\n",
    "            'vocab_size': 50000\n",
    "        }\n",
    "    }, 'excel_transformer_production.pt')\n",
    "    \n",
    "    print(\"✅ Modèle sauvegardé: excel_transformer_production.pt\")\n",
    "    \n",
    "    # Créer un script de chargement\n",
    "    loader_script = '''\n",
    "# Script pour charger le modèle en production\n",
    "import torch\n",
    "\n",
    "def load_excel_model(model_path='excel_transformer_production.pt'):\n",
    "    \"\"\"Charge le modèle Excel entraîné\"\"\"\n",
    "    \n",
    "    # Charger les données\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    config = checkpoint['config']\n",
    "    \n",
    "    # Recréer l'architecture (copier les classes depuis votre notebook)\n",
    "    # ... (inclure les classes ExcelTransformer, ExcelPredictor, etc.)\n",
    "    \n",
    "    # Charger les poids\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "# Utilisation:\n",
    "# model, config = load_excel_model()\n",
    "'''\n",
    "    \n",
    "    with open('load_model.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(loader_script)\n",
    "    \n",
    "    print(\"✅ Script de chargement: load_model.py\")\n",
    "\n",
    "# 🎯 FONCTION PRINCIPALE POUR CONTINUER\n",
    "def continue_development(model, trainer):\n",
    "    \"\"\"Suite du développement après entraînement réussi\"\"\"\n",
    "    \n",
    "    print(\"🎉 ENTRAÎNEMENT RÉUSSI! PROCHAINES ÉTAPES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Évaluation\n",
    "    data_folders = [\"embedding/data\", \"data\", \"./data\"]\n",
    "    json_files = []\n",
    "    for folder in data_folders:\n",
    "        if os.path.exists(folder):\n",
    "            json_files = glob.glob(os.path.join(folder, \"*.json\"))\n",
    "            json_files = [json.load(open(f, 'r', encoding='utf-8')) for f in json_files[:5]]\n",
    "            break\n",
    "    \n",
    "    if json_files:\n",
    "        accuracy = evaluate_trained_model(model, json_files)\n",
    "        \n",
    "        if accuracy > 0.7:\n",
    "            print(f\"\\n🏆 EXCELLENTE PERFORMANCE ({accuracy:.1%})!\")\n",
    "            print(\"   Votre modèle est prêt pour des tests avancés\")\n",
    "        elif accuracy > 0.5:\n",
    "            print(f\"\\n👍 BONNE PERFORMANCE ({accuracy:.1%})\")\n",
    "            print(\"   Continuez l'entraînement pour améliorer\")\n",
    "        else:\n",
    "            print(f\"\\n📈 PERFORMANCE MODÉRÉE ({accuracy:.1%})\")\n",
    "            print(\"   Ajustez les hyperparamètres ou ajoutez plus de données\")\n",
    "    \n",
    "    # 2. Demo interactif\n",
    "    print(f\"\\n🎮 Pour tester interactivement:\")\n",
    "    print(f\"   interactive_prediction_demo(model)\")\n",
    "    \n",
    "    # 3. Suggestions\n",
    "    advanced_training_suggestions()\n",
    "    \n",
    "    # 4. Sauvegarde\n",
    "    print(f\"\\n💾 Pour sauvegarder:\")\n",
    "    print(f\"   save_model_for_production(model, config)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Utilisation après votre entraînement:\n",
    "continue_development(model, trainer)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e9290f3-c705-430d-b6c8-0bdac51331aa",
   "metadata": {},
   "source": [
    "Interface d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da47f6c-a946-435b-85ab-3abf8114e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class ExcelMaskedEvaluator:\n",
    "    \"\"\"Évaluateur pour la tâche de masked prediction avec analyses détaillées\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model: 'MaskedCellPredictor',\n",
    "                 transformer_builder: 'JSONToGraphTransformer'):\n",
    "        self.model = model\n",
    "        self.transformer_builder = transformer_builder\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Stockage des résultats d'évaluation\n",
    "        self.evaluation_results = []\n",
    "        self.aggregated_metrics = defaultdict(list)\n",
    "        \n",
    "    def evaluate_excel_file(self, \n",
    "                           json_data: Dict[str, Any],\n",
    "                           strategies: List[str] = ['random', 'strategic'],\n",
    "                           num_candidates: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Évalue le modèle sur un fichier Excel complet\n",
    "        \n",
    "        Args:\n",
    "            json_data: Données Excel en JSON\n",
    "            strategies: Stratégies de masquage à tester\n",
    "            num_candidates: Nombre de candidats à générer\n",
    "            \n",
    "        Returns:\n",
    "            Résultats détaillés de l'évaluation\n",
    "        \"\"\"\n",
    "        results = {\n",
    "            'file_summary': {},\n",
    "            'strategy_results': {},\n",
    "            'cell_analysis': [],\n",
    "            'error_analysis': []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Extraire et filtrer les cellules\n",
    "            cells = self.transformer_builder._extract_cells_from_json(json_data)\n",
    "            cells = self.transformer_builder._filter_cells(cells, max_total_cells=100)\n",
    "            \n",
    "            if not cells:\n",
    "                return {'error': 'Aucune cellule trouvée'}\n",
    "            \n",
    "            # Créer le graphe\n",
    "            graph = self.transformer_builder.graph_embedder(cells)\n",
    "            \n",
    "            # Résumé du fichier\n",
    "            results['file_summary'] = {\n",
    "                'total_cells': len(cells),\n",
    "                'num_nodes': graph.num_nodes,\n",
    "                'num_edges': graph.num_edges,\n",
    "                'sheets': list(set(cell.sheet_name for cell in cells)),\n",
    "                'cell_types': {\n",
    "                    'empty': sum(1 for c in cells if c.cell_type == 0),\n",
    "                    'text': sum(1 for c in cells if c.cell_type == 1),\n",
    "                    'number': sum(1 for c in cells if c.cell_type == 2),\n",
    "                    'formula': sum(1 for c in cells if c.cell_type == 3)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Tester chaque stratégie de masquage\n",
    "            for strategy in strategies:\n",
    "                strategy_result = self._evaluate_strategy(\n",
    "                    graph, cells, strategy, num_candidates\n",
    "                )\n",
    "                results['strategy_results'][strategy] = strategy_result\n",
    "                \n",
    "                # Ajouter à l'analyse par cellule\n",
    "                for cell_result in strategy_result['cell_predictions']:\n",
    "                    cell_result['strategy'] = strategy\n",
    "                    cell_result['file_id'] = id(json_data)\n",
    "                    results['cell_analysis'].append(cell_result)\n",
    "            \n",
    "            # Analyse des erreurs\n",
    "            results['error_analysis'] = self._analyze_errors(results['cell_analysis'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            results['error'] = str(e)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _evaluate_strategy(self, \n",
    "                          graph: 'ExcelGraph',\n",
    "                          cells: List['FullCellInfo'],\n",
    "                          strategy: str,\n",
    "                          num_candidates: int) -> Dict[str, Any]:\n",
    "        \"\"\"Évalue une stratégie de masquage spécifique\"\"\"\n",
    "        \n",
    "        # Choisir les cellules à masquer selon la stratégie\n",
    "        if strategy == 'random':\n",
    "            mask_indices = ExcelMaskingStrategy.random_masking(cells, mask_ratio=0.2)\n",
    "        elif strategy == 'strategic':\n",
    "            mask_indices = ExcelMaskingStrategy.strategic_masking(cells)\n",
    "        else:\n",
    "            mask_indices = [0]  # Par défaut\n",
    "        \n",
    "        if not mask_indices:\n",
    "            return {'error': 'Aucune cellule à masquer'}\n",
    "        \n",
    "        # Générer les candidats\n",
    "        candidates = []\n",
    "        ground_truth_info = []\n",
    "        \n",
    "        for mask_idx in mask_indices:\n",
    "            cell = cells[mask_idx]\n",
    "            cell_candidates = generate_candidates(cell, num_candidates)\n",
    "            \n",
    "            # Informations sur la vérité terrain\n",
    "            true_value = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"\"\n",
    "            true_position = -1\n",
    "            \n",
    "            # Trouver la position de la vraie valeur dans les candidats\n",
    "            for i, candidate in enumerate(cell_candidates):\n",
    "                if candidate == true_value:\n",
    "                    true_position = i\n",
    "                    break\n",
    "            \n",
    "            # Si pas trouvée, l'insérer à une position aléatoire pour le test\n",
    "            if true_position == -1 and true_value:\n",
    "                true_position = 0\n",
    "                cell_candidates[0] = true_value\n",
    "            \n",
    "            candidates.append(cell_candidates)\n",
    "            ground_truth_info.append({\n",
    "                'cell_index': mask_idx,\n",
    "                'true_value': true_value,\n",
    "                'true_position': true_position,\n",
    "                'cell_type': cell.cell_type,\n",
    "                'position': (cell.row, cell.col),\n",
    "                'sheet': cell.sheet_name\n",
    "            })\n",
    "        \n",
    "        # Prédiction du modèle\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model.predict_top_candidates(graph, mask_indices, candidates)\n",
    "        \n",
    "        # Calculer les métriques\n",
    "        metrics = self._calculate_metrics(predictions, ground_truth_info)\n",
    "        \n",
    "        # Analyser chaque prédiction\n",
    "        cell_predictions = []\n",
    "        for i, (prediction, gt_info) in enumerate(zip(predictions, ground_truth_info)):\n",
    "            cell_pred = self._analyze_cell_prediction(prediction, gt_info, candidates[i])\n",
    "            cell_predictions.append(cell_pred)\n",
    "        \n",
    "        return {\n",
    "            'strategy': strategy,\n",
    "            'num_masked': len(mask_indices),\n",
    "            'metrics': metrics,\n",
    "            'cell_predictions': cell_predictions\n",
    "        }\n",
    "    \n",
    "    def _calculate_metrics(self, \n",
    "                          predictions: List[Dict],\n",
    "                          ground_truth_info: List[Dict]) -> Dict[str, float]:\n",
    "        \"\"\"Calcule les métriques de performance\"\"\"\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy_top1': 0.0,\n",
    "            'accuracy_top3': 0.0,\n",
    "            'accuracy_top5': 0.0,\n",
    "            'mrr': 0.0,  # Mean Reciprocal Rank\n",
    "            'avg_confidence': 0.0,\n",
    "            'by_type': {}\n",
    "        }\n",
    "        \n",
    "        if not predictions:\n",
    "            return metrics\n",
    "        \n",
    "        total = len(predictions)\n",
    "        top1_correct = 0\n",
    "        top3_correct = 0\n",
    "        top5_correct = 0\n",
    "        reciprocal_ranks = []\n",
    "        confidences = []\n",
    "        \n",
    "        # Métriques par type de cellule\n",
    "        type_metrics = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "        \n",
    "        for pred, gt_info in zip(predictions, ground_truth_info):\n",
    "            true_value = gt_info['true_value']\n",
    "            cell_type = gt_info['cell_type']\n",
    "            \n",
    "            # Trouver le rang de la vraie valeur\n",
    "            true_rank = None\n",
    "            for rank, candidate_info in enumerate(pred['candidates_ranked']):\n",
    "                if candidate_info['value'] == true_value:\n",
    "                    true_rank = rank + 1\n",
    "                    break\n",
    "            \n",
    "            if true_rank is not None:\n",
    "                # Accuracy\n",
    "                if true_rank == 1:\n",
    "                    top1_correct += 1\n",
    "                    type_metrics[cell_type]['correct'] += 1\n",
    "                if true_rank <= 3:\n",
    "                    top3_correct += 1\n",
    "                if true_rank <= 5:\n",
    "                    top5_correct += 1\n",
    "                \n",
    "                # MRR\n",
    "                reciprocal_ranks.append(1.0 / true_rank)\n",
    "            else:\n",
    "                reciprocal_ranks.append(0.0)\n",
    "            \n",
    "            type_metrics[cell_type]['total'] += 1\n",
    "            \n",
    "            # Confiance de la prédiction top-1\n",
    "            if pred['candidates_ranked']:\n",
    "                confidences.append(pred['candidates_ranked'][0]['probability'])\n",
    "        \n",
    "        # Calculer les métriques finales\n",
    "        metrics['accuracy_top1'] = top1_correct / total\n",
    "        metrics['accuracy_top3'] = top3_correct / total\n",
    "        metrics['accuracy_top5'] = top5_correct / total\n",
    "        metrics['mrr'] = np.mean(reciprocal_ranks)\n",
    "        metrics['avg_confidence'] = np.mean(confidences) if confidences else 0.0\n",
    "        \n",
    "        # Métriques par type\n",
    "        type_names = {0: 'empty', 1: 'text', 2: 'number', 3: 'formula'}\n",
    "        for cell_type, stats in type_metrics.items():\n",
    "            type_name = type_names.get(cell_type, f'type_{cell_type}')\n",
    "            if stats['total'] > 0:\n",
    "                metrics['by_type'][type_name] = stats['correct'] / stats['total']\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _analyze_cell_prediction(self, \n",
    "                                prediction: Dict,\n",
    "                                gt_info: Dict,\n",
    "                                candidates: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyse détaillée d'une prédiction de cellule\"\"\"\n",
    "        \n",
    "        true_value = gt_info['true_value']\n",
    "        cell_type = gt_info['cell_type']\n",
    "        \n",
    "        # Trouver la vraie valeur dans les prédictions\n",
    "        true_rank = None\n",
    "        true_confidence = 0.0\n",
    "        \n",
    "        for rank, candidate_info in enumerate(prediction['candidates_ranked']):\n",
    "            if candidate_info['value'] == true_value:\n",
    "                true_rank = rank + 1\n",
    "                true_confidence = candidate_info['probability']\n",
    "                break\n",
    "        \n",
    "        # Analyser la distribution des probabilités\n",
    "        probs = [c['probability'] for c in prediction['candidates_ranked']]\n",
    "        prob_analysis = {\n",
    "            'entropy': -sum(p * np.log(p + 1e-10) for p in probs),\n",
    "            'max_prob': max(probs),\n",
    "            'min_prob': min(probs),\n",
    "            'std_prob': np.std(probs)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'cell_index': gt_info['cell_index'],\n",
    "            'position': gt_info['position'],\n",
    "            'sheet': gt_info['sheet'],\n",
    "            'cell_type': cell_type,\n",
    "            'true_value': true_value,\n",
    "            'predicted_value': prediction['candidates_ranked'][0]['value'],\n",
    "            'predicted_confidence': prediction['candidates_ranked'][0]['probability'],\n",
    "            'true_rank': true_rank,\n",
    "            'true_confidence': true_confidence,\n",
    "            'is_correct': true_rank == 1 if true_rank else False,\n",
    "            'prob_analysis': prob_analysis,\n",
    "            'all_candidates': candidates,\n",
    "            'top5_predictions': prediction['candidates_ranked'][:5]\n",
    "        }\n",
    "    \n",
    "    def _analyze_errors(self, cell_analyses: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Analyse des erreurs et patterns de performance\"\"\"\n",
    "        \n",
    "        error_analysis = {\n",
    "            'common_errors': defaultdict(int),\n",
    "            'error_by_type': defaultdict(int),\n",
    "            'error_by_position': defaultdict(int),\n",
    "            'confidence_errors': [],\n",
    "            'patterns': {}\n",
    "        }\n",
    "        \n",
    "        correct_predictions = []\n",
    "        incorrect_predictions = []\n",
    "        \n",
    "        for analysis in cell_analyses:\n",
    "            if analysis['is_correct']:\n",
    "                correct_predictions.append(analysis)\n",
    "            else:\n",
    "                incorrect_predictions.append(analysis)\n",
    "                \n",
    "                # Analyser les types d'erreurs\n",
    "                true_val = analysis['true_value']\n",
    "                pred_val = analysis['predicted_value']\n",
    "                cell_type = analysis['cell_type']\n",
    "                \n",
    "                error_analysis['error_by_type'][cell_type] += 1\n",
    "                \n",
    "                # Erreurs de confiance élevée (confiant mais faux)\n",
    "                if analysis['predicted_confidence'] > 0.7:\n",
    "                    error_analysis['confidence_errors'].append(analysis)\n",
    "                \n",
    "                # Patterns d'erreurs communes\n",
    "                if cell_type == 2:  # Nombres\n",
    "                    try:\n",
    "                        true_num = float(true_val) if true_val else 0\n",
    "                        pred_num = float(pred_val) if pred_val else 0\n",
    "                        if abs(true_num - pred_num) < 10:\n",
    "                            error_analysis['common_errors']['close_number'] += 1\n",
    "                        else:\n",
    "                            error_analysis['common_errors']['far_number'] += 1\n",
    "                    except:\n",
    "                        error_analysis['common_errors']['invalid_number'] += 1\n",
    "                \n",
    "                elif cell_type == 1:  # Texte\n",
    "                    if len(true_val) == len(pred_val):\n",
    "                        error_analysis['common_errors']['same_length_text'] += 1\n",
    "                    elif true_val.lower() in pred_val.lower() or pred_val.lower() in true_val.lower():\n",
    "                        error_analysis['common_errors']['partial_text_match'] += 1\n",
    "                    else:\n",
    "                        error_analysis['common_errors']['different_text'] += 1\n",
    "                \n",
    "                elif cell_type == 3:  # Formule\n",
    "                    if '=' in pred_val:\n",
    "                        error_analysis['common_errors']['wrong_formula'] += 1\n",
    "                    else:\n",
    "                        error_analysis['common_errors']['formula_as_value'] += 1\n",
    "        \n",
    "        # Patterns généraux\n",
    "        if correct_predictions and incorrect_predictions:\n",
    "            avg_conf_correct = np.mean([p['predicted_confidence'] for p in correct_predictions])\n",
    "            avg_conf_incorrect = np.mean([p['predicted_confidence'] for p in incorrect_predictions])\n",
    "            \n",
    "            error_analysis['patterns'] = {\n",
    "                'avg_confidence_correct': avg_conf_correct,\n",
    "                'avg_confidence_incorrect': avg_conf_incorrect,\n",
    "                'confidence_separation': avg_conf_correct - avg_conf_incorrect,\n",
    "                'total_errors': len(incorrect_predictions),\n",
    "                'error_rate': len(incorrect_predictions) / len(cell_analyses)\n",
    "            }\n",
    "        \n",
    "        return error_analysis\n",
    "    \n",
    "    def generate_evaluation_report(self, \n",
    "                                  json_files: List[Dict],\n",
    "                                  output_file: str = \"evaluation_report.html\") -> str:\n",
    "        \"\"\"Génère un rapport d'évaluation complet en HTML\"\"\"\n",
    "        \n",
    "        print(\"🔍 Génération du rapport d'évaluation...\")\n",
    "        \n",
    "        all_results = []\n",
    "        aggregated_metrics = defaultdict(list)\n",
    "        \n",
    "        # Évaluer tous les fichiers\n",
    "        for i, json_data in enumerate(json_files):\n",
    "            print(f\"  Évaluation {i+1}/{len(json_files)}\")\n",
    "            \n",
    "            result = self.evaluate_excel_file(json_data)\n",
    "            if 'error' not in result:\n",
    "                all_results.append(result)\n",
    "                \n",
    "                # Agréger les métriques\n",
    "                for strategy, strategy_result in result['strategy_results'].items():\n",
    "                    if 'metrics' in strategy_result:\n",
    "                        for metric, value in strategy_result['metrics'].items():\n",
    "                            if isinstance(value, (int, float)):\n",
    "                                aggregated_metrics[f\"{strategy}_{metric}\"].append(value)\n",
    "        \n",
    "        # Créer le rapport HTML\n",
    "        html_content = self._create_html_report(all_results, aggregated_metrics)\n",
    "        \n",
    "        # Sauvegarder\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        print(f\"✅ Rapport sauvegardé: {output_file}\")\n",
    "        return output_file\n",
    "    \n",
    "    def _create_html_report(self, \n",
    "                           all_results: List[Dict],\n",
    "                           aggregated_metrics: Dict) -> str:\n",
    "        \"\"\"Crée le contenu HTML du rapport\"\"\"\n",
    "        \n",
    "        # Calculer les statistiques globales\n",
    "        total_files = len(all_results)\n",
    "        total_predictions = sum(\n",
    "            len(result['cell_analysis']) \n",
    "            for result in all_results\n",
    "        )\n",
    "        \n",
    "        # Métriques moyennes\n",
    "        avg_metrics = {}\n",
    "        for metric, values in aggregated_metrics.items():\n",
    "            if values:\n",
    "                avg_metrics[metric] = {\n",
    "                    'mean': np.mean(values),\n",
    "                    'std': np.std(values),\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values)\n",
    "                }\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html lang=\"fr\">\n",
    "        <head>\n",
    "            <meta charset=\"UTF-8\">\n",
    "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "            <title>Rapport d'Évaluation - Excel Masked Prediction</title>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 20px; }}\n",
    "                .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 5px; }}\n",
    "                .section {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}\n",
    "                .metric {{ display: inline-block; margin: 10px; padding: 10px; background: #f8f9fa; border-radius: 3px; }}\n",
    "                .good {{ background: #d4edda; }}\n",
    "                .warning {{ background: #fff3cd; }}\n",
    "                .error {{ background: #f8d7da; }}\n",
    "                table {{ width: 100%; border-collapse: collapse; margin: 10px 0; }}\n",
    "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "                th {{ background-color: #f2f2f2; }}\n",
    "                .chart {{ margin: 20px 0; text-align: center; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"header\">\n",
    "                <h1>📊 Rapport d'Évaluation - Excel Masked Prediction</h1>\n",
    "                <p>Analyse de performance du transformer sur {total_files} fichiers Excel</p>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>📈 Résumé Exécutif</h2>\n",
    "                <div class=\"metric good\">\n",
    "                    <strong>Fichiers analysés:</strong> {total_files}\n",
    "                </div>\n",
    "                <div class=\"metric good\">\n",
    "                    <strong>Prédictions totales:</strong> {total_predictions}\n",
    "                </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ajouter les métriques principales\n",
    "        for strategy in ['random', 'strategic']:\n",
    "            acc_key = f\"{strategy}_accuracy_top1\"\n",
    "            if acc_key in avg_metrics:\n",
    "                acc = avg_metrics[acc_key]['mean']\n",
    "                css_class = \"good\" if acc > 0.7 else \"warning\" if acc > 0.4 else \"error\"\n",
    "                html += f\"\"\"\n",
    "                <div class=\"metric {css_class}\">\n",
    "                    <strong>Accuracy {strategy}:</strong> {acc:.1%} ± {avg_metrics[acc_key]['std']:.1%}\n",
    "                </div>\n",
    "                \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>📊 Métriques Détaillées</h2>\n",
    "                <table>\n",
    "                    <tr>\n",
    "                        <th>Métrique</th>\n",
    "                        <th>Stratégie</th>\n",
    "                        <th>Moyenne</th>\n",
    "                        <th>Écart-type</th>\n",
    "                        <th>Min</th>\n",
    "                        <th>Max</th>\n",
    "                    </tr>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Table des métriques\n",
    "        metric_names = {\n",
    "            'accuracy_top1': 'Accuracy Top-1',\n",
    "            'accuracy_top3': 'Accuracy Top-3', \n",
    "            'accuracy_top5': 'Accuracy Top-5',\n",
    "            'mrr': 'Mean Reciprocal Rank',\n",
    "            'avg_confidence': 'Confiance Moyenne'\n",
    "        }\n",
    "        \n",
    "        for strategy in ['random', 'strategic']:\n",
    "            for metric, display_name in metric_names.items():\n",
    "                key = f\"{strategy}_{metric}\"\n",
    "                if key in avg_metrics:\n",
    "                    stats = avg_metrics[key]\n",
    "                    html += f\"\"\"\n",
    "                    <tr>\n",
    "                        <td>{display_name}</td>\n",
    "                        <td>{strategy.title()}</td>\n",
    "                        <td>{stats['mean']:.3f}</td>\n",
    "                        <td>{stats['std']:.3f}</td>\n",
    "                        <td>{stats['min']:.3f}</td>\n",
    "                        <td>{stats['max']:.3f}</td>\n",
    "                    </tr>\n",
    "                    \"\"\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "                </table>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>🔍 Analyse des Erreurs</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Analyse des erreurs les plus communes\n",
    "        all_errors = defaultdict(int)\n",
    "        for result in all_results:\n",
    "            if 'error_analysis' in result:\n",
    "                for error_type, count in result['error_analysis']['common_errors'].items():\n",
    "                    all_errors[error_type] += count\n",
    "        \n",
    "        if all_errors:\n",
    "            html += \"<h3>Erreurs les plus fréquentes:</h3><ul>\"\n",
    "            sorted_errors = sorted(all_errors.items(), key=lambda x: x[1], reverse=True)\n",
    "            for error_type, count in sorted_errors[:5]:\n",
    "                html += f\"<li><strong>{error_type}:</strong> {count} occurrences</li>\"\n",
    "            html += \"</ul>\"\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>📋 Exemples de Prédictions</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Quelques exemples de prédictions\n",
    "        example_count = 0\n",
    "        for result in all_results[:3]:  # Premiers 3 fichiers\n",
    "            if 'cell_analysis' in result:\n",
    "                html += f\"<h3>Fichier {example_count + 1}:</h3>\"\n",
    "                for cell in result['cell_analysis'][:2]:  # 2 cellules par fichier\n",
    "                    status = \"✅ Correct\" if cell['is_correct'] else \"❌ Incorrect\"\n",
    "                    html += f\"\"\"\n",
    "                    <div style=\"margin: 10px 0; padding: 10px; border-left: 3px solid {'green' if cell['is_correct'] else 'red'};\">\n",
    "                        <strong>{status}</strong> - Cellule ({cell['position'][0]}, {cell['position'][1]})<br>\n",
    "                        <strong>Vraie valeur:</strong> \"{cell['true_value']}\"<br>\n",
    "                        <strong>Prédiction:</strong> \"{cell['predicted_value']}\" ({cell['predicted_confidence']:.1%})<br>\n",
    "                        <strong>Type:</strong> {['Vide', 'Texte', 'Nombre', 'Formule'][cell['cell_type']]}\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                example_count += 1\n",
    "                if example_count >= 3:\n",
    "                    break\n",
    "        \n",
    "        html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>🎯 Recommandations</h2>\n",
    "                <ul>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Générer des recommandations basées sur les résultats\n",
    "        recommendations = []\n",
    "        \n",
    "        # Vérifier la performance globale\n",
    "        if 'random_accuracy_top1' in avg_metrics:\n",
    "            acc = avg_metrics['random_accuracy_top1']['mean']\n",
    "            if acc < 0.5:\n",
    "                recommendations.append(\"🔴 Performance faible (<50%): Augmenter la taille du modèle ou améliorer les données d'entraînement\")\n",
    "            elif acc < 0.7:\n",
    "                recommendations.append(\"🟡 Performance modérée: Optimiser l'architecture ou les hyperparamètres\")\n",
    "            else:\n",
    "                recommendations.append(\"🟢 Performance satisfaisante: Continuer l'entraînement pour améliorer la stabilité\")\n",
    "        \n",
    "        # Vérifier la différence entre stratégies\n",
    "        if ('random_accuracy_top1' in avg_metrics and \n",
    "            'strategic_accuracy_top1' in avg_metrics):\n",
    "            diff = (avg_metrics['strategic_accuracy_top1']['mean'] - \n",
    "                   avg_metrics['random_accuracy_top1']['mean'])\n",
    "            if abs(diff) < 0.05:\n",
    "                recommendations.append(\"⚪ Peu de différence entre stratégies: Le modèle pourrait bénéficier d'un meilleur encodage du contexte\")\n",
    "        \n",
    "        # Analyser la confiance\n",
    "        if 'random_avg_confidence' in avg_metrics:\n",
    "            conf = avg_metrics['random_avg_confidence']['mean']\n",
    "            if conf < 0.3:\n",
    "                recommendations.append(\"🔵 Confiance faible: Revoir la calibration du modèle\")\n",
    "            elif conf > 0.9:\n",
    "                recommendations.append(\"🟠 Confiance très élevée: Risque de sur-confiance, vérifier la diversité des données\")\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations.append(\"✨ Aucune recommandation spécifique - Continuer le monitoring\")\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            html += f\"<li>{rec}</li>\"\n",
    "        \n",
    "        html += f\"\"\"\n",
    "                </ul>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"section\">\n",
    "                <h2>ℹ️ Informations Techniques</h2>\n",
    "                <p><strong>Modèle:</strong> Excel Graph Transformer avec Masked Cell Prediction</p>\n",
    "                <p><strong>Date d'évaluation:</strong> {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "                <p><strong>Nombre de paramètres:</strong> {sum(p.numel() for p in self.model.parameters()):,}</p>\n",
    "                <p><strong>Stratégies testées:</strong> Random masking, Strategic masking</p>\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        return html\n",
    "    \n",
    "    def interactive_test(self, json_data: Dict[str, Any]):\n",
    "        \"\"\"Test interactif sur un fichier Excel\"\"\"\n",
    "        \n",
    "        print(\"\\n🎮 MODE INTERACTIF - Test de Prédiction\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Préparer les données\n",
    "            cells = self.transformer_builder._extract_cells_from_json(json_data)\n",
    "            cells = self.transformer_builder._filter_cells(cells, max_total_cells=50)\n",
    "            \n",
    "            if not cells:\n",
    "                print(\"❌ Aucune cellule trouvée dans le fichier\")\n",
    "                return\n",
    "            \n",
    "            graph = self.transformer_builder.graph_embedder(cells)\n",
    "            \n",
    "            print(f\"📊 Fichier chargé: {graph.num_nodes} cellules, {graph.num_edges} relations\")\n",
    "            print(f\"📋 Feuilles: {', '.join(set(cell.sheet_name for cell in cells))}\")\n",
    "            \n",
    "            # Afficher les cellules disponibles\n",
    "            print(\"\\n📱 Cellules disponibles:\")\n",
    "            for i, cell in enumerate(cells[:10]):  # Afficher les 10 premières\n",
    "                content = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"[vide]\"\n",
    "                type_name = ['Vide', 'Texte', 'Nombre', 'Formule'][cell.cell_type]\n",
    "                print(f\"  {i:2d}. ({cell.row:2d},{cell.col:2d}) {type_name:8s} | {content[:30]}\")\n",
    "            \n",
    "            if len(cells) > 10:\n",
    "                print(f\"  ... et {len(cells) - 10} autres cellules\")\n",
    "            \n",
    "            # Interface interactive\n",
    "            while True:\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                choice = input(\"Choisir une action:\\n\"\n",
    "                             \"  1. Masquer une cellule spécifique\\n\"\n",
    "                             \"  2. Masquage aléatoire\\n\"\n",
    "                             \"  3. Masquage stratégique\\n\"\n",
    "                             \"  4. Quitter\\n\"\n",
    "                             \"Votre choix (1-4): \").strip()\n",
    "                \n",
    "                if choice == '4':\n",
    "                    print(\"👋 Au revoir !\")\n",
    "                    break\n",
    "                \n",
    "                elif choice == '1':\n",
    "                    try:\n",
    "                        cell_idx = int(input(f\"Index de la cellule à masquer (0-{len(cells)-1}): \"))\n",
    "                        if 0 <= cell_idx < len(cells):\n",
    "                            mask_indices = [cell_idx]\n",
    "                        else:\n",
    "                            print(\"❌ Index invalide\")\n",
    "                            continue\n",
    "                    except ValueError:\n",
    "                        print(\"❌ Veuillez entrer un nombre\")\n",
    "                        continue\n",
    "                \n",
    "                elif choice == '2':\n",
    "                    mask_indices = ExcelMaskingStrategy.random_masking(cells, mask_ratio=0.1)\n",
    "                    print(f\"🎲 Masquage aléatoire: cellules {mask_indices}\")\n",
    "                \n",
    "                elif choice == '3':\n",
    "                    mask_indices = ExcelMaskingStrategy.strategic_masking(cells)\n",
    "                    print(f\"🎯 Masquage stratégique: cellules {mask_indices}\")\n",
    "                \n",
    "                else:\n",
    "                    print(\"❌ Choix invalide\")\n",
    "                    continue\n",
    "                \n",
    "                if not mask_indices:\n",
    "                    print(\"❌ Aucune cellule à masquer\")\n",
    "                    continue\n",
    "                \n",
    "                # Effectuer la prédiction\n",
    "                candidates = [generate_candidates(cells[idx], 10) for idx in mask_indices]\n",
    "                predictions = self.model.predict_top_candidates(graph, mask_indices, candidates)\n",
    "                \n",
    "                # Afficher les résultats\n",
    "                print(f\"\\n🔮 RÉSULTATS DE PRÉDICTION\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                for i, (mask_idx, prediction) in enumerate(zip(mask_indices, predictions)):\n",
    "                    cell = cells[mask_idx]\n",
    "                    true_value = str(cell.raw_value) if cell.raw_value else str(cell.formula) if cell.formula else \"[vide]\"\n",
    "                    \n",
    "                    print(f\"\\n📍 Cellule {mask_idx} - Position ({cell.row},{cell.col})\")\n",
    "                    print(f\"   Type: {['Vide', 'Texte', 'Nombre', 'Formule'][cell.cell_type]}\")\n",
    "                    print(f\"   Vraie valeur: '{true_value}'\")\n",
    "                    print(f\"   Top 5 prédictions:\")\n",
    "                    \n",
    "                    for rank, candidate in enumerate(prediction['candidates_ranked'][:5]):\n",
    "                        marker = \"🎯\" if candidate['value'] == true_value else f\"{rank+1}.\"\n",
    "                        confidence = candidate['probability']\n",
    "                        bar_length = int(confidence * 20)\n",
    "                        bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
    "                        \n",
    "                        print(f\"     {marker:3s} {candidate['value'][:25]:25s} │{bar}│ {confidence:.1%}\")\n",
    "                    \n",
    "                    # Trouver le rang de la vraie valeur\n",
    "                    true_rank = None\n",
    "                    for rank, candidate in enumerate(prediction['candidates_ranked']):\n",
    "                        if candidate['value'] == true_value:\n",
    "                            true_rank = rank + 1\n",
    "                            break\n",
    "                    \n",
    "                    if true_rank:\n",
    "                        if true_rank == 1:\n",
    "                            print(f\"   ✅ Prédiction correcte ! (rang {true_rank})\")\n",
    "                        elif true_rank <= 3:\n",
    "                            print(f\"   🟡 Dans le top 3 (rang {true_rank})\")\n",
    "                        elif true_rank <= 5:\n",
    "                            print(f\"   🟠 Dans le top 5 (rang {true_rank})\")\n",
    "                        else:\n",
    "                            print(f\"   ❌ Hors du top 5 (rang {true_rank})\")\n",
    "                    else:\n",
    "                        print(f\"   ❌ Vraie valeur non trouvée dans les candidats\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur: {e}\")\n",
    "\n",
    "# Fonction utilitaire pour lancer une évaluation complète\n",
    "def run_complete_evaluation(json_files: List[Dict], \n",
    "                           model: 'MaskedCellPredictor',\n",
    "                           transformer_builder: 'JSONToGraphTransformer') -> str:\n",
    "    \"\"\"Lance une évaluation complète et génère le rapport\"\"\"\n",
    "    \n",
    "    evaluator = ExcelMaskedEvaluator(model, transformer_builder)\n",
    "    \n",
    "    # Générer le rapport\n",
    "    report_file = evaluator.generate_evaluation_report(json_files)\n",
    "    \n",
    "    # Afficher un résumé\n",
    "    print(\"\\n📊 RÉSUMÉ DE L'ÉVALUATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    sample_result = evaluator.evaluate_excel_file(json_files[0] if json_files else {})\n",
    "    if 'error' not in sample_result and 'strategy_results' in sample_result:\n",
    "        for strategy, result in sample_result['strategy_results'].items():\n",
    "            if 'metrics' in result:\n",
    "                metrics = result['metrics']\n",
    "                print(f\"\\n{strategy.upper()} MASKING:\")\n",
    "                print(f\"  Accuracy Top-1: {metrics.get('accuracy_top1', 0):.1%}\")\n",
    "                print(f\"  Accuracy Top-3: {metrics.get('accuracy_top3', 0):.1%}\")\n",
    "                print(f\"  MRR: {metrics.get('mrr', 0):.3f}\")\n",
    "                print(f\"  Confiance moy.: {metrics.get('avg_confidence', 0):.1%}\")\n",
    "    \n",
    "    return report_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"📋 Module d'évaluation Excel Masked Prediction chargé\")\n",
    "    print(\"Utilisez run_complete_evaluation() pour une évaluation complète\")\n",
    "    print(\"Ou ExcelMaskedEvaluator.interactive_test() pour un test interactif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
